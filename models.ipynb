{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.14.0\n",
      "Keras version: 2.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Implementation and Performance Analysis Notebook\n",
    "\n",
    "This notebook serves as a comprehensive guide for analyzing and comparing the performance of different humor classification models across multimedia and natural text data. It provides an in-depth examination of binary and multifactorial classification approaches using two main architectures:\n",
    "\n",
    "1. Fine-tuned BERT Models:\n",
    "   - Binary classification (humor vs. non-humor)\n",
    "   - Multifactorial classification (humor intensity levels 1-5)\n",
    "   - Variants trained on different dataset sizes and captioning methods\n",
    "\n",
    "2. LSTM-based Architectures:\n",
    "   - Single-layer LSTM implementation\n",
    "   - Dual-layer LSTM implementation\n",
    "   - Both architectures combined with BERT embeddings\n",
    "\n",
    "Each section includes:\n",
    "- Model loading and configuration\n",
    "- Performance evaluation metrics (accuracy, F1-score, recall)\n",
    "- Comparative analysis between multimedia and natural text data\n",
    "- Detailed error analysis and prediction samples\n",
    "\n",
    "For implementation details and the complete steps to train these models yourself, please refer to the instructions provided in the README.md file. This notebook focuses on model evaluation and analysis rather than training, assuming pre-trained models are available.\n",
    "\n",
    "Note: This notebook requires access to trained model checkpoints and the complete dataset with both multimedia and natural text samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dataframes(file_humour, file_no_humour, one_hot:bool = False):\n",
    "    \"\"\"\n",
    "    Combine humor and non-humor datasets into a single dataset.\n",
    "    \n",
    "    Args:\n",
    "        file_humour (str): Path to CSV file containing humor data\n",
    "        file_no_humour (str): Path to CSV file containing non-humor data\n",
    "        \n",
    "    Returns:\n",
    "        Dataset: Combined dataset with humor and non-humor examples\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if one_hot:\n",
    "            df_humor = pd.read_csv(file_humour)\n",
    "            df_humor.rename(columns={\"Chistes\": \"text\"}, inplace=True)\n",
    "            df_humor.drop(columns=[\"id_chiste\"], inplace=True)\n",
    "            \n",
    "            # Create label encoder for nivel_risa\n",
    "            label_encoder = LabelEncoder()\n",
    "            df_humor['nivel_risa_encoded'] = label_encoder.fit_transform(df_humor['nivel_risa'])\n",
    "            \n",
    "            # Store the original mapping\n",
    "            label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "            print(\"Label mapping:\", label_mapping)\n",
    "            \n",
    "            dataset = Dataset.from_pandas(df_humor)\n",
    "            return dataset, label_encoder\n",
    "        else:\n",
    "            df_no_humor = pd.read_csv(file_no_humour)\n",
    "            df_no_humor[\"nivel_risa\"] = 0\n",
    "            \n",
    "            df_humor = pd.read_csv(file_humour)\n",
    "            df_humor.rename(columns={\"Chistes\": \"text\"}, inplace=True)\n",
    "            df_humor['label'] = 1\n",
    "            df_humor.drop(columns=[\"id_chiste\"], inplace=True)\n",
    "            \n",
    "            df_combined = pd.concat([df_humor, df_no_humor], ignore_index=True)\n",
    "            return Dataset.from_pandas(df_combined)\n",
    "    except Exception as e:\n",
    "        print(f\"Error on combine_dataframes: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = combine_dataframes(\"data/classification/complete_dataset_chistes.csv\",\"data/classification/data_with_no_humour.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'nivel_risa', 'label'],\n",
       "    num_rows: 19417\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c30d4ac2bb47388ab0a9604c3415cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19417 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-large-cased',  unk_token=\"[UNK]\")\n",
    "\n",
    "def tokenize_function(examples, column: str ='label'):\n",
    "    \"\"\"\n",
    "    Tokenizes text data and adds corresponding labels from a specified column.\n",
    "\n",
    "    Args:\n",
    "        examples (dict): Dictionary containing text samples to tokenize. Must have a 'text' key \n",
    "            containing the text to be tokenized.\n",
    "        column (str, optional): Name of the column containing the labels. Defaults to 'label'.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing:\n",
    "            - All tokenizer outputs (input_ids, attention_mask, etc.)\n",
    "            - 'labels': List of labels copied from the specified column\n",
    "\n",
    "    Notes:\n",
    "        - Uses a global 'tokenizer' object which must be defined before calling this function\n",
    "        - Truncates sequences to max_length=64 tokens\n",
    "        - Uses padding='max_length' to pad all sequences to the same length\n",
    "        \n",
    "    Example:\n",
    "        >>> data = {'text': ['sample text'], 'label': [1]}\n",
    "        >>> tokenized = tokenize_function(data)\n",
    "        >>> print(tokenized.keys())\n",
    "        dict_keys(['input_ids', 'attention_mask', 'labels'])\n",
    "    \"\"\"\n",
    "    tokenized = tokenizer(\n",
    "        examples['text'],\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=64\n",
    "    )\n",
    "    tokenized['labels'] = examples[column]  \n",
    "    return tokenized\n",
    "\n",
    "encoded_dataset = dataset.map(tokenize_function, batched=True)\n",
    "vocab_size = tokenizer.vocab_size\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28996"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver los tokens problemáticos\n",
    "problematic_tokens = []\n",
    "for i, tokens in enumerate(encoded_dataset['input_ids']):\n",
    "    if max(tokens) >= vocab_size:\n",
    "        problematic_tokens.append((i, max(tokens)))\n",
    "        print(f\"Ejemplo {i}, token problemático: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'nivel_risa', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 19417\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'nivel_risa', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 12231\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'nivel_risa', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 1360\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'nivel_risa', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 5826\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_validation_test_split = encoded_dataset.train_test_split(test_size=0.3, seed=42)\n",
    "\n",
    "train_validation_split = train_validation_test_split['train'].train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "final_split = DatasetDict({\n",
    "    'train': train_validation_split['train'],  # 70% * 0.9 = 63% del total\n",
    "    'validation': train_validation_split['test'],  # 70% * 0.1 = 7% del total\n",
    "    'test': train_validation_test_split['test']  # 30% del total\n",
    "})\n",
    "\n",
    "# Revisar tamaños\n",
    "print(final_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({\n",
    "    'text': final_split['test']['text'],\n",
    "    'label': final_split['test']['labels']\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "test_df.to_csv('data/testing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12231"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_split['train'].num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar una muestra aleatoria de 500 ejemplos para entrenamiento y 100 para validación\n",
    "train_sample = final_split['train'].shuffle(seed=42).select(range(500))\n",
    "validation_sample = final_split['validation'].shuffle(seed=42).select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Temp\\ipykernel_43424\\2023103589.py:33: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = df.groupby(column).apply(lambda x: x.sample(n=num_samples, random_state=42))\n"
     ]
    }
   ],
   "source": [
    "def sample_dataset(dataset, column, num_samples=20):\n",
    "    \"\"\"\n",
    "    Creates a balanced sample of data by sampling an equal number of records from each category.\n",
    "\n",
    "    Args:\n",
    "        dataset (Union[Dataset, pd.DataFrame]): Input dataset, can be either a Hugging Face Dataset \n",
    "            or pandas DataFrame.\n",
    "        column (str): Name of the column to stratify by (e.g., class labels).\n",
    "        num_samples (int, optional): Number of samples to take from each unique value in the specified \n",
    "            column. Defaults to 20.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame containing the balanced sample with index reset.\n",
    "        \n",
    "    Notes:\n",
    "        - Uses random_state=42 for reproducibility\n",
    "        - If a category has fewer samples than requested, may raise ValueError\n",
    "        - Automatically converts Hugging Face Dataset to pandas DataFrame if needed\n",
    "        \n",
    "    Example:\n",
    "        >>> df = pd.DataFrame({'text': ['a', 'b', 'c', 'd'], 'label': [0, 0, 1, 1]})\n",
    "        >>> balanced = sample_dataset(df, 'label', num_samples=1)\n",
    "        >>> print(balanced)\n",
    "           text  label\n",
    "        0    a      0\n",
    "        1    c      1\n",
    "    \"\"\"\n",
    "    if isinstance(dataset, Dataset):\n",
    "        df = dataset.to_pandas()\n",
    "    else:\n",
    "        df = dataset\n",
    "    \n",
    "    sampled_df = df.groupby(column).apply(lambda x: x.sample(n=num_samples, random_state=42))\n",
    "    return sampled_df.reset_index(drop=True)\n",
    "\n",
    "# Function to get predictions with proper tensor handling\n",
    "def get_prediction(model, text):\n",
    "    \"\"\"\n",
    "    Generates a single class prediction for a given text using a PyTorch model.\n",
    "\n",
    "    Args:\n",
    "        model: PyTorch model with a predict method that returns probabilities.\n",
    "        text (str): Input text to classify.\n",
    "\n",
    "    Returns:\n",
    "        int: Predicted class index (argmax of model probabilities).\n",
    "\n",
    "    Notes:\n",
    "        - Disables gradient computation for inference efficiency\n",
    "        - Assumes model.predict() returns a tensor of class probabilities\n",
    "        - Automatically handles tensor-to-numpy conversion\n",
    "        \n",
    "    Example:\n",
    "        >>> predicted_class = get_prediction(model, \"sample text\")\n",
    "        >>> print(predicted_class)\n",
    "        1\n",
    "    \"\"\"\n",
    "    # Get prediction probabilities\n",
    "    with torch.no_grad():  # Disable gradient tracking\n",
    "        probs = model.predict(text)\n",
    "        # Detach from computation graph and convert to numpy\n",
    "        return probs.detach().numpy().argmax()\n",
    "\n",
    "# Sample 20 rows per class\n",
    "sampled_data = sample_dataset(dataset, column=\"label\", num_samples=20)\n",
    "\n",
    "# Extract texts and labels\n",
    "texts = sampled_data[\"text\"].tolist()\n",
    "true_labels = sampled_data[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only Label - Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred,binary:bool=True):\n",
    "    \"\"\"\n",
    "    Compute evaluation metrics for model predictions.\n",
    "    \n",
    "    Args:\n",
    "        eval_pred (tuple): Tuple of predictions and labels\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing accuracy metric\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if binary:\n",
    "            predictions, labels = eval_pred\n",
    "            predictions = np.argmax(predictions, axis=1)\n",
    "            return {\"accuracy\": accuracy_score(labels, predictions)}\n",
    "        else:\n",
    "            predictions, labels = eval_pred\n",
    "            predictions = np.argmax(predictions, axis=1)\n",
    "            accuracy = accuracy_score(labels, predictions)\n",
    "            \n",
    "            label_encoder = LabelEncoder()\n",
    "            \n",
    "            # Convert numeric predictions back to original labels for better understanding\n",
    "            pred_original = label_encoder.inverse_transform(predictions)\n",
    "            labels_original = label_encoder.inverse_transform(labels)\n",
    "            \n",
    "            return {\n",
    "                \"accuracy\": accuracy,\n",
    "                \"predictions\": pred_original.tolist()[:5],  # Show first 5 predictions\n",
    "                \"true_labels\": labels_original.tolist()[:5]  # Show first 5 true labels\n",
    "            }\n",
    "                \n",
    "    except Exception as e:\n",
    "            print(f\"Error on compute_metrics: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification \n",
    "\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-large-cased', num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"steps\",\n",
    "    learning_rate=5.0e-05,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    use_cpu = False,\n",
    "    fp16=True,\n",
    "    save_total_limit=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizer(name_or_path='bert-large-cased', vocab_size=28996, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_sample,      \n",
    "    eval_dataset=validation_sample,  \n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo con captioning de GPT - 1000 data train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cargar el modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from models.finetuning import FineTuning\n",
    "\n",
    "# Initialize and load the model\n",
    "model_1k_gpt_finetuning = FineTuning(num_labels=2)\n",
    "model_path = r\"models\\binary\\complete_dataset_chistes_finetuning_binary_model_1000_300\"\n",
    "model_1k_gpt_finetuning.load_model(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 0 20]\n",
      " [ 0 20]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.50      1.00      0.67        20\n",
      "\n",
      "    accuracy                           0.50        40\n",
      "   macro avg       0.25      0.50      0.33        40\n",
      "weighted avg       0.25      0.50      0.33        40\n",
      "\n",
      "\n",
      "Sample Predictions:\n",
      "\n",
      "Text: para María de la Piedad una existencia de abandonada. De repente, todo en torno de ella --la enferme...\n",
      "True Label: 0\n",
      "Predicted: 1\n",
      "\n",
      "Text: Hospital General y un cesante, a quien llamaban don Cleto. Don Cleto Meana era el filósofo de la cas...\n",
      "True Label: 0\n",
      "Predicted: 1\n",
      "\n",
      "Text: ví hecho minero, Mas nunca tuvo el pobre mina buena: Busquemos una agora en otro canto, Que ya cansa...\n",
      "True Label: 0\n",
      "Predicted: 1\n",
      "\n",
      "Text: Una mano blanca y fría, blanca como la nieve y como la nieve fría, tocó su mano. Y sintió Augusto qu...\n",
      "True Label: 0\n",
      "Predicted: 1\n",
      "\n",
      "Text: nada!--rugió el Capitán con suma nobleza.--¡Pues no faltaba más, estando yo en el mundo![290]--Ciert...\n",
      "True Label: 0\n",
      "Predicted: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = [get_prediction(model_1k_gpt_finetuning, text) for text in texts]\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "class_report = classification_report(true_labels, predictions)\n",
    "\n",
    "# Display results\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Optional: Display predictions alongside texts\n",
    "print(\"\\nSample Predictions:\")\n",
    "for text, true_label, pred in zip(texts[:5], true_labels[:5], predictions[:5]):\n",
    "    print(f\"\\nText: {text[:100]}...\")  # Show first 100 chars\n",
    "    print(f\"True Label: {true_label}\")\n",
    "    print(f\"Predicted: {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metrics evaluation on validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Results for finetuning_bert (binary):\n",
      "--------------------------------------------------\n",
      "eval_loss: 0.6927055716514587\n",
      "eval_accuracy: 0.5183823529411765\n",
      "eval_f1_score: 0.6828087167070218\n",
      "eval_f1_score_micro: 0.5183823529411765\n",
      "eval_recall: 1.0\n",
      "eval_runtime: 3.5107\n",
      "eval_samples_per_second: 387.388\n",
      "eval_steps_per_second: 48.423\n",
      "epoch: 4.12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\binary\\evaluation\\finetuning_bert_complete_dataset_chistes_1000_validation_results.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Results for finetuning_bert (binary):\n",
      "--------------------------------------------------\n",
      "eval_loss: 0.6937559843063354\n",
      "eval_accuracy: 0.5092687950566427\n",
      "eval_f1_score: 0.6748549982940976\n",
      "eval_f1_score_micro: 0.5092687950566427\n",
      "eval_recall: 1.0\n",
      "eval_runtime: 14.9526\n",
      "eval_samples_per_second: 389.63\n",
      "eval_steps_per_second: 48.754\n",
      "epoch: 4.12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\binary\\testing\\finetuning_bert_binary_complete_dataset_chistes_1000_test_evaluation.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo con captioning de GPT - 5000 data train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from models.finetuning import FineTuning\n",
    "\n",
    "# Initialize and load the model\n",
    "model_5k_gpt_finetuning_binary = FineTuning(num_labels=2)\n",
    "model_path = r\"models\\binary\\complete_dataset_chistes_finetuning_binary_model_5000_300\"\n",
    "model_5k_gpt_finetuning_binary.load_model(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[20  0]\n",
      " [ 5 15]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        20\n",
      "           1       1.00      0.75      0.86        20\n",
      "\n",
      "    accuracy                           0.88        40\n",
      "   macro avg       0.90      0.88      0.87        40\n",
      "weighted avg       0.90      0.88      0.87        40\n",
      "\n",
      "\n",
      "Sample Predictions:\n",
      "\n",
      "Text: para María de la Piedad una existencia de abandonada. De repente, todo en torno de ella --la enferme...\n",
      "True Label: 0\n",
      "Predicted: 0\n",
      "\n",
      "Text: Hospital General y un cesante, a quien llamaban don Cleto. Don Cleto Meana era el filósofo de la cas...\n",
      "True Label: 0\n",
      "Predicted: 0\n",
      "\n",
      "Text: ví hecho minero, Mas nunca tuvo el pobre mina buena: Busquemos una agora en otro canto, Que ya cansa...\n",
      "True Label: 0\n",
      "Predicted: 0\n",
      "\n",
      "Text: Una mano blanca y fría, blanca como la nieve y como la nieve fría, tocó su mano. Y sintió Augusto qu...\n",
      "True Label: 0\n",
      "Predicted: 0\n",
      "\n",
      "Text: nada!--rugió el Capitán con suma nobleza.--¡Pues no faltaba más, estando yo en el mundo![290]--Ciert...\n",
      "True Label: 0\n",
      "Predicted: 0\n"
     ]
    }
   ],
   "source": [
    "predictions = [get_prediction(model_5k_gpt_finetuning_binary, text) for text in texts]\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "class_report = classification_report(true_labels, predictions)\n",
    "\n",
    "# Display results\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Optional: Display predictions alongside texts\n",
    "print(\"\\nSample Predictions:\")\n",
    "for text, true_label, pred in zip(texts[:5], true_labels[:5], predictions[:5]):\n",
    "    print(f\"\\nText: {text[:100]}...\")  # Show first 100 chars\n",
    "    print(f\"True Label: {true_label}\")\n",
    "    print(f\"Predicted: {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metrics on validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Results for finetuning_bert (binary):\n",
      "--------------------------------------------------\n",
      "eval_loss: 0.35674652457237244\n",
      "eval_accuracy: 0.8455882352941176\n",
      "eval_f1_score: 0.825\n",
      "eval_f1_score_micro: 0.8455882352941176\n",
      "eval_recall: 0.7021276595744681\n",
      "eval_runtime: 3.6226\n",
      "eval_samples_per_second: 375.423\n",
      "eval_steps_per_second: 46.928\n",
      "epoch: 0.824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\binary\\evaluation\\finetuning_bert_complete_dataset_chistes_5000_validation_results.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metrics on testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Results for finetuning_bert (binary):\n",
      "--------------------------------------------------\n",
      "eval_loss: 0.3687657415866852\n",
      "eval_accuracy: 0.8405423961551665\n",
      "eval_f1_score: 0.8145338390896386\n",
      "eval_f1_score_micro: 0.8405423961551665\n",
      "eval_recall: 0.6875631951466128\n",
      "eval_runtime: 14.7873\n",
      "eval_samples_per_second: 393.987\n",
      "eval_steps_per_second: 49.299\n",
      "epoch: 0.824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\binary\\testing\\finetuning_bert_binary_complete_dataset_chistes_5000_test_evaluation.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo con captioning de GPT - All data train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from models.finetuning import FineTuning\n",
    "\n",
    "# Initialize and load the model\n",
    "model_12k_gpt_finetuning = FineTuning(num_labels=2)\n",
    "model_path = r\"models\\binary\\complete_dataset_chistes_finetuning_binary_model_12231_300\"\n",
    "model_12k_gpt_finetuning.load_model(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[20  0]\n",
      " [20  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67        20\n",
      "           1       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.50        40\n",
      "   macro avg       0.25      0.50      0.33        40\n",
      "weighted avg       0.25      0.50      0.33        40\n",
      "\n",
      "\n",
      "Sample Predictions:\n",
      "\n",
      "Text: para María de la Piedad una existencia de abandonada. De repente, todo en torno de ella --la enferme...\n",
      "True Label: 0\n",
      "Predicted: 0\n",
      "\n",
      "Text: Hospital General y un cesante, a quien llamaban don Cleto. Don Cleto Meana era el filósofo de la cas...\n",
      "True Label: 0\n",
      "Predicted: 0\n",
      "\n",
      "Text: ví hecho minero, Mas nunca tuvo el pobre mina buena: Busquemos una agora en otro canto, Que ya cansa...\n",
      "True Label: 0\n",
      "Predicted: 0\n",
      "\n",
      "Text: Una mano blanca y fría, blanca como la nieve y como la nieve fría, tocó su mano. Y sintió Augusto qu...\n",
      "True Label: 0\n",
      "Predicted: 0\n",
      "\n",
      "Text: nada!--rugió el Capitán con suma nobleza.--¡Pues no faltaba más, estando yo en el mundo![290]--Ciert...\n",
      "True Label: 0\n",
      "Predicted: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = [get_prediction(model_12k_gpt_finetuning, text) for text in texts]\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "class_report = classification_report(true_labels, predictions)\n",
    "\n",
    "# Display results\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Optional: Display predictions alongside texts\n",
    "print(\"\\nSample Predictions:\")\n",
    "for text, true_label, pred in zip(texts[:5], true_labels[:5], predictions[:5]):\n",
    "    print(f\"\\nText: {text[:100]}...\")  # Show first 100 chars\n",
    "    print(f\"True Label: {true_label}\")\n",
    "    print(f\"Predicted: {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metrics on validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Results for finetuning_bert (binary):\n",
      "--------------------------------------------------\n",
      "eval_loss: 0.6962682604789734\n",
      "eval_accuracy: 0.48161764705882354\n",
      "eval_f1_score: 0.0\n",
      "eval_f1_score_micro: 0.48161764705882354\n",
      "eval_recall: 0.0\n",
      "eval_runtime: 3.2242\n",
      "eval_samples_per_second: 421.809\n",
      "eval_steps_per_second: 52.726\n",
      "epoch: 0.6638325703073904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\binary\\evaluation\\finetuning_bert_complete_dataset_chistes_12231_validation_results.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metrics on testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Results for finetuning_bert (binary):\n",
      "--------------------------------------------------\n",
      "eval_loss: 0.6953372359275818\n",
      "eval_accuracy: 0.49073120494335737\n",
      "eval_f1_score: 0.0\n",
      "eval_f1_score_micro: 0.49073120494335737\n",
      "eval_recall: 0.0\n",
      "eval_runtime: 13.7737\n",
      "eval_samples_per_second: 422.981\n",
      "eval_steps_per_second: 52.927\n",
      "epoch: 0.6638325703073904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\binary\\testing\\finetuning_bert_binary_complete_dataset_chistes_12231_test_evaluation.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo con captioning de blip - All data train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from models.finetuning import FineTuning\n",
    "\n",
    "# Initialize and load the model\n",
    "model_12k_blip_finetuning_binary = FineTuning(num_labels=2)\n",
    "model_path = r\"models\\binary\\captionning_blip_finetuning_binary_model_12225_300\"\n",
    "model_12k_blip_finetuning_binary.load_model(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 0 20]\n",
      " [ 0 20]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.50      1.00      0.67        20\n",
      "\n",
      "    accuracy                           0.50        40\n",
      "   macro avg       0.25      0.50      0.33        40\n",
      "weighted avg       0.25      0.50      0.33        40\n",
      "\n",
      "\n",
      "Sample Predictions:\n",
      "\n",
      "Text: para María de la Piedad una existencia de abandonada. De repente, todo en torno de ella --la enferme...\n",
      "True Label: 0\n",
      "Predicted: 1\n",
      "\n",
      "Text: Hospital General y un cesante, a quien llamaban don Cleto. Don Cleto Meana era el filósofo de la cas...\n",
      "True Label: 0\n",
      "Predicted: 1\n",
      "\n",
      "Text: ví hecho minero, Mas nunca tuvo el pobre mina buena: Busquemos una agora en otro canto, Que ya cansa...\n",
      "True Label: 0\n",
      "Predicted: 1\n",
      "\n",
      "Text: Una mano blanca y fría, blanca como la nieve y como la nieve fría, tocó su mano. Y sintió Augusto qu...\n",
      "True Label: 0\n",
      "Predicted: 1\n",
      "\n",
      "Text: nada!--rugió el Capitán con suma nobleza.--¡Pues no faltaba más, estando yo en el mundo![290]--Ciert...\n",
      "True Label: 0\n",
      "Predicted: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = [get_prediction(model_12k_blip_finetuning_binary, text) for text in texts]\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "class_report = classification_report(true_labels, predictions)\n",
    "\n",
    "# Display results\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Optional: Display predictions alongside texts\n",
    "print(\"\\nSample Predictions:\")\n",
    "for text, true_label, pred in zip(texts[:5], true_labels[:5], predictions[:5]):\n",
    "    print(f\"\\nText: {text[:100]}...\")  # Show first 100 chars\n",
    "    print(f\"True Label: {true_label}\")\n",
    "    print(f\"Predicted: {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metrics on evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Results for finetuning_bert (binary):\n",
      "--------------------------------------------------\n",
      "eval_loss: 0.6977542638778687\n",
      "eval_accuracy: 0.4952170713760118\n",
      "eval_f1_score: 0.6624015748031497\n",
      "eval_f1_score_micro: 0.4952170713760118\n",
      "eval_recall: 1.0\n",
      "eval_runtime: 3.7709\n",
      "eval_samples_per_second: 360.39\n",
      "eval_steps_per_second: 45.082\n",
      "epoch: 0.3368214519293656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\binary\\evaluation\\finetuning_bert_captionning_blip_12225_validation_results.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metrics on testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Results for finetuning_bert (binary):\n",
      "--------------------------------------------------\n",
      "eval_loss: 0.6942014098167419\n",
      "eval_accuracy: 0.5145997938852628\n",
      "eval_f1_score: 0.6795191653436153\n",
      "eval_f1_score_micro: 0.5145997938852628\n",
      "eval_recall: 1.0\n",
      "eval_runtime: 16.1916\n",
      "eval_samples_per_second: 359.568\n",
      "eval_steps_per_second: 44.961\n",
      "epoch: 0.3368214519293656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\binary\\testing\\finetuning_bert_binary_captionning_blip_12225_test_evaluation.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_lstm(classifier, text: str):\n",
    "    \"\"\"\n",
    "    Generates binary predictions for text using a BERT-tokenized LSTM classifier.\n",
    "    \n",
    "    Args:\n",
    "        classifier: LSTM classifier with encode_data and predict methods.\n",
    "                   Must accept BERT tokenized inputs and return probabilities.\n",
    "        text (str): Raw text input to classify.\n",
    "    \n",
    "    Returns:\n",
    "        int: Binary prediction (0 or 1) based on 0.5 threshold.\n",
    "    \n",
    "    Notes:\n",
    "        - Uses bert-large-cased tokenizer\n",
    "        - Truncates/pads sequences to 64 tokens\n",
    "        - Returns numpy array format with a dummy label\n",
    "        - Assumes classifier.encode_data() returns tuple of (input_ids, attention_mask, token_type_ids)\n",
    "        - Assumes classifier.predict() returns probability scores\n",
    "        \n",
    "    Workflow:\n",
    "        1. Tokenizes input text using BERT tokenizer\n",
    "        2. Formats tokens into required structure with dummy label\n",
    "        3. Encodes data using classifier's encode_data method\n",
    "        4. Gets probability predictions\n",
    "        5. Applies 0.5 threshold to get binary prediction\n",
    "        \n",
    "    Example:\n",
    "        >>> prediction = get_prediction_lstm(lstm_classifier, \"Sample text to classify\")\n",
    "        >>> print(prediction)  # Prints 0 or 1\n",
    "        1\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-large-cased')\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=64,\n",
    "        return_tensors='np'\n",
    "    )\n",
    "    \n",
    "    # Create properly formatted input\n",
    "    single_item = [{\n",
    "        'input_ids': tokens['input_ids'][0],\n",
    "        'attention_mask': tokens['attention_mask'][0],\n",
    "        'token_type_ids': tokens['token_type_ids'][0],\n",
    "        'labels': 0  # dummy label\n",
    "    }]\n",
    "    \n",
    "    # Get encoded input and predictions\n",
    "    encoded_input = classifier.encode_data(single_item)\n",
    "    probs = classifier.predict(encoded_input[0], encoded_input[1], encoded_input[2])\n",
    "    \n",
    "    return (probs > 0.5).astype(int)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datasets import DatasetDict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizer(name_or_path='bert-large-cased', vocab_size=28996, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'nivel_risa', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 19417\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'nivel_risa', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 12231\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample_1 = final_split['train']\n",
    "train_sample_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'nivel_risa', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 1360\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_sample_1 = final_split['validation']\n",
    "validation_sample_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertModel\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert_model = TFBertModel.from_pretrained('bert-large-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARCHITECTURE 1 - LSTM 2 One Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import load_model\n",
    "from models.encoder_only_lstm import LSTM_1Classifier, LSTM_2Classifier\n",
    "from keras.utils import custom_object_scope\n",
    "\n",
    "# Initialize classifier\n",
    "classifier_lstm2_binary = LSTM_2Classifier(bert_path='bert-large-cased', max_length=64)\n",
    "\n",
    "# Get the custom BertLayer class\n",
    "BertLayer = classifier_lstm2_binary.BertLayer\n",
    "\n",
    "# Load the model with custom_object_scope\n",
    "with custom_object_scope({'BertLayer': BertLayer}):\n",
    "    classifier_lstm2_binary.model = load_model('models/binary/lstm2_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 8s 8s/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 422ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "Confusion Matrix:\n",
      "[[20  0]\n",
      " [ 0 20]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        40\n",
      "   macro avg       1.00      1.00      1.00        40\n",
      "weighted avg       1.00      1.00      1.00        40\n",
      "\n",
      "\n",
      "Sample Predictions:\n",
      "\n",
      "Text: para María de la Piedad una existencia de abandonada. De repente, todo en torno de ella --la enferme...\n",
      "True Label: 0\n",
      "Predicted: [0]\n",
      "\n",
      "Text: Hospital General y un cesante, a quien llamaban don Cleto. Don Cleto Meana era el filósofo de la cas...\n",
      "True Label: 0\n",
      "Predicted: [0]\n",
      "\n",
      "Text: ví hecho minero, Mas nunca tuvo el pobre mina buena: Busquemos una agora en otro canto, Que ya cansa...\n",
      "True Label: 0\n",
      "Predicted: [0]\n",
      "\n",
      "Text: Una mano blanca y fría, blanca como la nieve y como la nieve fría, tocó su mano. Y sintió Augusto qu...\n",
      "True Label: 0\n",
      "Predicted: [0]\n",
      "\n",
      "Text: nada!--rugió el Capitán con suma nobleza.--¡Pues no faltaba más, estando yo en el mundo![290]--Ciert...\n",
      "True Label: 0\n",
      "Predicted: [0]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = [get_prediction_lstm(classifier_lstm2_binary, text) for text in texts]\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "class_report = classification_report(true_labels, predictions)\n",
    "\n",
    "# Display results\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Display sample predictions\n",
    "print(\"\\nSample Predictions:\")\n",
    "for text, true_label, pred in zip(texts[:5], true_labels[:5], predictions[:5]):\n",
    "    print(f\"\\nText: {text[:100]}...\")  # Show first 100 chars\n",
    "    print(f\"True Label: {true_label}\")\n",
    "    print(f\"Predicted: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Results for lstm2 (binary):\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.9895\n",
      "F1 Score: 0.9897\n",
      "Recall: 0.9862\n",
      "\n",
      "Debug Information:\n",
      "Unique predicted classes: [0 1]\n",
      "Unique true labels: [0 1]\n",
      "Number of samples: 5826\n",
      "\n",
      "Class Distribution:\n",
      "Predicted positives: 2946\n",
      "Predicted negatives: 2880\n",
      "Actual positives: 2967\n",
      "Actual negatives: 2859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\binary\\testing\\lstm2_binary_test_evaluation.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)      [(None, 64)]                 0         []                            \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer  [(None, 64)]                 0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " token_type_ids (InputLayer  [(None, 64)]                 0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bert_layer (BertLayer)      (None, 64, 1024)             3335792   ['input_ids[0][0]',           \n",
      "                                                          64         'attention_mask[0][0]',      \n",
      "                                                                     'token_type_ids[0][0]']      \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, 64, 1024)             0         ['bert_layer[0][0]',          \n",
      "                                                                     'bert_layer[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 64, 2048)             0         ['bert_layer[0][0]',          \n",
      "                                                                     'attention[0][0]']           \n",
      "                                                                                                  \n",
      " bidirectional (Bidirection  (None, 512)                  4720640   ['concatenate[0][0]']         \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    513       ['bidirectional[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 338300417 (1.26 GB)\n",
      "Trainable params: 4721153 (18.01 MB)\n",
      "Non-trainable params: 333579264 (1.24 GB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_lstm2_binary.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Results for lstm2 (binary):\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.9934\n",
      "F1 Score: 0.9936\n",
      "Recall: 0.9929\n",
      "\n",
      "Debug Information:\n",
      "Number of validation samples: 1360\n",
      "Unique predicted classes: [0 1]\n",
      "Unique true labels: [0 1]\n",
      "\n",
      "Class Distribution:\n",
      "Predicted positives: 704\n",
      "Predicted negatives: 656\n",
      "Actual positives: 705\n",
      "Actual negatives: 655\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\binary\\evaluation\\lstm2_validation_results.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture 2 - LSTM 1 Two layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Initialize classifier\n",
    "classifier_lstm1_binary = LSTM_1Classifier(bert_path='bert-large-cased', max_length=64)\n",
    "\n",
    "# Get the custom BertLayer class\n",
    "BertLayer = classifier_lstm1_binary.BertLayer\n",
    "\n",
    "# Load the model with custom_object_scope\n",
    "with custom_object_scope({'BertLayer': BertLayer}):\n",
    "    classifier_lstm1_binary.model = load_model('models/binary/lstm1_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 8s 8s/step\n",
      "1/1 [==============================] - 0s 462ms/step\n",
      "1/1 [==============================] - 0s 403ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 435ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 408ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 449ms/step\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 478ms/step\n",
      "1/1 [==============================] - 0s 422ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 426ms/step\n",
      "1/1 [==============================] - 0s 450ms/step\n",
      "1/1 [==============================] - 0s 422ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "Confusion Matrix:\n",
      "[[20  0]\n",
      " [ 0 20]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        40\n",
      "   macro avg       1.00      1.00      1.00        40\n",
      "weighted avg       1.00      1.00      1.00        40\n",
      "\n",
      "\n",
      "Sample Predictions:\n",
      "\n",
      "Text: para María de la Piedad una existencia de abandonada. De repente, todo en torno de ella --la enferme...\n",
      "True Label: 0\n",
      "Predicted: [0]\n",
      "\n",
      "Text: Hospital General y un cesante, a quien llamaban don Cleto. Don Cleto Meana era el filósofo de la cas...\n",
      "True Label: 0\n",
      "Predicted: [0]\n",
      "\n",
      "Text: ví hecho minero, Mas nunca tuvo el pobre mina buena: Busquemos una agora en otro canto, Que ya cansa...\n",
      "True Label: 0\n",
      "Predicted: [0]\n",
      "\n",
      "Text: Una mano blanca y fría, blanca como la nieve y como la nieve fría, tocó su mano. Y sintió Augusto qu...\n",
      "True Label: 0\n",
      "Predicted: [0]\n",
      "\n",
      "Text: nada!--rugió el Capitán con suma nobleza.--¡Pues no faltaba más, estando yo en el mundo![290]--Ciert...\n",
      "True Label: 0\n",
      "Predicted: [0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make predictions\n",
    "predictions = [get_prediction_lstm(classifier_lstm1_binary, text) for text in texts]\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "class_report = classification_report(true_labels, predictions)\n",
    "\n",
    "# Display results\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Display sample predictions\n",
    "print(\"\\nSample Predictions:\")\n",
    "for text, true_label, pred in zip(texts[:5], true_labels[:5], predictions[:5]):\n",
    "    print(f\"\\nText: {text[:100]}...\")  # Show first 100 chars\n",
    "    print(f\"True Label: {true_label}\")\n",
    "    print(f\"Predicted: {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results on testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Results for lstm1 (binary):\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.9827\n",
      "F1 Score: 0.9827\n",
      "Recall: 0.9690\n",
      "\n",
      "Debug Information:\n",
      "Unique predicted classes: [0 1]\n",
      "Unique true labels: [0 1]\n",
      "Number of samples: 5826\n",
      "\n",
      "Class Distribution:\n",
      "Predicted positives: 2884\n",
      "Predicted negatives: 2942\n",
      "Actual positives: 2967\n",
      "Actual negatives: 2859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\binary\\testing\\lstm1_binary_test_evaluation.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results on evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Results for lstm1 (binary):\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.9926\n",
      "F1 Score: 0.9929\n",
      "Recall: 0.9872\n",
      "\n",
      "Debug Information:\n",
      "Number of validation samples: 1360\n",
      "Unique predicted classes: [0 1]\n",
      "Unique true labels: [0 1]\n",
      "\n",
      "Class Distribution:\n",
      "Predicted positives: 697\n",
      "Predicted negatives: 663\n",
      "Actual positives: 705\n",
      "Actual negatives: 655\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\binary\\evaluation\\lstm1_validation_results.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)      [(None, 64)]                 0         []                            \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer  [(None, 64)]                 0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " token_type_ids (InputLayer  [(None, 64)]                 0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bert_layer (BertLayer)      (None, 64, 1024)             3335792   ['input_ids[0][0]',           \n",
      "                                                          64         'attention_mask[0][0]',      \n",
      "                                                                     'token_type_ids[0][0]']      \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, 64, 1024)             0         ['bert_layer[0][0]',          \n",
      "                                                                     'bert_layer[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 64, 2048)             0         ['bert_layer[0][0]',          \n",
      "                                                                     'attention[0][0]']           \n",
      "                                                                                                  \n",
      " bidirectional (Bidirection  (None, 64, 512)              4720640   ['concatenate[0][0]']         \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " dropout_73 (Dropout)        (None, 64, 512)              0         ['bidirectional[0][0]']       \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirecti  (None, 512)                  1574912   ['dropout_73[0][0]']          \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    513       ['bidirectional_1[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 339875329 (1.27 GB)\n",
      "Trainable params: 6296065 (24.02 MB)\n",
      "Non-trainable params: 333579264 (1.24 GB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_lstm1_binary.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multifactorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Temp\\ipykernel_43424\\2212130348.py:43: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = df.groupby(column).apply(lambda x: x.sample(n=num_samples, random_state=42))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Function to sample 20 rows per class\n",
    "def sample_dataset(dataset, column, num_samples=20):\n",
    "    \"\"\"\n",
    "    Creates a balanced dataset by sampling an equal number of rows from each class category.\n",
    "    \n",
    "    Args:\n",
    "        dataset (Union[Dataset, pd.DataFrame]): Input dataset, can be either a Hugging Face Dataset \n",
    "            or pandas DataFrame.\n",
    "        column (str): Name of the column containing class labels to stratify by.\n",
    "        num_samples (int, optional): Number of samples to draw from each unique class. \n",
    "            Defaults to 20.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: A balanced DataFrame containing the sampled data with:\n",
    "            - Equal number of samples per class\n",
    "            - Reset index\n",
    "            - All original columns preserved\n",
    "    \n",
    "    Notes:\n",
    "        - Uses random_state=42 for reproducible sampling\n",
    "        - If a class has fewer samples than num_samples, will raise ValueError\n",
    "        - Automatically converts Hugging Face Dataset to pandas DataFrame if needed\n",
    "        - Returns a new DataFrame; does not modify the input dataset\n",
    "    \n",
    "    Example:\n",
    "        >>> # For binary classification\n",
    "        >>> data = pd.DataFrame({'text': ['a', 'b', 'c', 'd'], 'label': [0, 0, 1, 1]})\n",
    "        >>> balanced = sample_dataset(data, column='label', num_samples=1)\n",
    "        >>> print(balanced['label'].value_counts())\n",
    "        0    1\n",
    "        1    1\n",
    "    \"\"\"\n",
    "    # Convert Dataset to a pandas DataFrame if necessary\n",
    "    if isinstance(dataset, Dataset):\n",
    "        df = dataset.to_pandas()\n",
    "    else:\n",
    "        df = dataset\n",
    "\n",
    "    sampled_df = df.groupby(column).apply(lambda x: x.sample(n=num_samples, random_state=42))\n",
    "    return sampled_df.reset_index(drop=True)\n",
    "\n",
    "# Sample 20 rows per class\n",
    "sampled_data = sample_dataset(dataset, column=\"nivel_risa\", num_samples=20)\n",
    "\n",
    "# Extract texts and labels\n",
    "texts = sampled_data[\"text\"].tolist()  # Assuming the column with text data is 'text'\n",
    "true_labels = sampled_data[\"nivel_risa\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>nivel_risa</th>\n",
       "      <th>nivel_risa_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No hay vuelta que darle dijo el que dormia en ...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La que me gusta se ha quitado la foto de perfi...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Que haces cuando ves un negro desangrarse en l...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>El profesor de la materia de relleno: De mañan...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Imagen de Bob Esponja vestido como un ganster,...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>¿Qué le dice una pizza a otra pizza en Año Nue...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>¿Qué hace un esquiador cuando quiere contar un...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>¿Cuál es el animal más rápido en el atletismo?...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>- ¿Qué hace un sombrero en una clase de histor...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>¿Qué hace una hiena en la escuela? ¡Ríe en tod...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  nivel_risa  \\\n",
       "0   No hay vuelta que darle dijo el que dormia en ...           4   \n",
       "1   La que me gusta se ha quitado la foto de perfi...           4   \n",
       "2   Que haces cuando ves un negro desangrarse en l...           4   \n",
       "3   El profesor de la materia de relleno: De mañan...           4   \n",
       "4   Imagen de Bob Esponja vestido como un ganster,...           4   \n",
       "..                                                ...         ...   \n",
       "95  ¿Qué le dice una pizza a otra pizza en Año Nue...           1   \n",
       "96  ¿Qué hace un esquiador cuando quiere contar un...           1   \n",
       "97  ¿Cuál es el animal más rápido en el atletismo?...           1   \n",
       "98  - ¿Qué hace un sombrero en una clase de histor...           1   \n",
       "99  ¿Qué hace una hiena en la escuela? ¡Ríe en tod...           1   \n",
       "\n",
       "    nivel_risa_encoded  \n",
       "0                    3  \n",
       "1                    3  \n",
       "2                    3  \n",
       "3                    3  \n",
       "4                    3  \n",
       "..                 ...  \n",
       "95                   0  \n",
       "96                   0  \n",
       "97                   0  \n",
       "98                   0  \n",
       "99                   0  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data.to_csv(\"data/balanced_sample_multifactorial.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset, label_encoder = combine_dataframes(\n",
    "    \"data/classification/complete_dataset_chistes.csv\",\n",
    "    \"data/classification/data_with_no_humour.csv\",one_hot=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validation_test_split = encoded_dataset.train_test_split(test_size=0.3, seed=42)\n",
    "train_validation_split = train_validation_test_split['train'].train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "final_split = DatasetDict({\n",
    "    'train': train_validation_split['train'],\n",
    "    'validation': train_validation_split['test'],\n",
    "    'test': train_validation_test_split['test']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'nivel_risa', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 12231\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'nivel_risa', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1360\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'nivel_risa', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 5826\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = final_split['train'].shuffle(seed=42).select(range(500))\n",
    "validation_sample = final_split['validation'].shuffle(seed=42).select(range(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41388225411745a5a1b313bc4427a761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9933 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_dataset = dataset.map(\n",
    "    lambda x: tokenize_function(x, column='nivel_risa_encoded'), \n",
    "    batched=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nivel_risa categories: 5\n"
     ]
    }
   ],
   "source": [
    "num_labels = len(label_encoder.classes_)\n",
    "print(f\"Number of nivel_risa categories: {num_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-large-cased', \n",
    "    num_labels=num_labels  # Set number of labels to match nivel_risa categories\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_multifactorial(binary:bool=True, encoder=None):\n",
    "    \"\"\"\n",
    "    Compute evaluation metrics for model predictions.\n",
    "    \n",
    "    Args:\n",
    "        binary (bool): Whether to compute metrics for binary classification\n",
    "        encoder: LabelEncoder instance for non-binary classification\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing metrics\n",
    "    \"\"\"\n",
    "    def compute(eval_pred):\n",
    "        try:\n",
    "            if binary:\n",
    "                predictions, labels = eval_pred\n",
    "                predictions = np.argmax(predictions, axis=1)\n",
    "                return {\"accuracy\": accuracy_score(labels, predictions)}\n",
    "            else:\n",
    "                predictions, labels = eval_pred\n",
    "                predictions = np.argmax(predictions, axis=1)\n",
    "                accuracy = accuracy_score(labels, predictions)\n",
    "                \n",
    "                # Use the passed encoder\n",
    "                pred_original = encoder.inverse_transform(predictions)\n",
    "                labels_original = encoder.inverse_transform(labels)\n",
    "                \n",
    "                # Convert lists to strings to avoid TensorBoard warning\n",
    "                pred_examples = ','.join(map(str, pred_original[:5]))\n",
    "                label_examples = ','.join(map(str, labels_original[:5]))\n",
    "                \n",
    "                return {\n",
    "                    \"accuracy\": accuracy,\n",
    "                    \"predictions_sample\": pred_examples,  # Now a string\n",
    "                    \"true_labels_sample\": label_examples,  # Now a string\n",
    "                    # Add some additional scalar metrics\n",
    "                    \"pred_mean\": predictions.mean(),\n",
    "                    \"pred_std\": predictions.std(),\n",
    "                }\n",
    "                    \n",
    "        except Exception as e:\n",
    "                print(f\"Error on compute_metrics: {e}\")\n",
    "    \n",
    "    return compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./finetuning_multifactorial_model',\n",
    "    evaluation_strategy=\"steps\",\n",
    "    learning_rate=5.0e-05,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    use_cpu=False,\n",
    "    fp16=True,\n",
    "    save_total_limit=1,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_sample,\n",
    "    eval_dataset=validation_sample,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics_multifactorial(encoder=label_encoder),  \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['para María de la Piedad una existencia de abandonada. De repente, todo en torno de ella --la enfermedad del marido, achaques de los hijos, tristezas de sus días, la costura--',\n",
       " 'Hospital General y un cesante, a quien llamaban don Cleto. Don Cleto Meana era el filósofo de la casa, era un hombre bien educado y culto, que había caído en',\n",
       " 'ví hecho minero, Mas nunca tuvo el pobre mina buena: Busquemos una agora en otro canto, Que ya cansa decir en este tanto. CANTO SEXTO. _Viene Obispo al Paraguay. Muere',\n",
       " 'Una mano blanca y fría, blanca como la nieve y como la nieve fría, tocó su mano. Y sintió Augusto que se derramaba por su ser todo como un fluido',\n",
       " 'nada!--rugió el Capitán con suma nobleza.--¡Pues no faltaba más, estando yo en el mundo![290]--Cierto es que el pobre Álvaro...--yo no quiero quitarle su mérito,--en cuanto supo[291] la fatal ocurrencia se',\n",
       " 'aquí estuvieres, pídelo; que por este buen servicio que me has hecho, se hará por ti. Yo, como no esperaba tal ganancia, lleno de placer tomé mis ducados resplandecientes, y',\n",
       " 'empacadas. Pedimos _té_, que genuínamente se pronuncia _Cham_: tendió el sirviente el mantel y nos pusimos en tren de hacer la libacion Asiática. Colocaron en la mesa panecillos y dulces:',\n",
       " 'pasarlo muy mal si uno de ellos le acertaba; mas los denuestos continuaron a más y mejor, mientras se iba aplacando lentamente la cólera. --¡El demonio del capellanzote!... ¡Si pensará',\n",
       " 'se quería hacer. Yo, que deseaba mucho saber lo que pasaba acerca de mi muerto, llegueme cuanto pude a la tumba y aun hallé una piedra en que puse los',\n",
       " 'las exequias, y le daremos sepultura. Su duelo toca también a toda la raza de Cadmo; y en punto a justicia a las veces el pueblo muda de pareceres. SEGUNDO',\n",
       " 'multiplicarse y precipitarse los acontecimientos, concluye por carecer de magnitud y hasta de espacio. Un viaje de varios días no acertamos siquiera a concebirlo; una obra lenta nos irrita. Pizarro',\n",
       " 'la esperanza de poder derribar uno o varios combatientes; mientras que el soldado antiguo, sobre todo el conquistador, ahorraba tentativas y daba directo con su espada en el pecho enemigo.',\n",
       " 'los enemigos. Estos son los capitanes de quienes hago memoria por el pronto; mas no te he dicho sino una pequeña parte de las muchas desgracias que nos rodean. ATOSSA',\n",
       " 'las cuales no se ve siempre delante de los ojos una capa flaca y moribunda, en que las noches no se pasan esperando las horas de los remedios... Había sido',\n",
       " 'no es cosa de creer que un hombre solo matase a tres tan valientes mancebos. Por tanto, mi parecer es que la verdad se sepa por cuestión de tormento, porque',\n",
       " 'La lucha de la independencia hizo escuela; en las contiendas fratricidas, el partidario vivió sobre el bien del enemigo, y al fin, la riqueza pública entera desapareció en la vorágine',\n",
       " 'ya cogerla, y acelera sus pasos alargando el hocico, y ésta dudando estar cogida escapa de las mordeduras, y dexa burlada la boca que le va á los alcances; del',\n",
       " 'ponían a peligro de su salud. Entonces lleváronme por medio del teatro los ministros de la justicia como a un carnero que quieren sacrificar, y pusiéronme delante del asiento de',\n",
       " 'bien, solitarios y modestos sus bienes, pocos o muchos, disimuladamente los encubren, y reciamente defienden, y con peligro de su sangre y vida los fortalecen. El mismo negocio que ahora',\n",
       " 'armas y esgrima; hay una diferencia monstruosa que es necesario suplir con una táctica especial. Dice a sus soldados de infantería que omitan los tajos y cuchilladas, y a sus',\n",
       " '¿Qué hace un futbolista después de comerse una pizza? Pedir un cambio porque se siente lleno.',\n",
       " 'Hoy estamos (una gallina) y mañana no se sabe (un sancocho)',\n",
       " 'Una ruleta con temas incomodos como \"conspiraciones,\" \"astrologia,\" \"opiniones no deseadas,\" y \"memes,\" mientras una persona pregunta: \"ÀPor donde empezamos?\"',\n",
       " '¿Qué hace un jugador de Resident Evil después de un susto? ¡Guarda su partida!',\n",
       " '¿Por qué los jugadores de billar son buenos en estrategia? ¡Porque siempre tienen un ángulo!',\n",
       " 'Dos compadres en un bar: - Que le vas a regalar a tu novia de San Valentin? - Un collar. - Que bonito, yo aun la llevo suelta.',\n",
       " '¿Por qué los caballos no viajan en tren? Porque prefieren galopar.',\n",
       " ' ¿Qué le dice un árbol a otro?\\n ¿Qué pasa tronco?\\n',\n",
       " 'Bob Esponja congelado y asustado en una habitacion de hielo.',\n",
       " 'Imagen de Cheems, el famoso meme de perro, acostado con expresion de resignacion. El texto dice \"Jueves\", indicando probablemente el cansancio tipico de mediados de semana.',\n",
       " '¿Qué le dijo un corredor al otro? ¡No te detengas hasta la línea de final!',\n",
       " '¿Cómo se relaja un informático? ¡Con una taza de hacking!',\n",
       " '¿Qué hace un personaje de FIFA cuando quiere bailar? ¡Practica su Celebration!',\n",
       " 'Mamá, en el cole me llaman robot. ¿Y cómo es eso, hijo? Porque siempre sigo órdenes en modo automático.',\n",
       " '¿Por qué los fantasmas del futuro no asustan? ¡Porque ya no tienen batería!',\n",
       " '¿Qué le dice una pizza a otra pizza en Año Nuevo? ¡Feliz año y que nos partan la salsa!',\n",
       " '¿Qué hace un esquiador cuando quiere contar un chiste? Un descenso rápido.',\n",
       " '¿Cuál es el animal más rápido en el atletismo? El chita. ¡Sin duda!',\n",
       " '- ¿Qué hace un sombrero en una clase de historia? - Remonta el tiempo.',\n",
       " '¿Qué hace una hiena en la escuela? ¡Ríe en todos los chistes de la clase!',\n",
       " '- ¡Niños, no juguéis con fuego!\\n...y Fuego se quedo sin amigos',\n",
       " 'Cómo puedes meter 1000 judíos en un vocho??? En el cenicero',\n",
       " '¿Por qué el rey Arturo no va de vacaciones? ¡Porque tiene una mesa redonda todo el año!',\n",
       " 'Un antropólogo está realizando unos estudios en una tribu africana, y es llamado por el jefe de la tribu que le dice muy enfadado:\\n- Venir aquí antropólogo. Haber nacido niño blanco en tribu.\\nEl antropólogo intenta quitarse el muerto de encima y le responde, señalando a un rebaño de ovejas:\\n- Mire jefe, en genética todo es posible. Mire ese rebaño de ovejas blancas, verá usted que entre ellas ha nacido una oveja negra.\\nEl jefe, sofocado, le contesta:\\n- Antropólogo, yo no decir nada de niño blanco. Tú no decir nada de oveja negra...',\n",
       " 'Un perro con una sonrisa picara y una expresion de \"burlona\" con el texto que dice: \"si me vas a clavar algo que no sea el visto\", rodeado de corazones naranjas.',\n",
       " 'Cual es el animal más rápido del planeta?  el elefante por qué va en vocho',\n",
       " '¿Por qué las hadas no usan paraguas? ¡Porque siempre están bajo techo encantado!',\n",
       " '—¿Cómo te reconoceré? —Si quieres le digo a mamá que me vaya a recoger ella al colegio, papá. —Sí, mejor.',\n",
       " 'Cuando me hace falta una decima para pasar la materia y no sé si el sistema aproxima: orando.',\n",
       " 'Una captura de pantalla de un titular en ingles que habla sobre una \"piscina de la muerte\" en el fondo del mar. La imagen incluye una burla con una referencia al Hombre Arania.',\n",
       " ' ¿Por qué la ensalada siempre está fresca?\\n Porque siempre se viste bien.\\n',\n",
       " 'Yo creyendo que tengo mi semestre bajo control. Mi semestre: una foto de un hombre cogiendo una botella por su tapa y la botella cayendo y solo se le queda la tapa en la mano.',\n",
       " 'En una representación teatral un hijo le pregunta a su padre:\\n- ¿Por qué le hechas tierra al pirata en los ojos?\\n- Porque el pirata ha gritado: tierra a la vista!',\n",
       " 'Paises donde celebran que eliminaron a brasil porque hace 10 años era gol de yepes: Colombia',\n",
       " 'Un borracho ve a un grupo de \"bautistas\" dentro de un río practicando el rito del Bautismo. \\nSín pénsarselo dos veces, el borrachito entra dando traspiés dentro del agua, se acerca al predicador y se queda a su lado. \\nEntonces el predicador se gira, ve al viejo borracho y le pregunta: \\n-Señor, ¿está usted preparado para encontrar a Jesús? \\nEl borrachito se da la vuelta y dice: \\n-Si, lo estoy. \\nEl predicador entonces sumerge al tipo dentro del agua, lo vuelve a sacar y le pregunta: \\n-¿Ha encontrado a Jesús? \\n-No -responde el borracho. \\nEl predicador lo vuelve a sumergir un poco más de tiempo y cuando lo saca le pregunta: \\n-Y, ahora, hermano, ¿has encontrado a Jesús?. \\n-No – vuelve a responder el borracho. \\nEnfadado, el pastor lo agarra, sumerge la cabeza dentro del agua durante casi un minuto y enojado le pregunta otra vez: \\n-Por la gracia de Dios!!! ¿has encontrado a Jesús ya? \\nEl viejo borracho se seca los ojos y medio ahogado le implora: \\n-No, carajo!!!...pero....está seguro que se cayó por aquí?',\n",
       " '*Niños, comeros el bocadillo de tortilla* Y Tortilla se quedó sin bocadillo.',\n",
       " 'listo para el 3er parcial. Yo: quiero ir a casa.',\n",
       " 'en el restaurante:\\n-¿vino de la casa,señor? \\n-¿y a ti que te importa de donde vengo?',\n",
       " ' ¿Cuál es el colmo de un meteorólogo?\\n No tener tiempo.\\n',\n",
       " '¿Por qué los faraones siempre estaban radiantes? ¡Porque eran iluminaciones históricas!',\n",
       " 'Una imagen de un gatito con los ojos llorosos y un texto que pregunta: \"Komo se desaktiba el modo triste\". Representa un estado emocional triste pero de una manera dulce y exagerada.',\n",
       " ' En qué se parecen una \"boda\" y un \"divorcio\"?\\n\\n - En que en la boda todo es arroz\\n y en el divorcio todo es \"paella\" .\\n',\n",
       " ' ¿Cómo sacas a Superman del agua?\\n Pues oxidado porque es el hombre de acero.\\n',\n",
       " 'Las mujeres que buscan a un hombre detallista, sensible, atento, delicado... deben saber que ese tipo de hombre TAMBIÉN busca hombres.',\n",
       " 'Esto son 2 Leperos en un tren, y uno saca un cigarro y se pone a fumar,en esto que el amigo le pregunta:\\n-¿Tienes mas?\\nDespues de 20 minutos de pensar,el otro lepero dice:\\n-No,TENGO MENOS',\n",
       " 'Sabes con que perdió un bebé boxeador? Con qué So Bas está',\n",
       " ' - María, dime la verdad, cuantos años tienes?\\n\\n - 25.\\n - Pero si me dijiste 25 el año pasado!\\n- A ver si te piensas que soy de esas que primero dice una cosa y después otra.\\n',\n",
       " '—Alto, control de drogas  —Gracias agente, no me fío ni un pelo de mi camello.',\n",
       " '-Papa, por qué envuelves al hamster en cinta aislante?? -Para que cuando le meta la polla no estalle hijo.',\n",
       " 'Cuando estoy hablando con un colombiana y me empieza a insultar (triple mil hijueputa …. Treinta ….). Yo llevando una calculadora en mi mano',\n",
       " '¿Como se dice en aleman autobus? ...subenpagenestrugenbagen',\n",
       " '¿Quién invento las fracciones? \\n- Enrique octavo',\n",
       " 'Esta el esposo despidiéndose de su esposa para irse a trabajar. Le dice a su esposa:\\n- Mi amor te alistas en la noche porque te voy a dar asta por las orejas. \\nY ella asustada contesta. \\n- Ayy mi amor por ahí no porque me quedo sorda\\nY el responde.\\n- Mmmmm no te has quedado muda',\n",
       " '—¿Me podría poner las sobras para el perro, por favor? — ¡Bieeeen, Papá va a comprar un peeerrrooo!',\n",
       " ' ¿Qué le dice un semáforo a otro?\\n No me mires, me estoy cambiando.\\n',\n",
       " ' – ¿Usted domina el inglés?\\n\\n – Hombre, si es bajito y se deja\\n',\n",
       " ' ¿Qué dice una cereza mirándose al espejo?\\n ¿Ceré eza?.\\n',\n",
       " '- Cual es el animal que a la vez son dos animales?\\n- El gato, porque es gato y araña.\\n- No, tu hermana, porque es zorra y cobra.',\n",
       " 'En la calle:\\n- Usted es un gilipollas, un idiota y un imbécil!\\n- ¡Oiga, oiga!, ¿eso son bromas o insultos?\\n- ¡Insultos!\\n- Ah, bueno, es que no aguanto las bromas de nadie.',\n",
       " '- Oye, ¿Pero a ti no te cae mal tu suegra?\\n- Si.\\n-Y entonces, ¿Por qué llevas su foto en la pitillera?\\n- Es que estoy intentando dejar de fumar.',\n",
       " 'No hay vuelta que darle dijo el que dormia en un muro',\n",
       " 'La que me gusta se ha quitado la foto de perfil y no le llegan los mensajes, creo que le gusto',\n",
       " 'Que haces cuando ves un negro desangrarse en la calle? Dejar de reír y pegarle otro tiro.',\n",
       " 'El profesor de la materia de relleno: De mañana un informe de lecturs del pdf que mandé - El profesor que tiene la materia del nombre de la carrera: qué sección es esta?',\n",
       " 'Imagen de Bob Esponja vestido como un ganster, con un sombrero verde, traje a rayas y sosteniendo un abanico de billetes, luciendo relojes y joyas.',\n",
       " 'Llegó un pastor alemán... ... y nadie entendió la misa.',\n",
       " 'Yo: Había una vez un osito que fue a la plaza, se subió a la hamaca y se cayó. Les dio gracia? Ustedes: No Yo: Al osito tampoco',\n",
       " 'Un hombre mirando con incredulidad al texto que describe la traicion de un companiero de videojuego que desmantela un clan al ser ascendido a co-lider.',\n",
       " 'Un asiento de auto lleno de objetos variados: un telefono, un bote de te helado \"Twisted Tea\", un frasco de vitamina C, un desinfectante de manos, un arma de fuego con peluca rubia encima, un vibrador p\\x9crpura y otros objetos. El mensaje transmite humor sobre estar preparado para cualquier eventualidad de manera absurda.',\n",
       " ' ¿Cómo llamas a un niño sin amigos?\\n Uno solo.\\n',\n",
       " 'El machismo es gay, es decir tratas mejor a un hombre que a una mujer, te lo quieres coger o que?',\n",
       " 'Cual es la diferencia entre Vinicius y un gorila? Que el gorila no se ilusiona tan fácil',\n",
       " 'Un meme donde un personaje animado con una expresion seria observa a alguien que prefiere jugar baloncesto en lugar de un juego tradicional llamado \"Indian booty bumping\".',\n",
       " 'Un perro mordiendo un zapato que cubre su hocico, dandole la apariencia de un ornitorrinco.',\n",
       " ' ¿Cuál es el plan de pensiones de un asesino en serie?\\n Matricularse en un curso de gerontología.\\n',\n",
       " ' ¿Qué tiene en común un bebé y una sandía?\\n Que los dos son blancos por dentro.\\n',\n",
       " '¿Como se dice suegra en Ruso? STORBA',\n",
       " ' ¿Cuál es la diferencia entre un mexicano y un ninja?\\n El ninja puede saltar muros sin lastimarse.\\n',\n",
       " 'Un cachorro disfrazado de bruja con texto: \"Dulce o yo?\" y alguien respondiendo: \"JAJAJAJA DULCES\".',\n",
       " ' ¿Por qué el CEO de Enron se suicidó?\\n Porque no quería pagar la luz.\\n',\n",
       " \"Una escena de entrevista de trabajo, utilizando una pintura renacentista donde alguien responde ÒI've always been passionate about not starving to deathÓ, resaltando la respuesta ironica sobre las necesidades basicas.\",\n",
       " 'Un perro Shiba Inu visto desde abajo, con una expresion seria y el texto \"Hey, you left me on read haha...\", expresando frustracion comica.',\n",
       " ' ¿Cuál es la diferencia entre un gay y un sacerdote?\\n Que el sacerdote no se come a los niños.\\n',\n",
       " ' ¿Sabes por qué los niños con cáncer no pueden jugar en los parques?\\n Porque los perros se los comen.\\n',\n",
       " 'Cuando tengo problemas: Mi problema con los exclusivos Cuando no tengo problemas: Por qué Mario funciona y las otras mascota no?',\n",
       " ' ¿Por qué las feministas no pueden ir a la playa?\\n Porque siempre quieren hacer olas.\\n',\n",
       " ' ¿Cuál es el plan de pensiones de un mexicano?\\n Morir joven.\\n',\n",
       " ' ¿Qué es lo que más le gusta a una mujer golpeada?\\n Nada, porque ya es sorda.\\n',\n",
       " ' ¿Cuál es el objeto favorito de un caníbal?\\n El tenedor.\\n',\n",
       " ' ¿Qué es lo peor de tener sexo con una adolescente?\\n Tener que limpiarle la silla de ruedas después.\\n',\n",
       " ' ¿Por qué los niños con cáncer nunca juegan a las escondidas?\\n Porque a nadie le gusta buscarlos.\\n',\n",
       " ' ¿Qué es lo más divertido de tener un bebé con síndrome de Down?\\n Que nunca vas a tener que preocuparte por que te lo roben.\\n',\n",
       " 'Insultos que tendrán más peso en generaciones futuras: Tu papá tenía una pagina de memes',\n",
       " ' ¿Cuál es la diferencia entre una prostituta y un objeto sexual?\\n Uno es un objeto que se puede comprar y vender, y el otro es un objeto sexual.\\n',\n",
       " 'No importa el tamaño del pájaro sino que tan duro le des a la cerda.-Angry birds',\n",
       " ' ¿Cuál es el regalo perfecto para un amigo que está pasando por un duelo?\\n Un paquete de pañuelos y una tarjeta que dice \"Lo siento, pero no tanto\".\\n',\n",
       " 'Una ilustracion fantasiosa de un herrero musculoso que parece estar afilando una espada mientras un mono esta sentado con un aire de resignacion, aniadiendo un toque absurdo.',\n",
       " ' ¿Cómo se llama un niño judío con cáncer?\\n Ceniza.\\n',\n",
       " ' ¿Por qué las mujeres no pueden hacer chistes de humor negro?\\n Porque no saben lo que es gracioso hasta que se lo explican tres veces.\\n',\n",
       " ' ¿Qué hace una abuela en una montaña rusa?\\n Recolectar las dentaduras postizas que se les caen a los demás pasajeros.\\n']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model trained with 1000 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from models.finetuning import MultifactorialFineTuning\n",
    "\n",
    "# Initialize the class (you'll need to specify num_labels)\n",
    "model_1k_gpt = MultifactorialFineTuning(num_labels=6)  # Since it's a multifactorial model with 6 classes\n",
    "\n",
    "# Load the saved model\n",
    "model_path = \"models/multifactorial/complete_dataset_chistes_finetuning_multifactorial_model_1000_300\"\n",
    "model_1k_gpt.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      1.00      0.29        20\n",
      "           1       0.00      0.00      0.00        20\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.00      0.00      0.00        20\n",
      "           4       0.00      0.00      0.00        20\n",
      "           5       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.17       120\n",
      "   macro avg       0.03      0.17      0.05       120\n",
      "weighted avg       0.03      0.17      0.05       120\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = [np.argmax(model_1k_gpt.predict(text)) for text in texts]\n",
    "\n",
    "conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "# Display results\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Optionally, print a classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results on evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Results for finetuning_bert (multifactorial):\n",
      "--------------------------------------------------\n",
      "eval_loss: 1.3677188158035278\n",
      "eval_accuracy: 0.48161764705882354\n",
      "eval_f1_score: 0.3131112246387389\n",
      "eval_f1_score_micro: 0.48161764705882354\n",
      "eval_recall: 0.48161764705882354\n",
      "eval_predictions_sample: 0,0,0,0,0\n",
      "eval_true_labels_sample: 0,0,3,3,0\n",
      "eval_pred_mean: 0.0\n",
      "eval_pred_std: 0.0\n",
      "eval_runtime: 3.281\n",
      "eval_samples_per_second: 414.504\n",
      "eval_steps_per_second: 51.813\n",
      "epoch: 4.12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\multifactorial\\evaluation\\finetuning_bert_complete_dataset_chistes_1000_validation_results.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results on test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Results for finetuning_bert (multifactorial):\n",
      "--------------------------------------------------\n",
      "eval_loss: 1.3475522994995117\n",
      "eval_accuracy: 0.49073120494335737\n",
      "eval_f1_score: 0.32308589866046256\n",
      "eval_f1_score_micro: 0.49073120494335737\n",
      "eval_recall: 0.49073120494335737\n",
      "eval_predictions_sample: 0,0,0,0,0\n",
      "eval_true_labels_sample: 2,0,1,0,3\n",
      "eval_pred_mean: 0.0\n",
      "eval_pred_std: 0.0\n",
      "eval_runtime: 14.0747\n",
      "eval_samples_per_second: 413.934\n",
      "eval_steps_per_second: 51.795\n",
      "epoch: 4.12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\multifactorial\\testing\\finetuning_bert_multifactorial_complete_dataset_chistes_1000_test_evaluation.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model trained with 5000 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from models.finetuning import MultifactorialFineTuning\n",
    "\n",
    "# Initialize the class (you'll need to specify num_labels)\n",
    "model_5k_gpt = MultifactorialFineTuning(num_labels=6)  # Since it's a multifactorial model with 6 classes\n",
    "\n",
    "# Load the saved model\n",
    "model_path = \"models/multifactorial/complete_dataset_chistes_finetuning_multifactorial_model_5000_300\"\n",
    "model_5k_gpt.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      1.00      0.29        20\n",
      "           1       0.00      0.00      0.00        20\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.00      0.00      0.00        20\n",
      "           4       0.00      0.00      0.00        20\n",
      "           5       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.17       120\n",
      "   macro avg       0.03      0.17      0.05       120\n",
      "weighted avg       0.03      0.17      0.05       120\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = [np.argmax(model_5k_gpt.predict(text)) for text in texts]\n",
    "\n",
    "conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "# Display results\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Optionally, print a classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results on evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Results for finetuning_bert (multifactorial):\n",
      "--------------------------------------------------\n",
      "eval_loss: 1.3914062976837158\n",
      "eval_accuracy: 0.48161764705882354\n",
      "eval_f1_score: 0.3131112246387389\n",
      "eval_f1_score_micro: 0.48161764705882354\n",
      "eval_recall: 0.48161764705882354\n",
      "eval_predictions_sample: 0,0,0,0,0\n",
      "eval_true_labels_sample: 0,0,3,3,0\n",
      "eval_pred_mean: 0.0\n",
      "eval_pred_std: 0.0\n",
      "eval_runtime: 3.2542\n",
      "eval_samples_per_second: 417.925\n",
      "eval_steps_per_second: 52.241\n",
      "epoch: 1.032\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\multifactorial\\evaluation\\finetuning_bert_complete_dataset_chistes_5000_validation_results.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results on testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Results for finetuning_bert (multifactorial):\n",
      "--------------------------------------------------\n",
      "eval_loss: 1.369434118270874\n",
      "eval_accuracy: 0.49073120494335737\n",
      "eval_f1_score: 0.32308589866046256\n",
      "eval_f1_score_micro: 0.49073120494335737\n",
      "eval_recall: 0.49073120494335737\n",
      "eval_predictions_sample: 0,0,0,0,0\n",
      "eval_true_labels_sample: 2,0,1,0,3\n",
      "eval_pred_mean: 0.0\n",
      "eval_pred_std: 0.0\n",
      "eval_runtime: 13.874\n",
      "eval_samples_per_second: 419.922\n",
      "eval_steps_per_second: 52.544\n",
      "epoch: 1.032\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Path to the file\n",
    "file_path = r\"models\\multifactorial\\testing\\finetuning_bert_multifactorial_complete_dataset_chistes_5000_test_evaluation.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model trained with the whole train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from models.finetuning import MultifactorialFineTuning\n",
    "\n",
    "# Initialize the class (you'll need to specify num_labels)\n",
    "model_12k_gpt_finetuning_multifactorial = MultifactorialFineTuning(num_labels=6)  # Since it's a multifactorial model with 6 classes\n",
    "\n",
    "# Load the saved model\n",
    "model_path = \"models/multifactorial/complete_dataset_chistes_finetuning_multifactorial_model_12231_300\"\n",
    "model_12k_gpt_finetuning_multifactorial.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      1.00      0.29        20\n",
      "           1       0.00      0.00      0.00        20\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.00      0.00      0.00        20\n",
      "           4       0.00      0.00      0.00        20\n",
      "           5       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.17       120\n",
      "   macro avg       0.03      0.17      0.05       120\n",
      "weighted avg       0.03      0.17      0.05       120\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = [np.argmax(model_12k_gpt_finetuning_multifactorial.predict(text)) for text in texts]\n",
    "\n",
    "conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "# Display results\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Optionally, print a classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results on evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Results for finetuning_bert (multifactorial):\n",
      "--------------------------------------------------\n",
      "eval_loss: 0.8678938746452332\n",
      "eval_accuracy: 0.5911764705882353\n",
      "eval_f1_score: 0.512193443974577\n",
      "eval_f1_score_micro: 0.5911764705882353\n",
      "eval_recall: 0.5911764705882353\n",
      "eval_predictions_sample: 0,0,3,3,0\n",
      "eval_true_labels_sample: 0,0,3,3,0\n",
      "eval_pred_mean: 1.5198529411764705\n",
      "eval_pred_std: 1.4998686144881637\n",
      "eval_runtime: 3.2495\n",
      "eval_samples_per_second: 418.53\n",
      "eval_steps_per_second: 52.316\n",
      "epoch: 0.3368214519293656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\multifactorial\\evaluation\\finetuning_bert_complete_dataset_chistes_12231_validation_results.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Results for finetuning_bert (multifactorial):\n",
      "--------------------------------------------------\n",
      "eval_loss: 0.8716588020324707\n",
      "eval_accuracy: 0.6071060762100927\n",
      "eval_f1_score: 0.5261256894074561\n",
      "eval_f1_score_micro: 0.6071060762100927\n",
      "eval_recall: 0.6071060762100927\n",
      "eval_predictions_sample: 3,0,3,0,3\n",
      "eval_true_labels_sample: 2,0,1,0,3\n",
      "eval_pred_mean: 1.4871266735324409\n",
      "eval_pred_std: 1.4999447581379988\n",
      "eval_runtime: 13.9483\n",
      "eval_samples_per_second: 417.686\n",
      "eval_steps_per_second: 52.264\n",
      "epoch: 0.3368214519293656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\multifactorial\\testing\\finetuning_bert_multifactorial_complete_dataset_chistes_12231_test_evaluation.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning captioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from models.finetuning import MultifactorialFineTuning\n",
    "\n",
    "# Initialize the class (you'll need to specify num_labels)\n",
    "model_12k_VIT_finetuning_multifactorial = MultifactorialFineTuning(num_labels=6)  # Since it's a multifactorial model with 6 classes\n",
    "\n",
    "# Load the saved model\n",
    "model_path = \"models/multifactorial/captionning_vlt_finetuning_multifactorial_model_12225_300\"\n",
    "model_12k_VIT_finetuning_multifactorial.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      1.00      0.29        20\n",
      "           1       0.00      0.00      0.00        20\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.00      0.00      0.00        20\n",
      "           4       0.00      0.00      0.00        20\n",
      "           5       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.17       120\n",
      "   macro avg       0.03      0.17      0.05       120\n",
      "weighted avg       0.03      0.17      0.05       120\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = [np.argmax(model_12k_VIT_finetuning_multifactorial.predict(text)) for text in texts]\n",
    "\n",
    "conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "# Display results\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Optionally, print a classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results on evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Results for finetuning_bert (multifactorial):\n",
      "--------------------------------------------------\n",
      "eval_loss: 1.3453768491744995\n",
      "eval_accuracy: 0.5047829286239882\n",
      "eval_f1_score: 0.33866121177120384\n",
      "eval_f1_score_micro: 0.5047829286239882\n",
      "eval_recall: 0.5047829286239882\n",
      "eval_predictions_sample: 0,0,0,0,0\n",
      "eval_true_labels_sample: 2,2,0,0,2\n",
      "eval_pred_mean: 0.0\n",
      "eval_pred_std: 0.0\n",
      "eval_runtime: 3.5247\n",
      "eval_samples_per_second: 385.561\n",
      "eval_steps_per_second: 48.231\n",
      "epoch: 0.3368214519293656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\multifactorial\\evaluation\\finetuning_bert_captionning_vlt_12225_validation_results.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Results for finetuning_bert (multifactorial):\n",
      "--------------------------------------------------\n",
      "eval_loss: 1.366455316543579\n",
      "eval_accuracy: 0.4854002061147372\n",
      "eval_f1_score: 0.31723889511569087\n",
      "eval_f1_score_micro: 0.4854002061147372\n",
      "eval_recall: 0.4854002061147372\n",
      "eval_predictions_sample: 0,0,0,0,0\n",
      "eval_true_labels_sample: 0,2,1,0,3\n",
      "eval_pred_mean: 0.0\n",
      "eval_pred_std: 0.0\n",
      "eval_runtime: 15.037\n",
      "eval_samples_per_second: 387.178\n",
      "eval_steps_per_second: 48.414\n",
      "epoch: 0.3368214519293656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\multifactorial\\testing\\finetuning_bert_multifactorial_captionning_vlt_12225_test_evaluation.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_lstm_multifactorial(classifier, text):\n",
    "    \"\"\"\n",
    "    Get predictions for multifactorial classification\n",
    "    \n",
    "    Args:\n",
    "        classifier: The trained classifier model\n",
    "        text: Input text to classify\n",
    "        \n",
    "    Returns:\n",
    "        int: Predicted class (0-5)\n",
    "    \"\"\"\n",
    "    # Initialize tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-large-cased')\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=64,\n",
    "        return_tensors='np'\n",
    "    )\n",
    "    \n",
    "    # Create properly formatted input\n",
    "    single_item = [{\n",
    "        'input_ids': tokens['input_ids'][0],\n",
    "        'attention_mask': tokens['attention_mask'][0],\n",
    "        'token_type_ids': tokens['token_type_ids'][0],\n",
    "        # For multifactorial, we use nivel_risa_encoded instead of labels\n",
    "        'nivel_risa_encoded': 0  # dummy label, will be ignored for prediction\n",
    "    }]\n",
    "    \n",
    "    # Get inputs only, ignore the encoded labels\n",
    "    input_ids = np.array([item['input_ids'] for item in single_item])\n",
    "    attention_mask = np.array([item['attention_mask'] for item in single_item])\n",
    "    token_type_ids = np.array([item['token_type_ids'] for item in single_item])\n",
    "    \n",
    "    # Make prediction\n",
    "    probs = classifier.predict(input_ids, attention_mask, token_type_ids)\n",
    "    \n",
    "    # Return class with highest probability\n",
    "    return np.argmax(probs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dataset(dataset, num_samples=20):\n",
    "    \"\"\"\n",
    "    Sample equal number of instances from each class, handling empty classes\n",
    "    \n",
    "    Args:\n",
    "        dataset: Input dataset\n",
    "        num_samples: Number of samples per class (default=20)\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Sampled dataset with equal class distribution\n",
    "    \"\"\"\n",
    "    # Convert Dataset to DataFrame if necessary\n",
    "    if not isinstance(dataset, pd.DataFrame):\n",
    "        df = pd.DataFrame(dataset)\n",
    "    else:\n",
    "        df = dataset\n",
    "    \n",
    "    # First check which classes are present\n",
    "    present_classes = df['nivel_risa'].unique()\n",
    "    print(f\"Classes present in dataset: {sorted(present_classes)}\")\n",
    "    print(f\"Class distribution:\\n{df['nivel_risa'].value_counts().sort_index()}\")\n",
    "    \n",
    "    # Sample from each present class\n",
    "    sampled_dfs = []\n",
    "    for class_label in present_classes:\n",
    "        class_data = df[df['nivel_risa'] == class_label]\n",
    "        n_available = len(class_data)\n",
    "        \n",
    "        if n_available == 0:\n",
    "            print(f\"Warning: No samples found for class {class_label}\")\n",
    "            continue\n",
    "            \n",
    "        if n_available >= num_samples:\n",
    "            sampled_class = class_data.sample(n=num_samples, random_state=42)\n",
    "        else:\n",
    "            print(f\"Warning: Only {n_available} samples available for class {class_label}, sampling with replacement\")\n",
    "            sampled_class = class_data.sample(n=num_samples, replace=True, random_state=42)\n",
    "        \n",
    "        sampled_dfs.append(sampled_class)\n",
    "    \n",
    "    if not sampled_dfs:\n",
    "        raise ValueError(\"No valid samples found in any class\")\n",
    "    \n",
    "    # Combine all sampled data\n",
    "    sampled_df = pd.concat(sampled_dfs, ignore_index=True)\n",
    "    print(f\"\\nFinal sampled distribution:\\n{sampled_df['nivel_risa'].value_counts().sort_index()}\")\n",
    "    \n",
    "    return sampled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(classifier, sampled_data):\n",
    "    \"\"\"\n",
    "    Evaluate classifier performance on sampled data\n",
    "    \n",
    "    Args:\n",
    "        classifier: Trained classifier model\n",
    "        sampled_data: DataFrame with sampled data\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (confusion_matrix, classification_report, sample_predictions)\n",
    "    \"\"\"\n",
    "    texts = sampled_data['text'].tolist()\n",
    "    true_labels = sampled_data['nivel_risa'].tolist()\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = []\n",
    "    for i, text in enumerate(texts):\n",
    "        try:\n",
    "            pred = get_prediction_lstm_multifactorial(classifier, text)\n",
    "            predictions.append(pred)\n",
    "            if i < 5:  # Print first few predictions for debugging\n",
    "                print(f\"\\nPrediction {i+1}:\")\n",
    "                print(f\"Text: {text[:100]}...\")\n",
    "                print(f\"True label: {true_labels[i]}\")\n",
    "                print(f\"Predicted: {pred}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error predicting text: {text[:100]}...\")\n",
    "            print(f\"Error details: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if not predictions:\n",
    "        raise ValueError(\"No valid predictions were made\")\n",
    "    \n",
    "    # Calculate metrics\n",
    "    conf_matrix = confusion_matrix(true_labels[:len(predictions)], predictions)\n",
    "    class_report = classification_report(true_labels[:len(predictions)], predictions)\n",
    "    \n",
    "    # Get sample predictions for display\n",
    "    sample_preds = []\n",
    "    for i in range(min(5, len(predictions))):\n",
    "        sample_preds.append({\n",
    "            'text': texts[i][:100],\n",
    "            'true_label': true_labels[i],\n",
    "            'predicted': predictions[i]\n",
    "        })\n",
    "    \n",
    "    return conf_matrix, class_report, sample_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BaseClassifier:\n",
    "    def __init__(self, bert_path='bert-large-cased', max_length=64, multifactorial= False):\n",
    "        \"\"\"\n",
    "        Base class for BERT-based classification models.\n",
    "        \n",
    "        Provides common functionality for model initialization, data encoding,\n",
    "        training, prediction, and evaluation. Serves as parent class for specific\n",
    "        classifier implementations.\n",
    "        \n",
    "        Attributes:\n",
    "            bert_path (str): Path to pre-trained BERT model\n",
    "            max_length (int): Maximum sequence length for input texts\n",
    "            model: The Keras model instance\n",
    "            multifactorial (bool): Whether model handles multiple classes\n",
    "        \"\"\"\n",
    "        self.bert_path = bert_path\n",
    "        self.max_length = max_length\n",
    "        self.model = None\n",
    "        self.multifactorial = multifactorial\n",
    "        \n",
    "    class BertLayer(keras.layers.Layer):\n",
    "        \"\"\"\n",
    "        Custom Keras layer wrapping BERT model.\n",
    "        \n",
    "        Creates a non-trainable BERT layer that outputs the last hidden states\n",
    "        of the model for use in downstream tasks.\n",
    "        \n",
    "        Args:\n",
    "            bert_path (str): Path to pre-trained BERT model\n",
    "            **kwargs: Additional arguments passed to parent Layer class\n",
    "        \"\"\"\n",
    "        def __init__(self, bert_path='bert-large-cased', **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "            # Specify output_hidden_states=True to get all hidden states\n",
    "            self.bert = TFBertModel.from_pretrained(bert_path, output_hidden_states=True)\n",
    "            self.bert.trainable = False\n",
    "            \n",
    "        def call(self, inputs):\n",
    "            input_ids, attention_mask, token_type_ids = inputs\n",
    "            outputs = self.bert(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids,                \n",
    "            )\n",
    "            # Use the last hidden state instead of pooler output\n",
    "            return outputs.last_hidden_state\n",
    "    \n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        Abstract method to define model architecture.\n",
    "        \n",
    "        Must be implemented by subclasses to create their specific model architectures.\n",
    "        \n",
    "        Raises:\n",
    "            NotImplementedError: If subclass doesn't implement this method\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Subclasses must implement build_model\")\n",
    "    \n",
    "    def encode_data(self, dataset):\n",
    "        \"\"\"\n",
    "        Encode input data for model processing.\n",
    "        \n",
    "        Args:\n",
    "            dataset: Dataset containing input_ids, attention_mask, token_type_ids, and labels\n",
    "            \n",
    "        Returns:\n",
    "            tuple: For binary classification:\n",
    "                - input_ids (np.array)\n",
    "                - attention_mask (np.array)\n",
    "                - token_type_ids (np.array)\n",
    "                - labels (np.array)\n",
    "            For multifactorial:\n",
    "                - Same as above but labels are one-hot encoded for 6 categories\n",
    "        \"\"\"\n",
    "        if self.multifactorial:\n",
    "            input_ids = np.array([item[\"input_ids\"] for item in dataset])\n",
    "            attention_mask = np.array([item[\"attention_mask\"] for item in dataset])\n",
    "            token_type_ids = np.array([item[\"token_type_ids\"] for item in dataset])\n",
    "            # Get labels and convert to one-hot encoding\n",
    "            labels = np.array([item[\"nivel_risa_encoded\"] for item in dataset])\n",
    "            # Convert to one-hot encoding for 6 categories (0-5)\n",
    "            one_hot_labels = np.eye(6)[labels]\n",
    "            return input_ids, attention_mask, token_type_ids, one_hot_labels\n",
    "        \n",
    "        else:\n",
    "            input_ids = np.array([item[\"input_ids\"] for item in dataset])\n",
    "            attention_mask = np.array([item[\"attention_mask\"] for item in dataset])\n",
    "            token_type_ids = np.array([item[\"token_type_ids\"] for item in dataset])\n",
    "            labels = np.array([item[\"labels\"] for item in dataset])\n",
    "            return input_ids, attention_mask, token_type_ids, labels\n",
    "    \n",
    "    def train(self, train_dataset, validation_dataset, epochs=10, batch_size=16, patience=3):\n",
    "        \"\"\"\n",
    "        Train the model on provided datasets.\n",
    "        \n",
    "        Args:\n",
    "            train_dataset: Training data\n",
    "            validation_dataset: Validation data\n",
    "            epochs (int): Number of training epochs\n",
    "            batch_size (int): Batch size for training\n",
    "            patience (int): Early stopping patience\n",
    "            \n",
    "        Returns:\n",
    "            keras.callbacks.History: Training history\n",
    "        \"\"\"\n",
    "        train_inputs = self.encode_data(train_dataset)\n",
    "        val_inputs = self.encode_data(validation_dataset)\n",
    "        early_stopping = keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', patience=patience, restore_best_weights=True, mode='min'\n",
    "        )\n",
    "        history = self.model.fit(\n",
    "            x=[train_inputs[0], train_inputs[1], train_inputs[2]],\n",
    "            y=train_inputs[3],\n",
    "            validation_data=( [val_inputs[0], val_inputs[1], val_inputs[2]], val_inputs[3] ),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=[early_stopping]\n",
    "        )\n",
    "        return history\n",
    "    \n",
    "    def predict(self, input_ids, attention_mask, token_type_ids):\n",
    "        \"\"\"\n",
    "        Make predictions using the trained model.\n",
    "        \n",
    "        Args:\n",
    "            input_ids: BERT input token IDs\n",
    "            attention_mask: BERT attention mask\n",
    "            token_type_ids: BERT token type IDs\n",
    "            \n",
    "        Returns:\n",
    "            np.array: Model predictions\n",
    "        \"\"\"\n",
    "        return self.model.predict([input_ids, attention_mask, token_type_ids])\n",
    "    \n",
    "    def evaluate(self, test_dataset):\n",
    "        \"\"\"\n",
    "        Evaluate model performance on test dataset.\n",
    "        \n",
    "        Args:\n",
    "            test_dataset: Test data to evaluate on\n",
    "            \n",
    "        Returns:\n",
    "            dict: Evaluation metrics (loss and accuracy)\n",
    "        \"\"\"\n",
    "        test_inputs = self.encode_data(test_dataset)\n",
    "        results = self.model.evaluate(\n",
    "            [test_inputs[0], test_inputs[1], test_inputs[2]],\n",
    "            test_inputs[3]\n",
    "        )\n",
    "        return dict(zip(self.model.metrics_names, results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM 1 AND LSTM 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_2_MultiFactorial(BaseClassifier):\n",
    "    \"\"\"\n",
    "    Multi-class classifier combining BERT with single bidirectional LSTM layer.\n",
    "    \n",
    "    Architecture:\n",
    "        1. BERT layer for text encoding\n",
    "        2. Self-attention layer\n",
    "        3. Concatenation of BERT output and attention\n",
    "        4. Single bidirectional LSTM\n",
    "        5. Six unit softmax output for multi-class classification\n",
    "    \"\"\"\n",
    "    \n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        Creates a multi-class classification model combining BERT with single LSTM layer.\n",
    "        \n",
    "        Architecture:\n",
    "            1. Input layers:\n",
    "                - input_ids: Token indices of input sequence (shape: [batch_size, 64])\n",
    "                - attention_mask: Mask for padding (shape: [batch_size, 64])\n",
    "                - token_type_ids: Segment tokens (shape: [batch_size, 64])\n",
    "            \n",
    "            2. BERT Layer:\n",
    "                - Non-trainable BERT-large-cased model\n",
    "                - Outputs last hidden states\n",
    "            \n",
    "            3. Attention mechanism:\n",
    "                - Self-attention on BERT outputs\n",
    "                - Helps focus on relevant parts of input\n",
    "            \n",
    "            4. Feature combination:\n",
    "                - Concatenates BERT outputs with attention outputs\n",
    "                - Enriches representation with attention information\n",
    "            \n",
    "            5. LSTM layer:\n",
    "                - Single Bidirectional LSTM with 256 units\n",
    "                - Returns final sequence state\n",
    "                - Total 512 features (256 * 2 directions)\n",
    "            \n",
    "            6. Output:\n",
    "                - Dense layer with 6 units (one per class)\n",
    "                - Softmax activation for multi-class classification\n",
    "        \n",
    "        Returns:\n",
    "            keras.Model: Compiled model with inputs [input_ids, attention_mask, token_type_ids]\n",
    "                        and multi-class classification output (6 classes)\n",
    "        \"\"\"\n",
    "        input_ids = keras.layers.Input(shape=(64,), dtype='int32', name='input_ids')\n",
    "        attention_mask = keras.layers.Input(shape=(64,), dtype='int32', name='attention_mask')\n",
    "        token_type_ids = keras.layers.Input(shape=(64,), dtype='int32', name='token_type_ids')\n",
    "        \n",
    "        bert_layer = self.BertLayer(self.bert_path)\n",
    "        sequence_output = bert_layer([input_ids, attention_mask, token_type_ids])\n",
    "        \n",
    "        attention = keras.layers.Attention()([sequence_output, sequence_output])\n",
    "        \n",
    "        merge_layer = keras.layers.Concatenate()([sequence_output, attention])\n",
    "        \n",
    "        LSTM1_layer = keras.layers.Bidirectional(\n",
    "            keras.layers.LSTM(units=256)\n",
    "        )(merge_layer)\n",
    "            \n",
    "        output_layer = keras.layers.Dense(units=6, activation='softmax')(LSTM1_layer)\n",
    "        \n",
    "        self.model = keras.Model(\n",
    "            inputs=[input_ids, attention_mask, token_type_ids],\n",
    "            outputs=output_layer\n",
    "        )\n",
    "        return self.model\n",
    "    \n",
    "    \n",
    "class LSTM_1_MultiFactorial(BaseClassifier):\n",
    "    \"\"\"\n",
    "    Multi-class classifier combining BERT with dual bidirectional LSTM layers.\n",
    "    \n",
    "    Architecture:\n",
    "        1. BERT layer for text encoding\n",
    "        2. Self-attention layer\n",
    "        3. Concatenation of BERT output and attention\n",
    "        4. First bidirectional LSTM with sequence return\n",
    "        5. Dropout layer\n",
    "        6. Second bidirectional LSTM\n",
    "        7. Six unit softmax output for multi-class classification\n",
    "    \"\"\"\n",
    "    \n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        Creates a multi-class classification model combining BERT with dual LSTM layers.\n",
    "        \n",
    "        Architecture:\n",
    "            1. Input layers:\n",
    "                - input_ids: Token indices of input sequence (shape: [batch_size, 64])\n",
    "                - attention_mask: Mask for padding (shape: [batch_size, 64])\n",
    "                - token_type_ids: Segment tokens (shape: [batch_size, 64])\n",
    "            \n",
    "            2. BERT Layer:\n",
    "                - Non-trainable BERT-large-cased model\n",
    "                - Outputs last hidden states\n",
    "            \n",
    "            3. Attention mechanism:\n",
    "                - Self-attention on BERT outputs\n",
    "                - Helps focus on relevant parts of input\n",
    "            \n",
    "            4. Feature combination:\n",
    "                - Concatenates BERT outputs with attention outputs\n",
    "                - Enriches representation with attention information\n",
    "            \n",
    "            5. First LSTM layer:\n",
    "                - Bidirectional LSTM with 256 units\n",
    "                - Returns sequences for hierarchical processing\n",
    "                - Total 512 features (256 * 2 directions)\n",
    "            \n",
    "            6. Regularization:\n",
    "                - Dropout layer with 0.3 rate\n",
    "                - Prevents overfitting\n",
    "            \n",
    "            7. Second LSTM layer:\n",
    "                - Bidirectional LSTM with 256 units\n",
    "                - Returns final sequence state\n",
    "                - Total 512 features (256 * 2 directions)\n",
    "            \n",
    "            8. Output:\n",
    "                - Dense layer with 6 units (one per class)\n",
    "                - Softmax activation for multi-class classification\n",
    "        \n",
    "        Returns:\n",
    "            keras.Model: Compiled model with inputs [input_ids, attention_mask, token_type_ids]\n",
    "                        and multi-class classification output (6 classes)\n",
    "        \"\"\"\n",
    "        input_ids = keras.layers.Input(shape=(64,), dtype='int32', name='input_ids')\n",
    "        attention_mask = keras.layers.Input(shape=(64,), dtype='int32', name='attention_mask')\n",
    "        token_type_ids = keras.layers.Input(shape=(64,), dtype='int32', name='token_type_ids')\n",
    "        \n",
    "        bert_layer = self.BertLayer(self.bert_path)\n",
    "        sequence_output = bert_layer([input_ids, attention_mask, token_type_ids])\n",
    "        \n",
    "        attention = keras.layers.Attention()([sequence_output, sequence_output])\n",
    "        \n",
    "        merge_layer = keras.layers.Concatenate()([sequence_output, attention])\n",
    "        \n",
    "        LSTM1_layer = keras.layers.Bidirectional(\n",
    "            keras.layers.LSTM(units=256, return_sequences=True)\n",
    "        )(merge_layer)\n",
    "        \n",
    "        dropout_layer = keras.layers.Dropout(rate=0.3)(LSTM1_layer)\n",
    "        \n",
    "        LSTM2_layer = keras.layers.Bidirectional(\n",
    "            keras.layers.LSTM(units=256)\n",
    "        )(dropout_layer)\n",
    "        \n",
    "        output_layer = keras.layers.Dense(units=6, activation='softmax')(LSTM2_layer)\n",
    "        \n",
    "        self.model = keras.Model(\n",
    "            inputs=[input_ids, attention_mask, token_type_ids],\n",
    "            outputs=output_layer\n",
    "        )\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Initialize classifier\n",
    "\n",
    "from models.encoder_only_lstm import LSTM_2_MultiFactorial, LSTM_1_MultiFactorial\n",
    "\n",
    "classifier_lstm2_multifactorial = LSTM_2_MultiFactorial(bert_path='bert-large-cased', max_length=64)\n",
    "\n",
    "# Get the custom BertLayer class\n",
    "BertLayer = classifier_lstm2_multifactorial.BertLayer\n",
    "\n",
    "# Load the model with custom_object_scope\n",
    "with custom_object_scope({'BertLayer': BertLayer}):\n",
    "    classifier_lstm2_multifactorial.model = load_model('models/multifactorial/lstm2_model.h5')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)      [(None, 64)]                 0         []                            \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer  [(None, 64)]                 0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " token_type_ids (InputLayer  [(None, 64)]                 0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bert_layer_2 (BertLayer)    (None, 64, 1024)             3335792   ['input_ids[0][0]',           \n",
      "                                                          64         'attention_mask[0][0]',      \n",
      "                                                                     'token_type_ids[0][0]']      \n",
      "                                                                                                  \n",
      " attention_2 (Attention)     (None, 64, 1024)             0         ['bert_layer_2[0][0]',        \n",
      "                                                                     'bert_layer_2[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 64, 2048)             0         ['bert_layer_2[0][0]',        \n",
      " )                                                                   'attention_2[0][0]']         \n",
      "                                                                                                  \n",
      " bidirectional_3 (Bidirecti  (None, 512)                  4720640   ['concatenate_2[0][0]']       \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 6)                    3078      ['bidirectional_3[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 338302982 (1.26 GB)\n",
      "Trainable params: 4723718 (18.02 MB)\n",
      "Non-trainable params: 333579264 (1.24 GB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_lstm2_multifactorial.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling dataset...\n",
      "Classes present in dataset: [1, 2, 3, 4, 5]\n",
      "Class distribution:\n",
      "nivel_risa\n",
      "1    1216\n",
      "2    4627\n",
      "3    2897\n",
      "4     988\n",
      "5     205\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final sampled distribution:\n",
      "nivel_risa\n",
      "1    20\n",
      "2    20\n",
      "3    20\n",
      "4    20\n",
      "5    20\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Making predictions...\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "\n",
      "Prediction 1:\n",
      "Text: No hay vuelta que darle dijo el que dormia en un muro...\n",
      "True label: 4\n",
      "Predicted: 2\n",
      "1/1 [==============================] - 1s 503ms/step\n",
      "\n",
      "Prediction 2:\n",
      "Text: La que me gusta se ha quitado la foto de perfil y no le llegan los mensajes, creo que le gusto...\n",
      "True label: 4\n",
      "Predicted: 4\n",
      "1/1 [==============================] - 0s 477ms/step\n",
      "\n",
      "Prediction 3:\n",
      "Text: Que haces cuando ves un negro desangrarse en la calle? Dejar de reír y pegarle otro tiro....\n",
      "True label: 4\n",
      "Predicted: 2\n",
      "1/1 [==============================] - 0s 453ms/step\n",
      "\n",
      "Prediction 4:\n",
      "Text: El profesor de la materia de relleno: De mañana un informe de lecturs del pdf que mandé - El profeso...\n",
      "True label: 4\n",
      "Predicted: 3\n",
      "1/1 [==============================] - 0s 458ms/step\n",
      "\n",
      "Prediction 5:\n",
      "Text: Imagen de Bob Esponja vestido como un ganster, con un sombrero verde, traje a rayas y sosteniendo un...\n",
      "True label: 4\n",
      "Predicted: 2\n",
      "1/1 [==============================] - 0s 440ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 392ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 398ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 466ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 372ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 437ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 381ms/step\n",
      "1/1 [==============================] - 0s 402ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 473ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 430ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 487ms/step\n",
      "1/1 [==============================] - 1s 516ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  0  0  0  0  0]\n",
      " [ 0  0 19  1  0  0]\n",
      " [ 0  0 18  2  0  0]\n",
      " [ 0  0 17  3  0  0]\n",
      " [ 0  0 14  3  3  0]\n",
      " [ 1  0 13  4  2  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00        20\n",
      "           2       0.22      0.90      0.36        20\n",
      "           3       0.23      0.15      0.18        20\n",
      "           4       0.60      0.15      0.24        20\n",
      "           5       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.24       100\n",
      "   macro avg       0.18      0.20      0.13       100\n",
      "weighted avg       0.21      0.24      0.16       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Sample dataset\n",
    "    print(\"\\nSampling dataset...\")\n",
    "    sampled_data = sample_dataset(dataset, num_samples=20)\n",
    "    \n",
    "    print(\"\\nMaking predictions...\")\n",
    "    # Evaluate predictions\n",
    "    conf_matrix, class_report, sample_preds = evaluate_predictions(classifier_lstm2_multifactorial, sampled_data)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(class_report)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error during execution: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Results for lstm2 (multifactorial):\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.7294\n",
      "F1 Score: 0.6718\n",
      "Recall: 0.7294\n",
      "\n",
      "Debug Information:\n",
      "Number of validation samples: 1360\n",
      "Unique predicted classes: [0 1 2 3 4]\n",
      "Unique true labels: [0 1 2 3 4 5]\n",
      "\n",
      "Class Distribution:\n",
      "Predicted class counts:\n",
      "Class 0: 663\n",
      "Class 1: 1\n",
      "Class 2: 611\n",
      "Class 3: 78\n",
      "Class 4: 7\n",
      "\n",
      "True class counts:\n",
      "Class 0: 655\n",
      "Class 1: 92\n",
      "Class 2: 334\n",
      "Class 3: 192\n",
      "Class 4: 74\n",
      "Class 5: 13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\multifactorial\\evaluation\\lstm2_validation_results.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Results for lstm2 (multifactorial):\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.7259\n",
      "F1 Score: 0.6722\n",
      "Recall: 0.7259\n",
      "\n",
      "Debug Information:\n",
      "Unique predicted classes: [0 1 2 3 4]\n",
      "Unique true labels: [0 1 2 3 4 5]\n",
      "Number of samples: 5826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\multifactorial\\testing\\lstm2_multifactorial_test_evaluation.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "classifier_lstm1_multifactorial = LSTM_1_MultiFactorial(bert_path='bert-large-cased', max_length=64)\n",
    "\n",
    "# Get the custom BertLayer class\n",
    "BertLayer = classifier_lstm1_multifactorial.BertLayer\n",
    "\n",
    "# Load the model with custom_object_scope\n",
    "with custom_object_scope({'BertLayer': BertLayer}):\n",
    "    classifier_lstm1_multifactorial.model = load_model('models/multifactorial/lstm1_model.h5')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)      [(None, 64)]                 0         []                            \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer  [(None, 64)]                 0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " token_type_ids (InputLayer  [(None, 64)]                 0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bert_layer_1 (BertLayer)    (None, 64, 1024)             3335792   ['input_ids[0][0]',           \n",
      "                                                          64         'attention_mask[0][0]',      \n",
      "                                                                     'token_type_ids[0][0]']      \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, 64, 1024)             0         ['bert_layer_1[0][0]',        \n",
      "                                                                     'bert_layer_1[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 64, 2048)             0         ['bert_layer_1[0][0]',        \n",
      " )                                                                   'attention_1[0][0]']         \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirecti  (None, 64, 512)              4720640   ['concatenate_1[0][0]']       \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " dropout_146 (Dropout)       (None, 64, 512)              0         ['bidirectional_1[0][0]']     \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirecti  (None, 512)                  1574912   ['dropout_146[0][0]']         \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 6)                    3078      ['bidirectional_2[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 339877894 (1.27 GB)\n",
      "Trainable params: 6298630 (24.03 MB)\n",
      "Non-trainable params: 333579264 (1.24 GB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_lstm1_multifactorial.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling dataset...\n",
      "Classes present in dataset: [1, 2, 3, 4, 5]\n",
      "Class distribution:\n",
      "nivel_risa\n",
      "1    1216\n",
      "2    4627\n",
      "3    2897\n",
      "4     988\n",
      "5     205\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final sampled distribution:\n",
      "nivel_risa\n",
      "1    20\n",
      "2    20\n",
      "3    20\n",
      "4    20\n",
      "5    20\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Making predictions...\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "\n",
      "Prediction 1:\n",
      "Text: No hay vuelta que darle dijo el que dormia en un muro...\n",
      "True label: 4\n",
      "Predicted: 2\n",
      "1/1 [==============================] - 0s 457ms/step\n",
      "\n",
      "Prediction 2:\n",
      "Text: La que me gusta se ha quitado la foto de perfil y no le llegan los mensajes, creo que le gusto...\n",
      "True label: 4\n",
      "Predicted: 4\n",
      "1/1 [==============================] - 0s 434ms/step\n",
      "\n",
      "Prediction 3:\n",
      "Text: Que haces cuando ves un negro desangrarse en la calle? Dejar de reír y pegarle otro tiro....\n",
      "True label: 4\n",
      "Predicted: 4\n",
      "1/1 [==============================] - 0s 416ms/step\n",
      "\n",
      "Prediction 4:\n",
      "Text: El profesor de la materia de relleno: De mañana un informe de lecturs del pdf que mandé - El profeso...\n",
      "True label: 4\n",
      "Predicted: 2\n",
      "1/1 [==============================] - 0s 417ms/step\n",
      "\n",
      "Prediction 5:\n",
      "Text: Imagen de Bob Esponja vestido como un ganster, con un sombrero verde, traje a rayas y sosteniendo un...\n",
      "True label: 4\n",
      "Predicted: 1\n",
      "1/1 [==============================] - 0s 424ms/step\n",
      "1/1 [==============================] - 0s 409ms/step\n",
      "1/1 [==============================] - 0s 416ms/step\n",
      "1/1 [==============================] - 0s 434ms/step\n",
      "1/1 [==============================] - 0s 427ms/step\n",
      "1/1 [==============================] - 0s 408ms/step\n",
      "1/1 [==============================] - 0s 413ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "1/1 [==============================] - 0s 428ms/step\n",
      "1/1 [==============================] - 0s 442ms/step\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "1/1 [==============================] - 0s 449ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 426ms/step\n",
      "1/1 [==============================] - 0s 413ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 424ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 392ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 482ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 392ms/step\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "1/1 [==============================] - 0s 435ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 438ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 387ms/step\n",
      "1/1 [==============================] - 0s 394ms/step\n",
      "1/1 [==============================] - 0s 359ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 447ms/step\n",
      "1/1 [==============================] - 0s 379ms/step\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 394ms/step\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "1/1 [==============================] - 0s 468ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 432ms/step\n",
      "1/1 [==============================] - 0s 440ms/step\n",
      "1/1 [==============================] - 0s 416ms/step\n",
      "1/1 [==============================] - 0s 403ms/step\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "1/1 [==============================] - 0s 414ms/step\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "1/1 [==============================] - 0s 379ms/step\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2 17  1  0  0]\n",
      " [ 0 20  0  0  0]\n",
      " [ 0 18  1  1  0]\n",
      " [ 2 10  1  7  0]\n",
      " [ 1  7  0 12  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.10      0.16        20\n",
      "           2       0.28      1.00      0.43        20\n",
      "           3       0.33      0.05      0.09        20\n",
      "           4       0.35      0.35      0.35        20\n",
      "           5       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.30       100\n",
      "   macro avg       0.27      0.30      0.21       100\n",
      "weighted avg       0.27      0.30      0.21       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Sample dataset\n",
    "    print(\"\\nSampling dataset...\")\n",
    "    sampled_data = sample_dataset(dataset, num_samples=20)\n",
    "    \n",
    "    print(\"\\nMaking predictions...\")\n",
    "    # Evaluate predictions\n",
    "    conf_matrix, class_report, sample_preds = evaluate_predictions(classifier_lstm1_multifactorial, sampled_data)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(class_report)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error during execution: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluation on validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Results for lstm1 (multifactorial):\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.7309\n",
      "F1 Score: 0.6804\n",
      "Recall: 0.7309\n",
      "\n",
      "Debug Information:\n",
      "Number of validation samples: 1360\n",
      "Unique predicted classes: [0 1 2 3 4]\n",
      "Unique true labels: [0 1 2 3 4 5]\n",
      "\n",
      "Class Distribution:\n",
      "Predicted class counts:\n",
      "Class 0: 665\n",
      "Class 1: 25\n",
      "Class 2: 596\n",
      "Class 3: 37\n",
      "Class 4: 37\n",
      "\n",
      "True class counts:\n",
      "Class 0: 655\n",
      "Class 1: 92\n",
      "Class 2: 334\n",
      "Class 3: 192\n",
      "Class 4: 74\n",
      "Class 5: 13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\multifactorial\\evaluation\\lstm1_validation_results.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluation on testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Results for lstm1 (multifactorial):\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.7245\n",
      "F1 Score: 0.6699\n",
      "Recall: 0.7245\n",
      "\n",
      "Debug Information:\n",
      "Unique predicted classes: [0 1 2 3 4]\n",
      "Unique true labels: [0 1 2 3 4 5]\n",
      "Number of samples: 5826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\multifactorial\\testing\\lstm1_multifactorial_test_evaluation.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXT VS MULTIMEDIA TEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are keeping the best model of finetuning captioning which would be the one with GPT meaning that for the binary it would be the one from 5000 data and for the multifactorial the one with all data, the other models we are using are the 2 encoder only classifiers with LSTMs layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, classification_report\n",
    "from typing import Dict, List, Tuple, Any\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample_stratified_data(dataset: Dataset, \n",
    "                          start_idx: int, \n",
    "                          end_idx: int, \n",
    "                          samples_per_category: int = 20,\n",
    "                          is_multifactorial: bool = False) -> Dataset:\n",
    "    \"\"\"\n",
    "    Creates a stratified sample of data from a specific index range, ensuring balanced representation \n",
    "    across categories.\n",
    "\n",
    "    Args:\n",
    "        dataset (Dataset): Input Hugging Face dataset to sample from.\n",
    "        start_idx (int): Starting index of the range to sample from.\n",
    "        end_idx (int): Ending index (exclusive) of the range to sample from.\n",
    "        samples_per_category (int, optional): Number of samples to select from each category. \n",
    "            Defaults to 20.\n",
    "        is_multifactorial (bool, optional): If True, samples from categories 1-5. If False, samples \n",
    "            from binary categories 0-1. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        Dataset: A new Hugging Face Dataset containing:\n",
    "            - For binary (is_multifactorial=False): 40 total samples (20 each from categories 0,1)\n",
    "            - For multifactorial (is_multifactorial=True): 100 total samples (20 each from \n",
    "              categories 1-5)\n",
    "\n",
    "    Notes:\n",
    "        - Expects 'nivel_risa' as the category column name\n",
    "        - Prints detailed sampling statistics during execution\n",
    "        - Uses sampling with replacement if a category has fewer samples than requested\n",
    "        - Only samples from categories that are present in the specified index range\n",
    "        - For binary classification, target categories are [0,1]\n",
    "        - For multifactorial classification, target categories are [1,2,3,4,5]\n",
    "\n",
    "    Example:\n",
    "        >>> # Binary classification example\n",
    "        >>> binary_sample = sample_stratified_data(dataset, 0, 1000, samples_per_category=20)\n",
    "        >>> print(len(binary_sample))  # Should print 40 (20 samples × 2 categories)\n",
    "        \n",
    "        >>> # Multifactorial classification example\n",
    "        >>> multi_sample = sample_stratified_data(dataset, 0, 1000, samples_per_category=20, \n",
    "        ...                                       is_multifactorial=True)\n",
    "        >>> print(len(multi_sample))  # Should print 100 (20 samples × 5 categories)\n",
    "    \"\"\"\n",
    "    subset = dataset.select(range(start_idx, end_idx))\n",
    "    \n",
    "    # Check what categories are present in the data\n",
    "    all_labels = [item['nivel_risa'] for item in subset]\n",
    "    unique_labels = sorted(set(all_labels))\n",
    "    print(f\"Categories present in range {start_idx}-{end_idx}: {unique_labels}\")\n",
    "    \n",
    "    # For binary classification (0,1) or multifactorial (1-5)\n",
    "    if is_multifactorial:\n",
    "        target_categories = [cat for cat in range(1, 6) if cat in unique_labels]\n",
    "    else:\n",
    "        target_categories = [cat for cat in [0, 1] if cat in unique_labels]\n",
    "    \n",
    "    sampled_data = []\n",
    "    for category in target_categories:\n",
    "        category_data = [i for i, item in enumerate(subset) if item['nivel_risa'] == category]\n",
    "        n_available = len(category_data)\n",
    "        \n",
    "        print(f\"Category {category}: {n_available} samples available\")\n",
    "        \n",
    "        if n_available > 0:\n",
    "            if n_available >= samples_per_category:\n",
    "                selected_indices = random.sample(category_data, samples_per_category)\n",
    "            else:\n",
    "                print(f\"Warning: Only {n_available} samples available for category {category}, sampling with replacement\")\n",
    "                selected_indices = random.choices(category_data, k=samples_per_category)\n",
    "            sampled_data.extend([subset[i] for i in selected_indices])\n",
    "    \n",
    "    result_dataset = Dataset.from_list(sampled_data)\n",
    "    \n",
    "    # Print distribution of samples\n",
    "    final_distribution = {}\n",
    "    for item in result_dataset:\n",
    "        category = item['nivel_risa']\n",
    "        final_distribution[category] = final_distribution.get(category, 0) + 1\n",
    "    \n",
    "    print(\"\\nFinal sample distribution:\")\n",
    "    for category in sorted(final_distribution.keys()):\n",
    "        print(f\"Category {category}: {final_distribution[category]} samples\")\n",
    "    print(f\"Total samples: {len(result_dataset)}\")\n",
    "    \n",
    "    return result_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(model, text, is_multifactorial=False, model_type='finetuning'):\n",
    "    \"\"\"\n",
    "    Generates predictions for a single text input using either a fine-tuned or LSTM model.\n",
    "\n",
    "    Args:\n",
    "        model: Trained model object that implements a predict method.\n",
    "            - For finetuning: Must return probabilities or predicted labels\n",
    "            - For LSTM: Must be compatible with get_prediction_lstm functions\n",
    "        text (str): Input text to classify.\n",
    "        is_multifactorial (bool, optional): If True, performs multi-class classification (1-5).\n",
    "            If False, performs binary classification (0-1). Defaults to False.\n",
    "        model_type (str, optional): Type of model to use. Must be either 'finetuning' or 'lstm'.\n",
    "            Defaults to 'finetuning'.\n",
    "\n",
    "    Returns:\n",
    "        Union[int, None]: \n",
    "            - For binary classification: 0 or 1\n",
    "            - For multifactorial: Integer from 1-5\n",
    "            - None if prediction fails\n",
    "    \n",
    "    Raises:\n",
    "        Exception: Catches and logs any prediction errors, returning None instead of failing.\n",
    "\n",
    "    Notes:\n",
    "        - For finetuning models:\n",
    "            - Binary: Returns 1 if probability > 0.5, else 0\n",
    "            - Multifactorial: Returns predicted label directly\n",
    "        - For LSTM models:\n",
    "            - Uses separate prediction functions for binary and multifactorial cases\n",
    "        - Truncates error messages for long texts to first 100 characters\n",
    "        \n",
    "    Example:\n",
    "        >>> # Binary classification with fine-tuned model\n",
    "        >>> result = predict_text(model, \"Sample text\", is_multifactorial=False)\n",
    "        >>> print(result)  # Prints 0 or 1\n",
    "        \n",
    "        >>> # Multifactorial classification with LSTM model\n",
    "        >>> result = predict_text(model, \"Sample text\", is_multifactorial=True, model_type='lstm')\n",
    "        >>> print(result)  # Prints 1-5\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if model_type == 'finetuning':\n",
    "            if is_multifactorial:\n",
    "                result = model.predict(text)\n",
    "                return result['predicted_label']\n",
    "            else:\n",
    "                probs = model.predict(text)\n",
    "                return int(probs[0][1] > 0.5)\n",
    "        else:  # LSTM\n",
    "            if is_multifactorial:\n",
    "                return get_prediction_lstm_multifactorial(model, text)\n",
    "            else:\n",
    "                return get_prediction_lstm(model, text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error predicting text: {text[:100]}...\")\n",
    "        print(f\"Error details: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data, is_multifactorial=False, model_type='finetuning'):\n",
    "    \"\"\"\n",
    "    Evaluates model performance on a dataset by computing accuracy, F1-score, and recall metrics.\n",
    "\n",
    "    Args:\n",
    "       model: Trained model object that implements prediction functionality. Should be compatible\n",
    "           with predict_text() function.\n",
    "       data (List[Dict]): List of dictionaries containing text samples and labels. Each dict must\n",
    "           have 'text' and 'nivel_risa' keys.\n",
    "       is_multifactorial (bool, optional): If True, performs multi-class evaluation (classes 1-5).\n",
    "           If False, performs binary evaluation (0-1). Defaults to False.\n",
    "       model_type (str, optional): Type of model to evaluate - either 'finetuning' or 'lstm'.\n",
    "           Defaults to 'finetuning'.\n",
    "\n",
    "    Returns:\n",
    "       Dict[str, float]: Dictionary containing evaluation metrics:\n",
    "           - 'accuracy': Overall classification accuracy\n",
    "           - 'f1_score': F1-score (weighted average for multi-class)\n",
    "           - 'recall': Recall score (weighted average for multi-class) \n",
    "           - 'n_samples': Number of successfully processed samples\n",
    "\n",
    "    Raises:\n",
    "       ValueError: If no valid predictions could be made on the input data.\n",
    "\n",
    "    Notes:\n",
    "       - Handles failed predictions gracefully by skipping them\n",
    "       - Uses weighted averaging for multi-class metrics to handle class imbalance\n",
    "       - Sets zero_division=0 for F1 and recall calculations to handle edge cases\n",
    "       - Truncates true labels if some predictions fail\n",
    "       - Prints progress and final metrics to stdout\n",
    "       \n",
    "    Example:\n",
    "       >>> test_data = [{'text': 'sample text', 'nivel_risa': 1}, ...]\n",
    "       >>> metrics = evaluate_model(model, test_data, is_multifactorial=True)\n",
    "       >>> print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    \"\"\"\n",
    "    texts = [item['text'] for item in data]\n",
    "    true_labels = [item['nivel_risa'] for item in data]\n",
    "    predictions = []\n",
    "    \n",
    "    print(f\"Evaluating {len(texts)} samples...\")\n",
    "    \n",
    "    for text in texts:\n",
    "        pred = predict_text(model, text, is_multifactorial, model_type)\n",
    "        if pred is not None:\n",
    "            predictions.append(pred)\n",
    "    \n",
    "    if not predictions:\n",
    "        raise ValueError(\"No valid predictions were made\")\n",
    "    \n",
    "    # Truncate true_labels to match predictions length\n",
    "    true_labels = true_labels[:len(predictions)]\n",
    "    \n",
    "    if is_multifactorial:\n",
    "        # Use weighted average for multiclass metrics to handle class imbalance\n",
    "        f1 = f1_score(true_labels, predictions, average='weighted', zero_division=0)\n",
    "        recall = recall_score(true_labels, predictions, average='weighted', zero_division=0)\n",
    "    else:\n",
    "        f1 = f1_score(true_labels, predictions, zero_division=0)\n",
    "        recall = recall_score(true_labels, predictions, zero_division=0)\n",
    "    \n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    \n",
    "    print(f\"Processed {len(predictions)} predictions out of {len(texts)} samples\")\n",
    "    print(f\"Metrics - Accuracy: {accuracy:.4f}, F1: {f1:.4f}, Recall: {recall:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'recall': recall,\n",
    "        'n_samples': len(predictions)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_performance(dataset, models):\n",
    "    \"\"\"\n",
    "    Compares multiple models' performance on multimedia and natural text data splits by evaluating\n",
    "    their accuracy, F1-score, and recall metrics.\n",
    "\n",
    "    Args:\n",
    "        dataset (Dataset): Hugging Face dataset containing text samples and labels.\n",
    "        models (Dict[str, Tuple]): Dictionary mapping model names to tuples containing:\n",
    "            - model: The trained model object\n",
    "            - is_multifactorial (bool): Whether model does multi-class classification\n",
    "            - model_type (str): Type of model ('finetuning' or 'lstm')\n",
    "            Example format: {\n",
    "                'model_name': (model_object, is_multifactorial, model_type)\n",
    "            }\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing evaluation results with columns:\n",
    "            - model: Name of the model\n",
    "            - data_type: Either 'multimedia' (indices 0-2006) or 'natural_text' (indices 2007+)\n",
    "            - accuracy: Classification accuracy\n",
    "            - f1_score: F1 score \n",
    "            - recall: Recall score\n",
    "            - n_samples: Number of samples evaluated\n",
    "\n",
    "    Notes:\n",
    "        - Splits data into two parts:\n",
    "            - Multimedia: First 2006 samples\n",
    "            - Natural text: Remaining samples (2007 onwards)\n",
    "        - Uses stratified sampling to get 20 samples per category from each split\n",
    "        - Handles errors independently for each model and data split\n",
    "        - Prints progress and error information during execution\n",
    "        - Missing results from failed evaluations will not appear in output DataFrame\n",
    "\n",
    "    Example:\n",
    "        >>> models_dict = {\n",
    "        ...     'BERT': (bert_model, False, 'finetuning'),\n",
    "        ...     'LSTM': (lstm_model, True, 'lstm')\n",
    "        ... }\n",
    "        >>> results_df = compare_models_performance(dataset, models_dict)\n",
    "        >>> print(results_df.groupby(['model', 'data_type'])['accuracy'].mean())\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    total_samples = len(dataset)\n",
    "    print(f\"Total dataset size: {total_samples}\")\n",
    "    \n",
    "    for model_name, (model, is_multifactorial, model_type) in models.items():\n",
    "        print(f\"\\nEvaluating {model_name}...\")\n",
    "        \n",
    "        try:\n",
    "            print(\"\\nSampling multimedia data (0-2006)...\")\n",
    "            multimedia_data = sample_stratified_data(dataset, 0, 2006, 20, is_multifactorial)\n",
    "            multimedia_metrics = evaluate_model(model, multimedia_data, is_multifactorial, model_type)\n",
    "            results.append({\n",
    "                'model': model_name,\n",
    "                'data_type': 'multimedia',\n",
    "                **multimedia_metrics\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating {model_name} on multimedia data: {str(e)}\")\n",
    "        \n",
    "        try:\n",
    "            print(\"\\nSampling natural text data (2007-end)...\")\n",
    "            natural_text_data = sample_stratified_data(dataset, 2007, total_samples, 20, is_multifactorial)\n",
    "            natural_metrics = evaluate_model(model, natural_text_data, is_multifactorial, model_type)\n",
    "            results.append({\n",
    "                'model': model_name,\n",
    "                'data_type': 'natural_text',\n",
    "                **natural_metrics\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating {model_name} on natural text data: {str(e)}\")\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size: 9933\n",
      "\n",
      "Evaluating GPT Binary...\n",
      "\n",
      "Sampling multimedia data (0-2006)...\n",
      "Categories present in range 0-2006: [1, 2, 3, 4, 5]\n",
      "Category 1: 286 samples available\n",
      "\n",
      "Final sample distribution:\n",
      "Category 1: 20 samples\n",
      "Total samples: 20\n",
      "Evaluating 20 samples...\n",
      "Processed 20 predictions out of 20 samples\n",
      "Metrics - Accuracy: 0.7000, F1: 0.8235, Recall: 0.7000\n",
      "\n",
      "Sampling natural text data (2007-end)...\n",
      "Categories present in range 2007-9933: [1, 2, 3, 4, 5]\n",
      "Category 1: 930 samples available\n",
      "\n",
      "Final sample distribution:\n",
      "Category 1: 20 samples\n",
      "Total samples: 20\n",
      "Evaluating 20 samples...\n",
      "Processed 20 predictions out of 20 samples\n",
      "Metrics - Accuracy: 0.9500, F1: 0.9744, Recall: 0.9500\n",
      "\n",
      "Evaluating LSTM2 Binary...\n",
      "\n",
      "Sampling multimedia data (0-2006)...\n",
      "Categories present in range 0-2006: [1, 2, 3, 4, 5]\n",
      "Category 1: 286 samples available\n",
      "\n",
      "Final sample distribution:\n",
      "Category 1: 20 samples\n",
      "Total samples: 20\n",
      "Evaluating 20 samples...\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 469ms/step\n",
      "1/1 [==============================] - 0s 437ms/step\n",
      "1/1 [==============================] - 0s 444ms/step\n",
      "1/1 [==============================] - 0s 448ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 413ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 400ms/step\n",
      "1/1 [==============================] - 0s 455ms/step\n",
      "1/1 [==============================] - 0s 398ms/step\n",
      "1/1 [==============================] - 0s 398ms/step\n",
      "1/1 [==============================] - 0s 424ms/step\n",
      "Processed 20 predictions out of 20 samples\n",
      "Metrics - Accuracy: 1.0000, F1: 1.0000, Recall: 1.0000\n",
      "\n",
      "Sampling natural text data (2007-end)...\n",
      "Categories present in range 2007-9933: [1, 2, 3, 4, 5]\n",
      "Category 1: 930 samples available\n",
      "\n",
      "Final sample distribution:\n",
      "Category 1: 20 samples\n",
      "Total samples: 20\n",
      "Evaluating 20 samples...\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 397ms/step\n",
      "1/1 [==============================] - 0s 397ms/step\n",
      "1/1 [==============================] - 0s 468ms/step\n",
      "1/1 [==============================] - 0s 422ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 465ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "Processed 20 predictions out of 20 samples\n",
      "Metrics - Accuracy: 1.0000, F1: 1.0000, Recall: 1.0000\n",
      "\n",
      "Evaluating LSTM1 Binary...\n",
      "\n",
      "Sampling multimedia data (0-2006)...\n",
      "Categories present in range 0-2006: [1, 2, 3, 4, 5]\n",
      "Category 1: 286 samples available\n",
      "\n",
      "Final sample distribution:\n",
      "Category 1: 20 samples\n",
      "Total samples: 20\n",
      "Evaluating 20 samples...\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 384ms/step\n",
      "1/1 [==============================] - 0s 429ms/step\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "1/1 [==============================] - 0s 437ms/step\n",
      "1/1 [==============================] - 0s 384ms/step\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 432ms/step\n",
      "1/1 [==============================] - 0s 439ms/step\n",
      "Processed 20 predictions out of 20 samples\n",
      "Metrics - Accuracy: 1.0000, F1: 1.0000, Recall: 1.0000\n",
      "\n",
      "Sampling natural text data (2007-end)...\n",
      "Categories present in range 2007-9933: [1, 2, 3, 4, 5]\n",
      "Category 1: 930 samples available\n",
      "\n",
      "Final sample distribution:\n",
      "Category 1: 20 samples\n",
      "Total samples: 20\n",
      "Evaluating 20 samples...\n",
      "1/1 [==============================] - 0s 400ms/step\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "1/1 [==============================] - 0s 410ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 378ms/step\n",
      "1/1 [==============================] - 0s 394ms/step\n",
      "1/1 [==============================] - 0s 407ms/step\n",
      "1/1 [==============================] - 0s 424ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 400ms/step\n",
      "1/1 [==============================] - 0s 380ms/step\n",
      "1/1 [==============================] - 0s 413ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 464ms/step\n",
      "1/1 [==============================] - 0s 451ms/step\n",
      "1/1 [==============================] - 0s 430ms/step\n",
      "1/1 [==============================] - 1s 540ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "Processed 20 predictions out of 20 samples\n",
      "Metrics - Accuracy: 1.0000, F1: 1.0000, Recall: 1.0000\n",
      "\n",
      "Evaluating GPT Multifactorial...\n",
      "\n",
      "Sampling multimedia data (0-2006)...\n",
      "Categories present in range 0-2006: [1, 2, 3, 4, 5]\n",
      "Category 1: 286 samples available\n",
      "Category 2: 986 samples available\n",
      "Category 3: 543 samples available\n",
      "Category 4: 167 samples available\n",
      "Category 5: 24 samples available\n",
      "\n",
      "Final sample distribution:\n",
      "Category 1: 20 samples\n",
      "Category 2: 20 samples\n",
      "Category 3: 20 samples\n",
      "Category 4: 20 samples\n",
      "Category 5: 20 samples\n",
      "Total samples: 100\n",
      "Evaluating 100 samples...\n",
      "Processed 100 predictions out of 100 samples\n",
      "Metrics - Accuracy: 0.2000, F1: 0.0721, Recall: 0.2000\n",
      "\n",
      "Sampling natural text data (2007-end)...\n",
      "Categories present in range 2007-9933: [1, 2, 3, 4, 5]\n",
      "Category 1: 930 samples available\n",
      "Category 2: 3640 samples available\n",
      "Category 3: 2354 samples available\n",
      "Category 4: 821 samples available\n",
      "Category 5: 181 samples available\n",
      "\n",
      "Final sample distribution:\n",
      "Category 1: 20 samples\n",
      "Category 2: 20 samples\n",
      "Category 3: 20 samples\n",
      "Category 4: 20 samples\n",
      "Category 5: 20 samples\n",
      "Total samples: 100\n",
      "Evaluating 100 samples...\n",
      "Processed 100 predictions out of 100 samples\n",
      "Metrics - Accuracy: 0.1800, F1: 0.0621, Recall: 0.1800\n",
      "\n",
      "Evaluating LSTM2 Multifactorial...\n",
      "\n",
      "Sampling multimedia data (0-2006)...\n",
      "Categories present in range 0-2006: [1, 2, 3, 4, 5]\n",
      "Category 1: 286 samples available\n",
      "Category 2: 986 samples available\n",
      "Category 3: 543 samples available\n",
      "Category 4: 167 samples available\n",
      "Category 5: 24 samples available\n",
      "\n",
      "Final sample distribution:\n",
      "Category 1: 20 samples\n",
      "Category 2: 20 samples\n",
      "Category 3: 20 samples\n",
      "Category 4: 20 samples\n",
      "Category 5: 20 samples\n",
      "Total samples: 100\n",
      "Evaluating 100 samples...\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "1/1 [==============================] - 0s 410ms/step\n",
      "1/1 [==============================] - 0s 402ms/step\n",
      "1/1 [==============================] - 0s 430ms/step\n",
      "1/1 [==============================] - 0s 395ms/step\n",
      "1/1 [==============================] - 0s 399ms/step\n",
      "1/1 [==============================] - 0s 393ms/step\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 441ms/step\n",
      "1/1 [==============================] - 0s 409ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 359ms/step\n",
      "1/1 [==============================] - 0s 359ms/step\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 400ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 359ms/step\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 384ms/step\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "1/1 [==============================] - 0s 414ms/step\n",
      "1/1 [==============================] - 0s 409ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 414ms/step\n",
      "1/1 [==============================] - 0s 475ms/step\n",
      "1/1 [==============================] - 0s 438ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 1s 536ms/step\n",
      "1/1 [==============================] - 0s 395ms/step\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 468ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 372ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "Processed 100 predictions out of 100 samples\n",
      "Metrics - Accuracy: 0.2300, F1: 0.1275, Recall: 0.2300\n",
      "\n",
      "Sampling natural text data (2007-end)...\n",
      "Categories present in range 2007-9933: [1, 2, 3, 4, 5]\n",
      "Category 1: 930 samples available\n",
      "Category 2: 3640 samples available\n",
      "Category 3: 2354 samples available\n",
      "Category 4: 821 samples available\n",
      "Category 5: 181 samples available\n",
      "\n",
      "Final sample distribution:\n",
      "Category 1: 20 samples\n",
      "Category 2: 20 samples\n",
      "Category 3: 20 samples\n",
      "Category 4: 20 samples\n",
      "Category 5: 20 samples\n",
      "Total samples: 100\n",
      "Evaluating 100 samples...\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 359ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "Processed 100 predictions out of 100 samples\n",
      "Metrics - Accuracy: 0.2600, F1: 0.1866, Recall: 0.2600\n",
      "\n",
      "Evaluating LSTM1 Multifactorial...\n",
      "\n",
      "Sampling multimedia data (0-2006)...\n",
      "Categories present in range 0-2006: [1, 2, 3, 4, 5]\n",
      "Category 1: 286 samples available\n",
      "Category 2: 986 samples available\n",
      "Category 3: 543 samples available\n",
      "Category 4: 167 samples available\n",
      "Category 5: 24 samples available\n",
      "\n",
      "Final sample distribution:\n",
      "Category 1: 20 samples\n",
      "Category 2: 20 samples\n",
      "Category 3: 20 samples\n",
      "Category 4: 20 samples\n",
      "Category 5: 20 samples\n",
      "Total samples: 100\n",
      "Evaluating 100 samples...\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 359ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 1s 558ms/step\n",
      "1/1 [==============================] - 0s 494ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 429ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "1/1 [==============================] - 0s 395ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 387ms/step\n",
      "1/1 [==============================] - 0s 397ms/step\n",
      "1/1 [==============================] - 0s 381ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 448ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 393ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 437ms/step\n",
      "1/1 [==============================] - 0s 448ms/step\n",
      "1/1 [==============================] - 0s 392ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "1/1 [==============================] - 0s 427ms/step\n",
      "1/1 [==============================] - 0s 405ms/step\n",
      "1/1 [==============================] - 0s 447ms/step\n",
      "1/1 [==============================] - 0s 423ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 400ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "Processed 100 predictions out of 100 samples\n",
      "Metrics - Accuracy: 0.2200, F1: 0.1670, Recall: 0.2200\n",
      "\n",
      "Sampling natural text data (2007-end)...\n",
      "Categories present in range 2007-9933: [1, 2, 3, 4, 5]\n",
      "Category 1: 930 samples available\n",
      "Category 2: 3640 samples available\n",
      "Category 3: 2354 samples available\n",
      "Category 4: 821 samples available\n",
      "Category 5: 181 samples available\n",
      "\n",
      "Final sample distribution:\n",
      "Category 1: 20 samples\n",
      "Category 2: 20 samples\n",
      "Category 3: 20 samples\n",
      "Category 4: 20 samples\n",
      "Category 5: 20 samples\n",
      "Total samples: 100\n",
      "Evaluating 100 samples...\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 415ms/step\n",
      "1/1 [==============================] - 1s 522ms/step\n",
      "1/1 [==============================] - 0s 400ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 1s 600ms/step\n",
      "1/1 [==============================] - 0s 464ms/step\n",
      "1/1 [==============================] - 0s 427ms/step\n",
      "1/1 [==============================] - 0s 467ms/step\n",
      "1/1 [==============================] - 1s 536ms/step\n",
      "1/1 [==============================] - 0s 470ms/step\n",
      "1/1 [==============================] - 0s 410ms/step\n",
      "1/1 [==============================] - 0s 394ms/step\n",
      "1/1 [==============================] - 0s 485ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "1/1 [==============================] - 0s 425ms/step\n",
      "1/1 [==============================] - 1s 501ms/step\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 445ms/step\n",
      "1/1 [==============================] - 1s 513ms/step\n",
      "1/1 [==============================] - 0s 481ms/step\n",
      "Processed 100 predictions out of 100 samples\n",
      "Metrics - Accuracy: 0.2700, F1: 0.2006, Recall: 0.2700\n",
      "\n",
      "Results:\n",
      "                   model     data_type  accuracy  f1_score  recall  n_samples\n",
      "0             GPT Binary    multimedia    0.7000    0.8235  0.7000         20\n",
      "1             GPT Binary  natural_text    0.9500    0.9744  0.9500         20\n",
      "2           LSTM2 Binary    multimedia    1.0000    1.0000  1.0000         20\n",
      "3           LSTM2 Binary  natural_text    1.0000    1.0000  1.0000         20\n",
      "4           LSTM1 Binary    multimedia    1.0000    1.0000  1.0000         20\n",
      "5           LSTM1 Binary  natural_text    1.0000    1.0000  1.0000         20\n",
      "6     GPT Multifactorial    multimedia    0.2000    0.0721  0.2000        100\n",
      "7     GPT Multifactorial  natural_text    0.1800    0.0621  0.1800        100\n",
      "8   LSTM2 Multifactorial    multimedia    0.2300    0.1275  0.2300        100\n",
      "9   LSTM2 Multifactorial  natural_text    0.2600    0.1866  0.2600        100\n",
      "10  LSTM1 Multifactorial    multimedia    0.2200    0.1670  0.2200        100\n",
      "11  LSTM1 Multifactorial  natural_text    0.2700    0.2006  0.2700        100\n",
      "\n",
      "Summary by model type and data type:\n",
      "                                  accuracy     f1_score     recall      \\\n",
      "                                      mean std     mean std   mean std   \n",
      "model                data_type                                           \n",
      "GPT Binary           multimedia     0.7000 NaN   0.8235 NaN 0.7000 NaN   \n",
      "                     natural_text   0.9500 NaN   0.9744 NaN 0.9500 NaN   \n",
      "GPT Multifactorial   multimedia     0.2000 NaN   0.0721 NaN 0.2000 NaN   \n",
      "                     natural_text   0.1800 NaN   0.0621 NaN 0.1800 NaN   \n",
      "LSTM1 Binary         multimedia     1.0000 NaN   1.0000 NaN 1.0000 NaN   \n",
      "                     natural_text   1.0000 NaN   1.0000 NaN 1.0000 NaN   \n",
      "LSTM1 Multifactorial multimedia     0.2200 NaN   0.1670 NaN 0.2200 NaN   \n",
      "                     natural_text   0.2700 NaN   0.2006 NaN 0.2700 NaN   \n",
      "LSTM2 Binary         multimedia     1.0000 NaN   1.0000 NaN 1.0000 NaN   \n",
      "                     natural_text   1.0000 NaN   1.0000 NaN 1.0000 NaN   \n",
      "LSTM2 Multifactorial multimedia     0.2300 NaN   0.1275 NaN 0.2300 NaN   \n",
      "                     natural_text   0.2600 NaN   0.1866 NaN 0.2600 NaN   \n",
      "\n",
      "                                  n_samples            \n",
      "                                       mean  min  max  \n",
      "model                data_type                         \n",
      "GPT Binary           multimedia     20.0000   20   20  \n",
      "                     natural_text   20.0000   20   20  \n",
      "GPT Multifactorial   multimedia    100.0000  100  100  \n",
      "                     natural_text  100.0000  100  100  \n",
      "LSTM1 Binary         multimedia     20.0000   20   20  \n",
      "                     natural_text   20.0000   20   20  \n",
      "LSTM1 Multifactorial multimedia    100.0000  100  100  \n",
      "                     natural_text  100.0000  100  100  \n",
      "LSTM2 Binary         multimedia     20.0000   20   20  \n",
      "                     natural_text   20.0000   20   20  \n",
      "LSTM2 Multifactorial multimedia    100.0000  100  100  \n",
      "                     natural_text  100.0000  100  100  \n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'GPT Binary': (model_5k_gpt_finetuning_binary, False, 'finetuning'),\n",
    "    'LSTM2 Binary': (classifier_lstm2_binary, False, 'lstm'),\n",
    "    'LSTM1 Binary': (classifier_lstm1_binary, False, 'lstm'),\n",
    "    'GPT Multifactorial': (model_12k_gpt_finetuning_multifactorial, True, 'finetuning'),\n",
    "    'LSTM2 Multifactorial': (classifier_lstm2_multifactorial, True, 'lstm'),\n",
    "    'LSTM1 Multifactorial': (classifier_lstm1_multifactorial, True, 'lstm')\n",
    "}\n",
    "\n",
    "# Run comparison\n",
    "results_df = compare_models_performance(dataset, models)\n",
    "\n",
    "# Display results with better formatting\n",
    "print(\"\\nResults:\")\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "print(results_df)\n",
    "# Show detailed summary statistics\n",
    "print(\"\\nSummary by model type and data type:\")\n",
    "summary = results_df.groupby(['model', 'data_type']).agg({\n",
    "    'accuracy': ['mean', 'std'],\n",
    "    'f1_score': ['mean', 'std'],\n",
    "    'recall': ['mean', 'std'],\n",
    "    'n_samples': ['mean', 'min', 'max']\n",
    "}).round(4)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>data_type</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>n_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT Binary</td>\n",
       "      <td>multimedia</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.8235</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT Binary</td>\n",
       "      <td>natural_text</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSTM2 Binary</td>\n",
       "      <td>multimedia</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTM2 Binary</td>\n",
       "      <td>natural_text</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LSTM1 Binary</td>\n",
       "      <td>multimedia</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LSTM1 Binary</td>\n",
       "      <td>natural_text</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GPT Multifactorial</td>\n",
       "      <td>multimedia</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GPT Multifactorial</td>\n",
       "      <td>natural_text</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.0621</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LSTM2 Multifactorial</td>\n",
       "      <td>multimedia</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.1275</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LSTM2 Multifactorial</td>\n",
       "      <td>natural_text</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LSTM1 Multifactorial</td>\n",
       "      <td>multimedia</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.1670</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LSTM1 Multifactorial</td>\n",
       "      <td>natural_text</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.2006</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model     data_type  accuracy  f1_score  recall  n_samples\n",
       "0             GPT Binary    multimedia    0.7000    0.8235  0.7000         20\n",
       "1             GPT Binary  natural_text    0.9500    0.9744  0.9500         20\n",
       "2           LSTM2 Binary    multimedia    1.0000    1.0000  1.0000         20\n",
       "3           LSTM2 Binary  natural_text    1.0000    1.0000  1.0000         20\n",
       "4           LSTM1 Binary    multimedia    1.0000    1.0000  1.0000         20\n",
       "5           LSTM1 Binary  natural_text    1.0000    1.0000  1.0000         20\n",
       "6     GPT Multifactorial    multimedia    0.2000    0.0721  0.2000        100\n",
       "7     GPT Multifactorial  natural_text    0.1800    0.0621  0.1800        100\n",
       "8   LSTM2 Multifactorial    multimedia    0.2300    0.1275  0.2300        100\n",
       "9   LSTM2 Multifactorial  natural_text    0.2600    0.1866  0.2600        100\n",
       "10  LSTM1 Multifactorial    multimedia    0.2200    0.1670  0.2200        100\n",
       "11  LSTM1 Multifactorial  natural_text    0.2700    0.2006  0.2700        100"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propmts Results LLM ChatGPT vs Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mi hermana siempre me consuela. Debe ser porqu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>los platos y platitos forman una estrella. Los...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>¿Qué pinta un pintor cuando se aburre? Abstrac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>del presupuesto _del cielo_. Entónces es cuand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mismo joven rubio de la imagen anterior, pero ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5821</th>\n",
       "      <td>Estaba en un restaurante y mientras iba al bañ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5822</th>\n",
       "      <td>corriendo, dando brincos increibles y vueltas ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5823</th>\n",
       "      <td>con buenos parques de artillería y fuertes res...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5824</th>\n",
       "      <td>y por esta causa me afligía más que de antes. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5825</th>\n",
       "      <td>gitano. Contó también el concierto que entre P...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5826 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     Mi hermana siempre me consuela. Debe ser porqu...      1\n",
       "1     los platos y platitos forman una estrella. Los...      0\n",
       "2     ¿Qué pinta un pintor cuando se aburre? Abstrac...      1\n",
       "3     del presupuesto _del cielo_. Entónces es cuand...      0\n",
       "4     Mismo joven rubio de la imagen anterior, pero ...      1\n",
       "...                                                 ...    ...\n",
       "5821  Estaba en un restaurante y mientras iba al bañ...      1\n",
       "5822  corriendo, dando brincos increibles y vueltas ...      0\n",
       "5823  con buenos parques de artillería y fuertes res...      0\n",
       "5824  y por esta causa me afligía más que de antes. ...      0\n",
       "5825  gitano. Contó también el concierto que entre P...      0\n",
       "\n",
       "[5826 rows x 2 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/testing.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  label\n",
      "0   en ella más de la cuenta. Esto se iba murmuran...      0\n",
      "1   un bravo sir Rogerio, que batalló en compañía ...      0\n",
      "2   familia; rostro enjuto, nariz aguileña, aspect...      0\n",
      "3   Una pregunta para todos los racistas, de verda...      1\n",
      "4   por muerto a don Martín, cogió los cuartos del...      0\n",
      "5   todo. FÁBULA XVI. _SIRINGA TRANSFORMADA EN CAÑ...      0\n",
      "6    ¿Cuál es la diferencia entre un bebé y una bo...      1\n",
      "7   como te gustan los hombres ? Yo: lejos y callados      1\n",
      "8   Yo esperando que sean las 5pm para ver el part...      1\n",
      "9   casa y reino de nuestros padres, y esta nuestr...      0\n",
      "10   ¿Sabes por qué los niños con cáncer no pueden...      1\n",
      "11  le di por los pechos, y así los despaché a tod...      0\n",
      "12  miraban y alababan, pero ningún rey, ni otro a...      0\n",
      "13   ¿Cómo se llama el mejor amigo de un robot? ¡USB!      1\n",
      "14   ¿Por qué la modelo fitness se hizo un tatuaje...      1\n",
      "15  ninguna sobre los destinos de la Europa y del ...      0\n",
      "16  que se encuentra en samoa, tahitiano, sandwich...      0\n",
      "17  - Se abre el telón y aparecen cientos de barra...      1\n",
      "18  de libros, tiesa y rubia, con un perfil anticu...      0\n",
      "19  Estoy saliendo con una chica que podría ser mi...      1\n",
      "20  sobre la tumba? ¿Cuál es el brazo que va a mov...      0\n",
      "21  sentí estremecerse mi pecho, porque sus palabr...      0\n",
      "22  abstenerse. No os conduciré yo por eminencias ...      0\n",
      "23  -¿Ha visto usted como toca mi hijo el violín? ...      1\n",
      "24  -¿Que te apuestas a que hago una tortilla haci...      1\n",
      "25  porque Guillermo Borsiere, que gime hace poco ...      0\n",
      "26  - Míre, jefe, como ayer llegué tarde le he tra...      1\n",
      "27   ¿Qué usan los magos para escribir?\\n Plumas e...      1\n",
      "28  gitanica no entrase en la cárcel, y todos los ...      0\n",
      "29  Iban dos lombrices caminando de paseo y charla...      1\n",
      "30  Todo el mundo en ese carril ha visto destino f...      1\n",
      "31  -Jaimito, ¿quien fue Juana de Arco? -Una droga...      1\n",
      "32  en medio de este enorme bullicio! ¡Cuánto debe...      0\n",
      "33  ¿Qué hace un boxeador cuando quiere descansar?...      1\n",
      "34  está? —¡Ay, ay, ay, chico, eso es más complica...      0\n",
      "35      ¿Qué hace Thor en la montaña? Martillar-bres.      1\n",
      "36  se la arrebata de su presencia, y la lleva á p...      0\n",
      "37  --Venga el asno, señor huésped; que también sa...      0\n",
      "38   ¿Por qué el café siempre está estresado?\\n Po...      1\n",
      "39  -de quien está boquita? Y ésta naricita? Y ést...      1\n"
     ]
    }
   ],
   "source": [
    "class_0 = df[df['label'] == 0]\n",
    "class_1 = df[df['label'] == 1]\n",
    "\n",
    "# Calculate the number of samples per class for balance (10 samples each)\n",
    "n_samples = 20\n",
    "\n",
    "# Randomly sample from each class\n",
    "class_0_sampled = resample(class_0, n_samples=n_samples, random_state=42)\n",
    "class_1_sampled = resample(class_1, n_samples=n_samples, random_state=42)\n",
    "\n",
    "# Combine sampled data\n",
    "balanced_sample = pd.concat([class_0_sampled, class_1_sampled])\n",
    "\n",
    "# Shuffle the resulting dataframe\n",
    "balanced_sample = balanced_sample.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Display the selected samples\n",
    "print(balanced_sample)\n",
    "\n",
    "balanced_sample.to_csv(\"data/balanced_sample.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating GPT Binary...\n",
      "\n",
      "Evaluating LSTM2 Binary...\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 493ms/step\n",
      "1/1 [==============================] - 0s 395ms/step\n",
      "1/1 [==============================] - 0s 393ms/step\n",
      "1/1 [==============================] - 0s 425ms/step\n",
      "1/1 [==============================] - 0s 446ms/step\n",
      "1/1 [==============================] - 0s 415ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 462ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 381ms/step\n",
      "1/1 [==============================] - 0s 432ms/step\n",
      "1/1 [==============================] - 0s 384ms/step\n",
      "1/1 [==============================] - 0s 417ms/step\n",
      "1/1 [==============================] - 0s 395ms/step\n",
      "1/1 [==============================] - 0s 405ms/step\n",
      "1/1 [==============================] - 0s 420ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 424ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 442ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 372ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 441ms/step\n",
      "1/1 [==============================] - 0s 408ms/step\n",
      "1/1 [==============================] - 0s 436ms/step\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "1/1 [==============================] - 0s 378ms/step\n",
      "1/1 [==============================] - 0s 478ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 416ms/step\n",
      "\n",
      "Evaluating LSTM1 Binary...\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 429ms/step\n",
      "1/1 [==============================] - 0s 387ms/step\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "1/1 [==============================] - 0s 420ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 359ms/step\n",
      "1/1 [==============================] - 0s 393ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 378ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 359ms/step\n",
      "1/1 [==============================] - 0s 402ms/step\n",
      "1/1 [==============================] - 0s 419ms/step\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 407ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "\n",
      "Evaluating GPT Multifactorial...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating LSTM2 Multifactorial...\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 472ms/step\n",
      "1/1 [==============================] - 0s 403ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 380ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 430ms/step\n",
      "1/1 [==============================] - 0s 398ms/step\n",
      "1/1 [==============================] - 0s 400ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 407ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 1s 511ms/step\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 420ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 450ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 457ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 413ms/step\n",
      "1/1 [==============================] - 0s 434ms/step\n",
      "1/1 [==============================] - 0s 384ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 450ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "\n",
      "Evaluating LSTM1 Multifactorial...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 0s 469ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 477ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "1/1 [==============================] - 0s 411ms/step\n",
      "1/1 [==============================] - 0s 437ms/step\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 402ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 379ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "1/1 [==============================] - 0s 379ms/step\n",
      "1/1 [==============================] - 0s 381ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 414ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 397ms/step\n",
      "1/1 [==============================] - 1s 504ms/step\n",
      "1/1 [==============================] - 0s 413ms/step\n",
      "1/1 [==============================] - 0s 435ms/step\n",
      "1/1 [==============================] - 0s 443ms/step\n",
      "1/1 [==============================] - 0s 403ms/step\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 424ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 402ms/step\n",
      "1/1 [==============================] - 0s 424ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 475ms/step\n",
      "1/1 [==============================] - 0s 469ms/step\n",
      "1/1 [==============================] - 0s 395ms/step\n",
      "1/1 [==============================] - 0s 416ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 380ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 411ms/step\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 390ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 404ms/step\n",
      "1/1 [==============================] - 0s 421ms/step\n",
      "\n",
      "Binary Classification Results:\n",
      "==============================\n",
      "\n",
      "GPT Binary\n",
      "----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        20\n",
      "           1       1.00      0.70      0.82        20\n",
      "\n",
      "    accuracy                           0.85        40\n",
      "   macro avg       0.88      0.85      0.85        40\n",
      "weighted avg       0.88      0.85      0.85        40\n",
      "\n",
      "\n",
      "LSTM2 Binary\n",
      "------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        40\n",
      "   macro avg       1.00      1.00      1.00        40\n",
      "weighted avg       1.00      1.00      1.00        40\n",
      "\n",
      "\n",
      "LSTM1 Binary\n",
      "------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        20\n",
      "           1       1.00      0.90      0.95        20\n",
      "\n",
      "    accuracy                           0.95        40\n",
      "   macro avg       0.95      0.95      0.95        40\n",
      "weighted avg       0.95      0.95      0.95        40\n",
      "\n",
      "\n",
      "Multifactorial Classification Results:\n",
      "====================================\n",
      "\n",
      "GPT Multifactorial\n",
      "------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00        20\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.20      0.90      0.32        20\n",
      "           4       0.00      0.00      0.00        20\n",
      "           5       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.18       100\n",
      "   macro avg       0.03      0.15      0.05       100\n",
      "weighted avg       0.04      0.18      0.06       100\n",
      "\n",
      "\n",
      "LSTM2 Multifactorial\n",
      "--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00        20\n",
      "           2       0.22      0.90      0.36        20\n",
      "           3       0.23      0.15      0.18        20\n",
      "           4       0.60      0.15      0.24        20\n",
      "           5       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.24       100\n",
      "   macro avg       0.18      0.20      0.13       100\n",
      "weighted avg       0.21      0.24      0.16       100\n",
      "\n",
      "\n",
      "LSTM1 Multifactorial\n",
      "--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.10      0.16        20\n",
      "           2       0.28      1.00      0.43        20\n",
      "           3       0.33      0.05      0.09        20\n",
      "           4       0.35      0.35      0.35        20\n",
      "           5       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.30       100\n",
      "   macro avg       0.27      0.30      0.21       100\n",
      "weighted avg       0.27      0.30      0.21       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAo0AAAIjCAYAAABmuyHTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABgXUlEQVR4nO3deVxUZfvH8e+AMiACKqJAKq655JoV7kvuWY+oZWolmlqZ9stISyvXFlrdHk3bXHLJdtstdzOX3EhzSw2lRVRQMVBB4fz+KOdxBDxgDGdkPu9e5/Xq3Ge7Zs5MXF33fe6xGYZhCAAAALgCL6sDAAAAgPsjaQQAAIApkkYAAACYImkEAACAKZJGAAAAmCJpBAAAgCmSRgAAAJgiaQQAAIApkkYAAACYImnENWf//v3q2LGjgoKCZLPZtGTJkgI9/6FDh2Sz2TR37twCPe+1rE2bNmrTpo3VYaCA5Od+9u/fX5UrV3ZqS01N1aBBgxQaGiqbzabhw4cXeIyuNHfuXNlsNh06dCjfx+b0fgCegqQRV+XgwYN68MEHVbVqVfn6+iowMFDNmzfX1KlTdfbsWZdeOzo6Wjt37tTzzz+v+fPn66abbnLp9QpT//79ZbPZFBgYmOP7uH//ftlsNtlsNr366qv5Pv+ff/6p8ePHKy4urgCiLRyVK1fW7bffbrrfF198odatW6tcuXIqUaKEqlatql69emnp0qWS/k6ULr53V1rGjx/vuK7NZlP79u1zvN5bb73lOGbLli2O9iNHjmjUqFFq27atAgICZLPZtHr16jy/Xld/BnKS38/FCy+8oLlz52rIkCGaP3++7rvvvgKJ4/JrFPT/EAL4d4pZHQCuPV999ZXuuusu2e129evXT3Xr1lVGRobWrVunkSNHateuXXrzzTddcu2zZ89qw4YNevrppzVs2DCXXCMiIkJnz55V8eLFXXJ+M8WKFdOZM2f0xRdfqFevXk7bFi5cKF9fX507d+6qzv3nn39qwoQJqly5sho2bJjn47777rurul5hefXVVzVy5Ei1bt1ao0ePVokSJXTgwAEtX75cixcvVufOnfX0009r0KBBjmM2b96sadOm6amnnlLt2rUd7fXr13f8u6+vr1atWqXExESFhoY6XTO3e7Fv3z699NJLqlGjhurVq6cNGzbk+/W48jOQkyt9Lt566y1lZWU5ta1cuVJNmjTRuHHjCiyGy73wwgu68847FRUVVeDnvu+++9S7d2/Z7fYCPzdQlJE0Il/i4+PVu3dvRUREaOXKlQoLC3NsGzp0qA4cOKCvvvrKZdc/fvy4JKlUqVIuu4bNZpOvr6/Lzm/GbrerefPmeu+997IlDIsWLVLXrl318ccfF0osZ86cUYkSJeTj41Mo17saFy5c0LPPPqsOHTrkmNweO3ZMktShQwendl9fX02bNk0dOnTItau2efPm2rx5s95//309+uijjvbff/9d33//vbp3757tXjRu3FjJyckqU6aMPvroI9111135fk3u9BnI6X+ejh07pjp16hTK9QtSWlqa/P395e3tLW9vb6vDAa45dE8jX15++WWlpqbqnXfecUoYL6pevbrTH9eLf9CrVasmu92uypUr66mnnlJ6errTcRe7INetW6dbbrlFvr6+qlq1qt59913HPuPHj1dERIQkaeTIkbLZbI6xRbmNMxo/frxsNptT27Jly9SiRQuVKlVKJUuWVM2aNfXUU085tuc2pnHlypVq2bKl/P39VapUKXXr1k179uzJ8XoHDhxQ//79VapUKQUFBWnAgAE6c+ZM7m/sZfr27atvvvlGp06dcrRt3rxZ+/fvV9++fbPtf+LECY0YMUL16tVTyZIlFRgYqC5duuinn35y7LN69WrdfPPNkqQBAwY4ujgvvs42bdqobt262rp1q1q1aqUSJUo43pfLx8BFR0fL19c32+vv1KmTSpcurT///DPPr/XfSkpK0unTp9W8efMct5crV+6qz+3r66sePXpo0aJFTu3vvfeeSpcurU6dOmU7JiAgQGXKlLnqa16U389ATp91yXz8ntnn4tLv1urVq2Wz2RQfH6+vvvrKse+hQ4eUkZGhsWPHqnHjxgoKCpK/v79atmypVatWZbtmVlaWpk6dqnr16snX11chISHq3Lmzo5vfZrMpLS1N8+bNc1yjf//+juO3b9+uLl26KDAwUCVLllS7du20cePGHF/3mjVr9PDDD6tcuXKqUKFCru/JZ599pq5duyo8PFx2u13VqlXTs88+q8zMzBzfN8ATkTQiX7744gtVrVpVzZo1y9P+gwYN0tixY3XjjTdq8uTJat26tWJjY9W7d+9s+x44cEB33nmnOnTooNdee02lS5dW//79tWvXLklSjx49NHnyZElSnz59NH/+fE2ZMiVf8e/atUu333670tPTNXHiRL322mv6z3/+ox9++OGKxy1fvlydOnXSsWPHNH78eMXExGj9+vVq3rx5jn+Me/Xqpb/++kuxsbHq1auX5s6dqwkTJuQ5zh49eshms+mTTz5xtC1atEi1atXSjTfemG3/X3/9VUuWLNHtt9+uSZMmaeTIkdq5c6dat27tSOBq166tiRMnSpIeeOABzZ8/X/Pnz1erVq0c50lOTlaXLl3UsGFDTZkyRW3bts0xvqlTpyokJETR0dGOP6pvvPGGvvvuO/33v/9VeHh4nl/rv1WuXDn5+fnpiy++0IkTJwr8/H379tWPP/6ogwcPOtoWLVqkO++806VDGPL7GbhaeflcXLrv/PnzVbZsWTVs2NCxb0hIiE6fPq23335bbdq00UsvvaTx48fr+PHj6tSpU7axkgMHDtTw4cNVsWJFvfTSSxo1apR8fX0did/8+fNlt9vVsmVLxzUefPBBSX9/h1u2bKmffvpJTzzxhMaMGaP4+Hi1adNGmzZtyhbzww8/rN27d2vs2LEaNWpUru/D3LlzVbJkScXExGjq1Klq3Lix6TGAxzGAPEpJSTEkGd26dcvT/nFxcYYkY9CgQU7tI0aMMCQZK1eudLRFREQYkoy1a9c62o4dO2bY7Xbj8ccfd7TFx8cbkoxXXnnF6ZzR0dFGREREthjGjRtnXPoxnzx5siHJOH78eK5xX7zGnDlzHG0NGzY0ypUrZyQnJzvafvrpJ8PLy8vo169ftuvdf//9Tufs3r27ERwcnOs1L30d/v7+hmEYxp133mm0a9fOMAzDyMzMNEJDQ40JEybk+B6cO3fOyMzMzPY67Ha7MXHiREfb5s2bs722i1q3bm1IMmbNmpXjttatWzu1ffvtt4Yk47nnnjN+/fVXo2TJkkZUVJTpa8yviIgIo2vXrlfcZ+zYsYYkw9/f3+jSpYvx/PPPG1u3br3iMR9++KEhyVi1atUVr3vhwgUjNDTUePbZZw3DMIzdu3cbkow1a9YYc+bMMSQZmzdvvqpr5ORqPwOXf9YvuhhjfHy8o+3y+3mlz0VO362c7smFCxeM9PR0p7aTJ08a5cuXd/o+rFy50pBk/N///V+2a2VlZTn+3d/f34iOjs62T1RUlOHj42McPHjQ0fbnn38aAQEBRqtWrbK97hYtWhgXLlxwOkdO78mZM2eyXevBBx80SpQoYZw7d87Rltt/awBPQKUReXb69GlJf3e/5cXXX38tSYqJiXFqf/zxxyUp29jHOnXqqGXLlo71kJAQ1axZU7/++utVx3y5i2MhP/vss2yD+3Nz5MgRxcXFqX///k7djvXr11eHDh0cr/NSDz30kNN6y5YtlZyc7HgP86Jv375avXq1EhMTtXLlSiUmJubYLSn9PQbOy+vvr3NmZqaSk5MdXe/btm3L8zXtdrsGDBiQp307duyoBx98UBMnTlSPHj3k6+urN954I8/XKkgTJkzQokWL1KhRI3377bd6+umn1bhxY914443ZutDzy9vbW7169dJ7770n6e8HUSpWrOj0WXWV/HwGrObt7e0Y+5qVlaUTJ07owoULuummm5w+gx9//LFsNluOD9Hk1L1+qczMTH333XeKiopS1apVHe1hYWHq27ev1q1bl+07Nnjw4DyNX/Tz83P8+19//aWkpCS1bNlSZ86c0d69e02PBzwBSSPyLDAwUNLf/0HNi8OHD8vLy0vVq1d3ag8NDVWpUqV0+PBhp/ZKlSplO0fp0qV18uTJq4w4u7vvvlvNmzfXoEGDVL58efXu3VsffPDBFRPIi3HWrFkz27batWsrKSlJaWlpTu2Xv5bSpUtLUr5ey2233aaAgAC9//77WrhwoW6++eZs7+VFWVlZmjx5smrUqCG73a6yZcsqJCREO3bsUEpKSp6ved111+XroZdXX31VZcqUUVxcnKZNm5an8YPHjx9XYmKiY0lNTc3z9a6kT58++v7773Xy5El999136tu3r7Zv36477rjjXz9p3LdvX+3evVs//fSTFi1apN69e5smOAUhP58BdzBv3jzVr19fvr6+Cg4OVkhIiL766iunz+DBgwcVHh5+VeM+jx8/rjNnzuT6XczKytJvv/3m1F6lSpU8nXvXrl3q3r27goKCFBgYqJCQEN17772SlK/vEFCUkTQizwIDAxUeHq6ff/45X8fl9Y9rbtUAwzCu+hqXD2L38/PT2rVrtXz5ct13333asWOH7r77bnXo0KFAB7z/m9dykd1uV48ePTRv3jx9+umnV6wwvfDCC4qJiVGrVq20YMECffvtt1q2bJluuOGGPFdUJedqS15s377d8XTyzp0783TMzTffrLCwMMdSUHMNXhQYGKgOHTpo4cKFio6O1sGDB3Mc65YfkZGRqlatmoYPH674+PhCq/bl5zOQ1++AqyxYsED9+/dXtWrV9M4772jp0qVatmyZbr311nx9BgtaXj7Tp06dUuvWrfXTTz9p4sSJ+uKLL7Rs2TK99NJLkmRp/IA7Ycod5Mvtt9+uN998Uxs2bFDTpk2vuG9ERISysrK0f/9+p3nwjh49qlOnTjmehC4IpUuXdnrK9KLLq5mS5OXlpXbt2qldu3aaNGmSXnjhBT399NNatWpVjhM5X4xz37592bbt3btXZcuWlb+//79/ETno27evZs+eLS8vrxwfHrroo48+Utu2bfXOO+84tZ86dUply5Z1rBdkdSwtLU0DBgxQnTp11KxZM7388svq3r2740nc3CxcuNBp0upLuxkL2k033aR58+bpyJEj//pcffr00XPPPafatWvna47Lfyuvn4GL1exTp045TUmV03fgcgXxufjoo49UtWpVffLJJ07nu7wbulq1avr222914sSJK1Ybc4opJCREJUqUyPW76OXlpYoVK+Y79tWrVys5OVmffPKJ0wNA8fHx+T4XUJRRaUS+PPHEE/L399egQYN09OjRbNsPHjyoqVOnSvq7a01StiecJ02aJEnq2rVrgcVVrVo1paSkaMeOHY62I0eO6NNPP3XaL6enay8mAJdPA3RRWFiYGjZsqHnz5jklpj///LO+++47x+t0hbZt2+rZZ5/V9OnTs00ufSlvb+9sVcwPP/xQf/zxh1PbxeQ2pwQ7v5588kklJCRo3rx5mjRpkipXrqzo6Ohc38eLmjdvrvbt2zuWf5s0njlzJtcJtL/55htJOQ8tyK9BgwZp3Lhxeu211/71ufIjr5+BatWqSZLWrl3raLs4bY2ZgvhcXKyuX/o53LRpU7Z707NnTxmGkeNsApce6+/vny0eb29vdezYUZ999pnTrAVHjx7VokWL1KJFC8cwmn8be0ZGhl5//fV8nwsoyqg0Il+qVaumRYsW6e6771bt2rWdfhFm/fr1+vDDDx3zqTVo0EDR0dF68803Hd0/P/74o+bNm6eoqKhcp3O5Gr1799aTTz6p7t276//+7/905swZzZw5U9dff73TIPyJEydq7dq16tq1qyIiInTs2DG9/vrrqlChglq0aJHr+V955RV16dJFTZs21cCBA3X27Fn997//VVBQkONn51zBy8tLzzzzjOl+t99+uyZOnKgBAwaoWbNm2rlzpxYuXJgtIatWrZpKlSqlWbNmKSAgQP7+/oqMjMzzuK+LVq5cqddff13jxo1zTP8yZ84ctWnTRmPGjNHLL7+cr/OZOXDggJ577rls7Y0aNVJkZKSaNWumJk2aqHPnzqpYsaJOnTqlJUuW6Pvvv1dUVJQaNWr0r2OIiIjI872+GOvF6aLmz5+vdevWSVKe7uel8voZ6NixoypVqqSBAwdq5MiR8vb21uzZsxUSEqKEhIQrHlsQn4vbb79dn3zyibp3766uXbsqPj5es2bNUp06dZzGrbZt21b33Xefpk2bpv3796tz587KysrS999/r7Zt2zp+6alx48Zavny5Jk2apPDwcFWpUkWRkZF67rnnHHOtPvzwwypWrJjeeOMNpaenX/XnrlmzZipdurSio6P1f//3f7LZbJo/f36+hpMAHsG6B7dxLfvll1+MwYMHG5UrVzZ8fHyMgIAAo3nz5sZ///tfp+kpzp8/b0yYMMGoUqWKUbx4caNixYrG6NGjnfYxjNynVbl8apDcptwxDMP47rvvjLp16xo+Pj5GzZo1jQULFmSbhmTFihVGt27djPDwcMPHx8cIDw83+vTpY/zyyy/ZrnH59CPLly83mjdvbvj5+RmBgYHGHXfcYezevdtpn4vXu3xKn5ym+MjJpdOt5Ca3KXcef/xxIywszPDz8zOaN29ubNiwIcepcj777DOjTp06RrFixZxeZ+vWrY0bbrghx2teep7Tp08bERERxo033micP3/eab/HHnvM8PLyMjZs2HDF15AfF6djymkZOHCgcf78eeOtt94yoqKijIiICMNutxslSpQwGjVqZLzyyivZpoG5KK9T7lxJblPu5BZvXv6Te7WfAcMwjK1btxqRkZGGj4+PUalSJWPSpEl5mnLHMHL/XOR1yp2srCzjhRdecNyDRo0aGV9++WWOx1+4cMF45ZVXjFq1ahk+Pj5GSEiI0aVLF6dpkvbu3Wu0atXK8PPzMyQ5Tb+zbds2o1OnTkbJkiWNEiVKGG3btjXWr1/vdI0rTYeU03vyww8/GE2aNDH8/PyM8PBw44knnnBMK3XpZ4Qpd+DJbIbB/0oBAADgyhjTCAAAAFMkjQAAADBF0ggAAABTJI0AAABuIjY2VjfffLMCAgJUrlw5RUVFZZub9Ny5cxo6dKiCg4NVsmRJ9ezZM8dp8C5lGIbGjh2rsLAw+fn5qX379tq/f3++YiNpBAAAcBNr1qzR0KFDtXHjRi1btkznz59Xx44dnX6u9rHHHtMXX3yhDz/8UGvWrNGff/6pHj16XPG8L7/8sqZNm6ZZs2Zp06ZN8vf3V6dOnfL1M6s8PQ0AAOCmjh8/rnLlymnNmjVq1aqVUlJSFBISokWLFunOO++U9PcvItWuXVsbNmxQkyZNsp3DMAyFh4fr8ccf14gRIyT9/Zvq5cuX19y5c6/4a1OXotIIAADgQunp6Tp9+rTTYvbrWRelpKRIkuNnN7du3arz5887/extrVq1VKlSpVx/HSs+Pl6JiYlOxwQFBSkyMjLXY3JSJH8R5veTGVaHgH/UGbLY6hBwicOz77E6BPzDz8fb6hAAt+NrYVbi12iYy879ZLey2X46c9y4caa/MpWVlaXhw4erefPmqlu3riQpMTFRPj4+Tr8xL0nly5dXYmJijue52F6+fPk8H5OTIpk0AgAAuIvRo0crJibGqc1ut5seN3ToUP3888+OnyG1GkkjAACAzXUj9ux2e56SxEsNGzZMX375pdauXasKFSo42kNDQ5WRkaFTp045VRuPHj2q0NDQHM91sf3o0aMKCwtzOqZhw4Z5jokxjQAAADab65Z8MAxDw4YN06effqqVK1eqSpUqTtsbN26s4sWLa8WKFY62ffv2KSEhQU2bNs3xnFWqVFFoaKjTMadPn9amTZtyPSYnJI0AAABuYujQoVqwYIEWLVqkgIAAJSYmKjExUWfPnpX09wMsAwcOVExMjFatWqWtW7dqwIABatq0qdOT07Vq1dKnn34qSbLZbBo+fLiee+45ff7559q5c6f69eun8PBwRUVF5Tk2uqcBAABc2D2dHzNnzpQktWnTxql9zpw56t+/vyRp8uTJ8vLyUs+ePZWenq5OnTrp9ddfd9p/3759jievJemJJ55QWlqaHnjgAZ06dUotWrTQ0qVL5evrm+fYiuQ8jTw97T54etq98PS0++DpaSA7S5+evukxl5377JbJLjt3YaLSCAAAkM+xh57IPWqxAAAAcGtUGgEAANxkTKM74x0CAACAKSqNAAAAjGk0RdIIAABA97Qp3iEAAACYotIIAABA97QpKo0AAAAwRaURAACAMY2meIcAAABgikojAAAAYxpNUWkEAACAKSqNAAAAjGk0RdIIAABA97Qp0moAAACYotIIAABA97Qp3iEAAACYotIIAABApdEU7xAAAABMUWkEAADw4ulpM1QaAQAAYIpKIwAAAGMaTZE0AgAAMLm3KdJqAAAAmKLSCAAAQPe0Kd4hAAAAmKLSCAAAwJhGU1QaAQAAYIpKIwAAAGMaTfEOAQAAwBSVRgAAAMY0miJpBAAAoHvaFO8QAAAATFFpdDOL5r2tdauXK+FwvOx2X9Wp10APDH1MFSOqWB1akdesVjk9escNalglWGFlSqjPq6v01ZbfHNtPL+6X43HPLNiqaV/uKqwwPdL2rVu04N3Z2rd7l5KSjuulSdPUum17q8PyaIsXLdS8Oe8oKem4rq9ZS6OeGqN69etbHZZH4l4UELqnTVFpdDM7tm/Rf3r21vS3F+rlaW8q88IFPfHogzp79ozVoRV5/r7F9PPhk3p8zqYct1d/8AOnZcjMH5SVZejzHw8XcqSe5+zZM6pxfU2NGD3G6lAgaek3X+vVl2P14MNDtfjDT1WzZi0NeXCgkpOTrQ7N43AvUJioNLqZF6fMclp/Ysxz6tmltfbv3a36jW6yKCrPsCzuTy2L+zPX7cdSzjmtd72potbuTtShY6muDs3jNWvRSs1atLI6DPxj/rw56nFnL0V17ylJembcBK1du1pLPvlYAwc/YHF0noV7UYAY02jK0qQxKSlJs2fP1oYNG5SYmChJCg0NVbNmzdS/f3+FhIRYGZ5bSEv9OyEJCAyyOBJcKiTIV50aVdBDM3+wOhSgUJ3PyNCe3bs0cPCDjjYvLy81adJMO37abmFknod7gcJmWVq9efNmXX/99Zo2bZqCgoLUqlUrtWrVSkFBQZo2bZpq1aqlLVu2mJ4nPT1dp0+fdlrS09ML4RW4XlZWlmZMeUl16zdSlWo1rA4Hl+jbqppSz52naxoe5+Spk8rMzFRwcLBTe3BwsJKSkiyKyjNxLwqYzea6pYiwrNL4yCOP6K677tKsWbNku+wNNQxDDz30kB555BFt2LDhiueJjY3VhAkTnNoee+IZxYy69sc+TXvleR06eEBT35xndSi4zH1tquuDdfFKP59ldSgAABQKy5LGn376SXPnzs2WMEqSzWbTY489pkaNGpmeZ/To0YqJiXFqO37m2s/qp736vDb+sEaTZ81VSLlQq8PBJZrWKqfrrwtS/6lrrQ4FKHSlS5WWt7d3tgctkpOTVbZsWYui8kzciwLGmEZTlr1DoaGh+vHHH3Pd/uOPP6p8+fKm57Hb7QoMDHRa7HZ7QYZaqAzD0LRXn9e6NSv16vR3FBZeweqQcJl+batr28Ek/Zxw0upQgEJX3MdHtevcoE0b/9cLlJWVpU2bNqh+A/P/0UfB4V4UMJuX65YiwrJK44gRI/TAAw9o69atateunSNBPHr0qFasWKG33npLr776qlXhWWbaK89rxXdf69mXp6qEv79OJP89LsXfv6Tsvr4WR1e0+duLqWpogGO9crmSqhdRWidTM/R7cpokKcCvuKIiI/T0gq1WhemRzpxJ0++/JTjW//zjD/2yb48CA4MUGhZuYWSe6b7oARrz1JO64Ya6qluvvhbMn6ezZ88qqnsPq0PzONwLFCbLksahQ4eqbNmymjx5sl5//XVlZmZKkry9vdW4cWPNnTtXvXr1sio8y3z+yfuSpJiH73dqH/nMs+p8e5QFEXmORtWC9fXYTo712H43S5IWrjmgITPXS5J6Nqssm82mj36ItyRGT7Vn9y4NHdzfsT71tZckSbfdEaWxE1+wKCrP1bnLbTp54oRenz5NSUnHVbNWbb3+xtsKpku00HEvClARemDFVWyGYRhWB3H+/HnHk15ly5ZV8eLF/9X5fj+ZURBhoQDUGbLY6hBwicOz77E6BPzDz8fb6hAAt+Nr4USAfv+Z6bJzn/18iMvOXZjcYnLv4sWLKywszOowAACApypCYw9dhXcIAAAApkgaAQAA3Ghy77Vr1+qOO+5QeHi4bDablixZclmothyXV155Jddzjh8/Ptv+tWrVyldcJI0AAABuJC0tTQ0aNNCMGTNy3H7kyBGnZfbs2bLZbOrZs+cVz3vDDTc4Hbdu3bp8xeUWYxoBAAAs5cIxjenp6dl+4thut+c6r3SXLl3UpUuXXM8XGur8ox+fffaZ2rZtq6pVq14xjmLFimU7Nj+oNAIAALiwezo2NlZBQUFOS2xsbIGEffToUX311VcaOHCg6b779+9XeHi4qlatqnvuuUcJCQmmx1yKSiMAAIAL5fSTxwX163Xz5s1TQECAevS48oTukZGRmjt3rmrWrKkjR45owoQJatmypX7++WcFBARc8diLSBoBAIDHs7lwcu8rdUX/W7Nnz9Y999wjX5Nfjbu0u7t+/fqKjIxURESEPvjggzxVKSWSRgAAgGvS999/r3379un999/P97GlSpXS9ddfrwMHDuT5GMY0AgAAj5fbNDYFsbjKO++8o8aNG6tBgwb5PjY1NVUHDx7M14+rkDQCAAC4kdTUVMXFxSkuLk6SFB8fr7i4OKcHV06fPq0PP/xQgwYNyvEc7dq10/Tp0x3rI0aM0Jo1a3To0CGtX79e3bt3l7e3t/r06ZPnuOieBgAAcF1BMN+2bNmitm3bOtYvPkQTHR2tuXPnSpIWL14swzByTfoOHjyopKQkx/rvv/+uPn36KDk5WSEhIWrRooU2btyokJCQPMdlMwzDuIrX49Z+P5lhdQj4R50hi60OAZc4PPseq0PAP/x8vK0OAXA7vhaWsvzvmuOyc6d9OMBl5y5MVBoBAIDHc+XYw6KCpBEAAHg8kkZzPAgDAAAAU1QaAQCAx6PSaI5KIwAAAExRaQQAAB6PSqM5Ko0AAAAwRaURAACAQqMpKo0AAAAwRaURAAB4PMY0mqPSCAAAAFNUGgEAgMej0miOpBEAAHg8kkZzdE8DAADAFJVGAADg8ag0mqPSCAAAAFNUGgEAACg0mqLSCAAAAFNUGgEAgMdjTKM5Ko0AAAAwRaURAAB4PCqN5kgaAQCAxyNpNEf3NAAAAExRaQQAAKDQaIpKIwAAAExRaQQAAB6PMY3mqDQCAADAVJGsNJYN8LE6BPzj/L4frQ4Bl/Dz6Wd1CADglqg0mqPSCAAAAFNFstIIAACQH1QazZE0AgAAj0fSaI7uaQAAAJii0ggAAECh0RSVRgAAAJii0ggAADweYxrNUWkEAACAKSqNAADA41FpNEelEQAAAKaoNAIAAI9HpdEcSSMAAAA5oym6pwEAAGCKSiMAAPB4dE+bo9IIAAAAU1QaAQCAx6PSaI5KIwAAAExRaQQAAB6PSqM5Ko0AAABuZO3atbrjjjsUHh4um82mJUuWOG3v37+/bDab09K5c2fT886YMUOVK1eWr6+vIiMj9eOPP+YrLpJGAADg8S5Pwgpyya+0tDQ1aNBAM2bMyHWfzp0768iRI47lvffeu+I533//fcXExGjcuHHatm2bGjRooE6dOunYsWN5jovuaQAAADfqne7SpYu6dOlyxX3sdrtCQ0PzfM5JkyZp8ODBGjBggCRp1qxZ+uqrrzR79myNGjUqT+eg0ggAAOBC6enpOn36tNOSnp7+r865evVqlStXTjVr1tSQIUOUnJyc674ZGRnaunWr2rdv72jz8vJS+/bttWHDhjxfk6QRAAB4PFd2T8fGxiooKMhpiY2NvepYO3furHfffVcrVqzQSy+9pDVr1qhLly7KzMzMcf+kpCRlZmaqfPnyTu3ly5dXYmJinq9L9zQAAIALjR49WjExMU5tdrv9qs/Xu3dvx7/Xq1dP9evXV7Vq1bR69Wq1a9fuqs9rhqQRAAB4PFdOuWO32/9VkmimatWqKlu2rA4cOJBj0li2bFl5e3vr6NGjTu1Hjx7N17hIuqcBAACuYb///ruSk5MVFhaW43YfHx81btxYK1ascLRlZWVpxYoVatq0aZ6vQ9IIAAA8ns3muiW/UlNTFRcXp7i4OElSfHy84uLilJCQoNTUVI0cOVIbN27UoUOHtGLFCnXr1k3Vq1dXp06dHOdo166dpk+f7liPiYnRW2+9pXnz5mnPnj0aMmSI0tLSHE9T5wXd0wAAAG5ky5Ytatu2rWP94njI6OhozZw5Uzt27NC8efN06tQphYeHq2PHjnr22WedusAPHjyopKQkx/rdd9+t48ePa+zYsUpMTFTDhg21dOnSbA/HXInNMAyjAF6fWzl3weoIcFHpm4dZHQIucXLzdPOdAMAivhaWsmqMXOqyc+9/xfzXWq4FVBoBAIDH46enzTGmEQAAAKaoNAIAAI/nyil3igoqjQAAADBFpREAAHg8Co3mqDQCAADAFJVGAADg8by8KDWaodIIAAAAU1QaAQCAx2NMozmSRgAA4PGYcscc3dMAAAAwRdLohhYvWqguHW7VzY3q6Z7ed2nnjh1Wh1Tkjbi/o9YtGKlj617V4RWx+mDSYNWIKOe0j92nmCaP6qXfV72k4z+8pvdeHaRyZQIsitgz8d1wH9wL98G9KBg2m+uWooKk0c0s/eZrvfpyrB58eKgWf/ipataspSEPDlRycrLVoRVpLW+srlnvr1Xrfq/q9iHTVayYt76cOUwlfH0c+7w8oqe6tqqre554Rx0HTVFYSJAWvzbIwqg9C98N98G9cB/cCxQmkkY3M3/eHPW4s5eiuvdUterV9cy4CfL19dWSTz62OrQirduw17Xgi03a82uidv7yhx4Yt0CVwsqoUZ2KkqTAkr7qH9VUT076RGs2/6Lte37TA+MWqGnDarqlXmVrg/cQfDfcB/fCfXAvCo7NZnPZUlSQNLqR8xkZ2rN7l5o0beZo8/LyUpMmzbTjp+0WRuZ5Akv6SpJOppyRJDWqXUk+xYtp5cZ9jn1+OXRUCUdOKLJ+FUti9CR8N9wH98J9cC9Q2Nw6afztt990//33X3Gf9PR0nT592mlJT08vpAgL1slTJ5WZmang4GCn9uDgYCUlJVkUleex2Wx6ZcSdWr/9oHYfPCJJCg0OVHrGeaWknnXa91jyaZUPDrQiTI/Cd8N9cC/cB/eiYFFpNOfWSeOJEyc0b968K+4TGxuroKAgp+WVl2ILKUIURVNG99IN1cPUb9Qcq0MBAMBtWDpP4+eff37F7b/++qvpOUaPHq2YmBinNsPb/q/iskrpUqXl7e2dbQBzcnKyypYta1FUnmXyk3fptpZ11X7gFP1x7JSjPTH5tOw+xRVU0s+p2lguOFBHk09bEKln4bvhPrgX7oN7UbCKUEHQZSxNGqOiomSz2WQYRq77mJV17Xa77HbnJPHchQIJr9AV9/FR7To3aNPGDbq1XXtJUlZWljZt2qDefe61OLqib/KTd+k/tzZQx8FTdfhP5/8Ib9+ToIzzF9Q2sqaWrIiTJNWIKKdKYWW0aUe8BdF6Fr4b7oN74T64FwWrKHUju4qlSWNYWJhef/11devWLcftcXFxaty4cSFHZa37ogdozFNP6oYb6qpuvfpaMH+ezp49q6juPawOrUibMrqX7u5yk+567E2lpp1T+eC/519MST2nc+nndTr1nOYu2aCXHu+hEylp+ivtnCY9eZc2/vSrftx5yNrgPQTfDffBvXAf3AsUJkuTxsaNG2vr1q25Jo1mVciiqHOX23TyxAm9Pn2akpKOq2at2nr9jbcVTFeDSz3Yq5Ukadnbw53aB4+drwVfbJIkPfHqx8rKMvTeq4Nk9ymm5ev36NHY9ws7VI/Fd8N9cC/cB/ei4FBoNGczLMzKvv/+e6Wlpalz5845bk9LS9OWLVvUunXrfJ33Wu2eLopK3zzM6hBwiZObp1sdAgDkytfCUtaNE1e67Nzbxt7qsnMXJksrjS1btrzidn9//3wnjAAAAPnFmEZzbj3lDgAAANyDpZVGAAAAd0Ch0RyVRgAAAJii0ggAADweYxrNUWkEAACAKSqNAADA41FoNEfSCAAAPB7d0+bongYAAIApKo0AAMDjUWg0R6URAAAApqg0AgAAj8eYRnNUGgEAAGCKSiMAAPB4FBrNUWkEAACAKSqNAADA4zGm0RxJIwAA8HjkjObongYAAIApKo0AAMDj0T1tjkojAAAATFFpBAAAHo9KozkqjQAAADBFpREAAHg8Co3mqDQCAADAFJVGAADg8RjTaI5KIwAA8Hg2m+uW/Fq7dq3uuOMOhYeHy2azacmSJY5t58+f15NPPql69erJ399f4eHh6tevn/78888rnnP8+PGy2WxOS61atfIVF0kjAACAG0lLS1ODBg00Y8aMbNvOnDmjbdu2acyYMdq2bZs++eQT7du3T//5z39Mz3vDDTfoyJEjjmXdunX5iovuaQAA4PHcqXu6S5cu6tKlS47bgoKCtGzZMqe26dOn65ZbblFCQoIqVaqU63mLFSum0NDQq46LSiMAAIALpaen6/Tp005Lenp6gZ0/JSVFNptNpUqVuuJ++/fvV3h4uKpWrap77rlHCQkJ+boOSSMAAPB4rhzTGBsbq6CgIKclNja2QOI+d+6cnnzySfXp00eBgYG57hcZGam5c+dq6dKlmjlzpuLj49WyZUv99ddfeb4W3dMAAAAuNHr0aMXExDi12e32f33e8+fPq1evXjIMQzNnzrzivpd2d9evX1+RkZGKiIjQBx98oIEDB+bpeiSNAADA43m5cEyj3W4vkCTxUhcTxsOHD2vlypVXrDLmpFSpUrr++ut14MCBPB9D9zQAAMA15GLCuH//fi1fvlzBwcH5PkdqaqoOHjyosLCwPB9D0ggAADyeO83TmJqaqri4OMXFxUmS4uPjFRcXp4SEBJ0/f1533nmntmzZooULFyozM1OJiYlKTExURkaG4xzt2rXT9OnTHesjRozQmjVrdOjQIa1fv17du3eXt7e3+vTpk+e46J4GAAAez52m3NmyZYvatm3rWL84HjI6Olrjx4/X559/Lklq2LCh03GrVq1SmzZtJEkHDx5UUlKSY9vvv/+uPn36KDk5WSEhIWrRooU2btyokJCQPMdF0ggAAOBG2rRpI8Mwct1+pW0XHTp0yGl98eLF/zYskkYAAAAv9yk0ui3GNAIAAMAUlUYAAODx3GlMo7ui0ggAAABTVBoBAIDHo9BojqQRrhV+vdUR4BJnMzKtDgFwO34+3laHAFwTSBoBAIDHs4lSoxmSRgAA4PGYcsccD8IAAADAFJVGAADg8ZhyxxyVRgAAAJii0ggAADwehUZzVBoBAABgikojAADweF6UGk1RaQQAAIApKo0AAMDjUWg0R9IIAAA8HlPumMtT0rhjx448n7B+/fpXHQwAAADcU56SxoYNG8pms8kwjBy3X9xms9mUmZlZoAECAAC4GoVGc3lKGuPj410dBwAAANxYnpLGiIgIV8cBAABgGabcMXdVU+7Mnz9fzZs3V3h4uA4fPixJmjJlij777LMCDQ4AAADuId9J48yZMxUTE6PbbrtNp06dcoxhLFWqlKZMmVLQ8QEAALiczYVLUZHvpPG///2v3nrrLT399NPy9vZ2tN90003auXNngQYHAAAA95DveRrj4+PVqFGjbO12u11paWkFEhQAAEBhYp5Gc/muNFapUkVxcXHZ2pcuXaratWsXREwAAACFysvmuqWoyHelMSYmRkOHDtW5c+dkGIZ+/PFHvffee4qNjdXbb7/tihgBAABgsXwnjYMGDZKfn5+eeeYZnTlzRn379lV4eLimTp2q3r17uyJGAAAAl6J72txV/fb0Pffco3vuuUdnzpxRamqqypUrV9BxAQAAwI1cVdIoSceOHdO+ffsk/Z2dh4SEFFhQAAAAhYlCo7l8Pwjz119/6b777lN4eLhat26t1q1bKzw8XPfee69SUlJcESMAAAAslu+kcdCgQdq0aZO++uornTp1SqdOndKXX36pLVu26MEHH3RFjAAAAC5ls9lcthQV+e6e/vLLL/Xtt9+qRYsWjrZOnTrprbfeUufOnQs0OAAAALiHfCeNwcHBCgoKytYeFBSk0qVLF0hQAAAAhakozafoKvnunn7mmWcUExOjxMRER1tiYqJGjhypMWPGFGhwAAAAhYHuaXN5qjQ2atTI6UXv379flSpVUqVKlSRJCQkJstvtOn78OOMaAQAAiqA8JY1RUVEuDgMAAMA6Race6Dp5ShrHjRvn6jgAAADgxq56cm8AAICiwqsIjT10lXwnjZmZmZo8ebI++OADJSQkKCMjw2n7iRMnCiw4AAAAuId8Pz09YcIETZo0SXfffbdSUlIUExOjHj16yMvLS+PHj3dBiAAAAK5ls7luKSrynTQuXLhQb731lh5//HEVK1ZMffr00dtvv62xY8dq48aNrogRAAAAFst30piYmKh69epJkkqWLOn4venbb79dX331VcFGBwAAUAiYp9FcvpPGChUq6MiRI5KkatWq6bvvvpMkbd68WXa7vWCjAwAAgFvId9LYvXt3rVixQpL0yCOPaMyYMapRo4b69eun+++/v8ADBAAAcDXGNJrL99PTL774ouPf7777bkVERGj9+vWqUaOG7rjjjgINzlMtXrRQ8+a8o6Sk47q+Zi2NemqM6tWvb3VYRV7zG8L1WM/GurF6iMKCS6rXs1/qi42/Orb7+xbXc/2b6Y6m1VQmwFeHjp7W65/H6e1vfrYwas+wfesWLXh3tvbt3qWkpON6adI0tW7b3uqwPBb3w73wN6NgMOWOuXxXGi/XpEkTxcTEKDIyUi+88EJBxOTRln7ztV59OVYPPjxUiz/8VDVr1tKQBwcqOTnZ6tCKPH/f4toZf1zDZ67OcftLg1uqQ+MIDXj1WzV8aL6mf7Zdk4e0UdfIKoUbqAc6e/aMalxfUyNG8/v27oD74T74m4HC9K+TxouOHDmiMWP4D8i/NX/eHPW4s5eiuvdUterV9cy4CfL19dWSTz62OrQi77uthzVh/kZ9vuHXHLc3qRWmBSv26Pudfyjh2F+avXSXdsQn6abryxdypJ6nWYtWemjoo2pzK9Usd8D9cB/8zSg47tQ9vXbtWt1xxx0KDw+XzWbTkiVLnLYbhqGxY8cqLCxMfn5+at++vfbv32963hkzZqhy5cry9fVVZGSkfvzxx3zFVWBJI/698xkZ2rN7l5o0beZo8/LyUpMmzbTjp+0WRgZJ2rj3iG6PrKrwYH9JUqv6FVQjvJSWb0uwODIAnoi/GUVXWlqaGjRooBkzZuS4/eWXX9a0adM0a9Ysbdq0Sf7+/urUqZPOnTuX6znff/99xcTEaNy4cdq2bZsaNGigTp066dixY3mOi58RdCMnT51UZmamgoODndqDg4MVH59z9QuFJ2bmGs145FYdfHegzl/IVJYhPTxthX7Y9afVoQHwQPzNKFjuNDVOly5d1KVLlxy3GYahKVOm6JlnnlG3bt0kSe+++67Kly+vJUuWqHfv3jkeN2nSJA0ePFgDBgyQJM2aNUtfffWVZs+erVGjRuUpLssrjWfPntW6deu0e/fubNvOnTund99994rHp6en6/Tp005Lenq6q8KFB3v4P/V1S61Q9ZzwhZo9ulij3v5eU4a0UduGFa0ODQDgxgoyV4mPj1diYqLat//f8JCgoCBFRkZqw4YNOR6TkZGhrVu3Oh3j5eWl9u3b53pMTvJcaYyJibni9uPHj+f5ohf98ssv6tixoxISEmSz2dSiRQstXrxYYWFhkqSUlBQNGDBA/fr1y/UcsbGxmjBhglPb02PG6Zmx4/Mdj9VKlyotb2/vbAOYk5OTVbZsWYuigiT5+nhrQr9muvv5r7R08yFJ0s+HklW/aoiG97hRq+J+szZAAB6HvxkFy5VVtJxylXHjxl3Vzy8nJiZKksqXdx5PX758ece2yyUlJSkzMzPHY/bu3Zvna+c5ady+3Xx8RKtWrfJ8YUl68sknVbduXW3ZskWnTp3S8OHD1bx5c61evVqVKlXK0zlGjx6dLaE1vK/NScaL+/iodp0btGnjBt3a7u//G8jKytKmTRvUu8+9Fkfn2Yp7e8unuLeysgyn9sysLKZpAGAJ/mZcO3LKVa7FH0TJc9K4atWqAr/4+vXrtXz5cpUtW1Zly5bVF198oYcfflgtW7bUqlWr5O/vb3oOu92e7Y0/d6HAQy0090UP0JinntQNN9RV3Xr1tWD+PJ09e1ZR3XtYHVqR5+9bXNXCgxzrlUMDVb9qWZ3865x+O56qtTt+1wv3t9DZjAtKOPaXWta7TvfcWltPvv29hVF7hjNn0vT7b/974OjPP/7QL/v2KDAwSKFh4RZG5pm4H+6DvxkFx5VjGnPKVa5WaGioJOno0aOOntmL6w0bNszxmLJly8rb21tHjx51aj969KjjfHlh6YMwZ8+eVbFi/wvBZrNp5syZGjZsmFq3bq1FixZZGJ01One5TSdPnNDr06cpKem4ataqrdffeFvBdDW43I01yum7F3s61l8e/HflfP7y3Xpg8nL1e3mpJkY309wRnVQ6wFcJx05r/Lsb9NbXO60K2WPs2b1LQwf3d6xPfe0lSdJtd0Rp7ETmhy1s3A/3wd+MguN1jXQaValSRaGhoVqxYoUjSTx9+rQ2bdqkIUOG5HiMj4+PGjdurBUrVigqKkrS31XpFStWaNiwYXm+ts0wDMN8N9e45ZZb9Mgjj+i+++7Ltm3YsGFauHChTp8+rczMzHyd91quNBY1pbtNszoEXOLPD4daHQLgdvx8vK0OAf/wtbCUNfyzvI/ty68p3Wrla//U1FQdOHBAktSoUSNNmjRJbdu2VZkyZVSpUiW99NJLevHFFzVv3jxVqVJFY8aM0Y4dO7R79275+vpKktq1a6fu3bs7ksL3339f0dHReuONN3TLLbdoypQp+uCDD7R3795sYx1zY2mlsXv37nrvvfdyTBqnT5+urKwszZo1y4LIAACAJ3GnSuOWLVvUtm1bx/rF8ZDR0dGaO3eunnjiCaWlpemBBx7QqVOn1KJFCy1dutSRMErSwYMHlZSU5Fi/++67dfz4cY0dO1aJiYlq2LChli5dmueEUbK40ugqVBrdB5VG90KlEciOSqP7sLLSGPO56yqNk/6Tv0qju2JybwAA4PHcaXJvd3VV0xJ9//33uvfee9W0aVP98ccfkqT58+dr3bp1BRocAAAA3EO+k8aPP/5YnTp1kp+fn7Zv3+6Y0TwlJUUvvMBTcwAA4NrjZXPdUlTkO2l87rnnNGvWLL311lsqXry4o7158+batm1bgQYHAAAA95DvMY379u3L8ZdfgoKCdOrUqYKICQAAoFAxpNFcviuNoaGhjrmDLrVu3TpVrVq1QIICAAAoTF42m8uWoiLfSePgwYP16KOPatOmTbLZbPrzzz+1cOFCjRgxIteZyAEAAHBty3f39KhRo5SVlaV27drpzJkzatWqlex2u0aMGKFHHnnEFTECAAC41FVNJ+Nh8p002mw2Pf300xo5cqQOHDig1NRU1alTRyVLlnRFfAAAAHADVz25t4+Pj+rUqVOQsQAAAFiiCA09dJl8J41t27a94qzpK1eu/FcBAQAAwP3kO2ls2LCh0/r58+cVFxenn3/+WdHR0QUVFwAAQKEpSk85u0q+k8bJkyfn2D5+/Hilpqb+64AAAADgfgrsYaF7771Xs2fPLqjTAQAAFBqbzXVLUXHVD8JcbsOGDfL19S2o0wEAABSaovQb0a6S76SxR48eTuuGYejIkSPasmWLxowZU2CBAQAAwH3kO2kMCgpyWvfy8lLNmjU1ceJEdezYscACAwAAKCw8CGMuX0ljZmamBgwYoHr16ql06dKuigkAAABuJl8Pwnh7e6tjx446deqUi8IBAAAofDwIYy7fT0/XrVtXv/76qytiAQAAgJvKd9L43HPPacSIEfryyy915MgRnT592mkBAAC41njZXLcUFXke0zhx4kQ9/vjjuu222yRJ//nPf5x+TtAwDNlsNmVmZhZ8lAAAALBUnpPGCRMm6KGHHtKqVatcGQ8AAEChs6kIlQRdJM9Jo2EYkqTWrVu7LBgAAAArFKVuZFfJ15hGW1F6BAgAAAB5lq95Gq+//nrTxPHEiRP/KiAAAIDCRqXRXL6SxgkTJmT7RRgAAAAUfflKGnv37q1y5cq5KhYAAABLMATPXJ7HNPJmAgAAeK58Pz0NAABQ1DCm0Vyek8asrCxXxgEAAAA3lq8xjQAAAEURo/DMkTQCAACP50XWaCpfk3sDAADAM1FpBAAAHo8HYcxRaQQAAIApKo0AAMDjMaTRHJVGAAAAmKLSCAAAPJ6XKDWaKZJJY9JfGVaHgH/cP6iD1SEAbmnpvkSrQ8A/ute7zuoQgGtCkUwaAQAA8oMxjeZIGgEAgMdjyh1zPAgDAAAAU1QaAQCAx+NnBM1RaQQAAIApKo0AAMDjUWg0R6URAAAApkgaAQCAx/Oy2Vy25EflypVls9myLUOHDs1x/7lz52bb19fXtyDekmzongYAAHATmzdvVmZmpmP9559/VocOHXTXXXflekxgYKD27dvnWLe5qK+dpBEAAHg8V45pTE9PV3p6ulOb3W6X3W7Ptm9ISIjT+osvvqhq1aqpdevWuZ7fZrMpNDS0YIK9ArqnAQCAx/Ny4RIbG6ugoCCnJTY21jSmjIwMLViwQPfff/8Vq4epqamKiIhQxYoV1a1bN+3ateuq3gMzVBoBAABcaPTo0YqJiXFqy6nKeLklS5bo1KlT6t+/f6771KxZU7Nnz1b9+vWVkpKiV199Vc2aNdOuXbtUoUKFfxu6E5JGAADg8Vw1DlDKvSvazDvvvKMuXbooPDw8132aNm2qpk2bOtabNWum2rVr64033tCzzz57VfHmhqQRAADAzRw+fFjLly/XJ598kq/jihcvrkaNGunAgQMFHhNjGgEAgMezuXC5GnPmzFG5cuXUtWvXfB2XmZmpnTt3Kiws7CqvnDuSRgAAADeSlZWlOXPmKDo6WsWKOXcK9+vXT6NHj3asT5w4Ud99951+/fVXbdu2Tffee68OHz6sQYMGFXhcdE8DAACPl99JuF1p+fLlSkhI0P33359tW0JCgry8/lfzO3nypAYPHqzExESVLl1ajRs31vr161WnTp0Cj4ukEQAAwI107NhRhmHkuG316tVO65MnT9bkyZMLISqSRgAAgKsee+hJSBoBAIDHc6PeabfFgzAAAAAwRaURAAB4PFdO7l1UUGkEAACAKSqNAADA41FFM8d7BAAAAFNUGgEAgMdjTKM5Ko0AAAAwRaURAAB4POqM5qg0AgAAwBSVRgAA4PEY02iOpBEAAHg8ul7N8R4BAADAFJVGAADg8eieNkelEQAAAKaoNAIAAI9HndEclUYAAACYotIIAAA8HkMazVFpBAAAgCkqjQAAwON5MarRFEkjAADweHRPmyNpdDOL5r2tdauXK+FwvOx2X9Wp10APDH1MFSOqWB1akVc92E/tawSrYilflfIrrjc2/qYdR1Kd9ulau6yaVy4tv+Je+jX5rBbHHdHxtPMWRew5tm/dogXvzta+3buUlHRcL02aptZt21sdlkeaPKyPUpKOZmu/uWM3db3/UQsiwuJFCzVvzjtKSjqu62vW0qinxqhe/fpWh4UiiDGNbmbH9i36T8/emv72Qr087U1lXrigJx59UGfPnrE6tCLPp5iXfk9J1wc/Zf+DKEkdagSrTdUyWhx3RK+sPqSMzCwNa15Jxbz431NXO3v2jGpcX1MjRo+xOhSP98ALM/X4rI8cy31PvyJJqhPZ2uLIPNPSb77Wqy/H6sGHh2rxh5+qZs1aGvLgQCUnJ1sd2jXH5sJ/igoqjW7mxSmznNafGPOcenZprf17d6t+o5ssisoz7D6apt1H03Ld3rZ6GS3dl+SoPs7b8qdevK2GGoQFaOsfpwsrTI/UrEUrNWvRyuowIMk/sJTT+rrPFql0+XBVrtPAmoA83Px5c9Tjzl6K6t5TkvTMuAlau3a1lnzysQYOfsDi6FDUUGl0c2mpfycoAYFBFkfi2YJLFFeQbzHtO/6/pPLchSwdOnlWVcr4WRgZYJ0LF85rx7rlatSmCz/BZoHzGRnas3uXmjRt5mjz8vJSkybNtOOn7RZGdm2y2Vy3FBWWVxr37NmjjRs3qmnTpqpVq5b27t2rqVOnKj09Xffee69uvfXWKx6fnp6u9PT0y9psstvtrgy7UGRlZWnGlJdUt34jValWw+pwPFqg799fldPnMp3a/zqX6dgGeJq9m3/QubRUNWzdyepQPNLJUyeVmZmp4OBgp/bg4GDFx/9qUVQoyiytNC5dulQNGzbUiBEj1KhRIy1dulStWrXSgQMHdPjwYXXs2FErV6684jliY2MVFBTktMyY/HIhvQLXmvbK8zp08ICeea5ovB4ARcv2VV+rRsNbFFimrNWhAP+al2wuW4oKS5PGiRMnauTIkUpOTtacOXPUt29fDR48WMuWLdOKFSs0cuRIvfjii1c8x+jRo5WSkuK0DH3siUJ6Ba4z7dXntfGHNXrt9XcUUi7U6nA83ulzFyRJgb7eTu0Bvt6ObYAnOXU8Ub/u3KYbb+1qdSgeq3Sp0vL29s720EtycrLKliWRR8GzNGnctWuX+vfvL0nq1auX/vrrL915552O7ffcc4927NhxxXPY7XYFBgY6Lddy17RhGJr26vNat2alXp3+jsLCK1gdEiQlnzmvlHMXVDPE39HmW8xLlUv7Kf7EWQsjA6yxffVS+QeVUo1GTawOxWMV9/FR7To3aNPGDY62rKwsbdq0QfUbNLIwsmsTYxrNWT4Y6+LgaS8vL/n6+ioo6H8PfAQEBCglJcWq0Cwx7ZXnteK7r/Xsy1NVwt9fJ5KTJEn+/iVl9/W1OLqize5tU0hJH8d6cAkfVQiyKy0jUyfPXtCqAyfUuWZZHUvNUPKZ87q9dohSzl3QT0f+sjBqz3DmTJp+/y3Bsf7nH3/ol317FBgYpNCwcAsj80xZWVmKW7NUDVp1lLe3t/kBcJn7ogdozFNP6oYb6qpuvfpaMH+ezp49q6juPawO7ZpTlJI7V7E0aaxcubL279+vatWqSZI2bNigSpUqObYnJCQoLCzMqvAs8fkn70uSYh6+36l95DPPqvPtURZE5DkqlfbT8JYRjvU765eXJG08fErztx3Rsv3J8ilmU99GYfIr7qWDyWc1Y/1vupBlWBWyx9ize5eGDu7vWJ/62kuSpNvuiNLYiS9YFJXn+nXnVqUkHVOjNl2sDsXjde5ym06eOKHXp09TUtJx1axVW6+/8baC6Z6GC9gMw7DsL96sWbNUsWJFde2a85iYp556SseOHdPbb7+dr/P+fjKjIMJDAYhdfdDqEHCJ5zpdb3UI+MfSfYlWh4B/dK93ndUh4B9WTkaxbE+Sy87doXbRSOItrTQ+9NBDV9z+wgtUEAAAANyB5WMaAQAArMYvwprjF2EAAABgikojAADweLYiNAm3q1BpBAAAgCkqjQAAwOMxT6M5kkYAAODx6J42R/c0AAAATFFpBAAAHo8pd8xRaQQAAIApKo0AAMDjMabRHJVGAAAAmKLSCAAAPB5T7pij0ggAAOAmxo8fL5vN5rTUqlXrisd8+OGHqlWrlnx9fVWvXj19/fXXLomNpBEAAHg8mwuX/Lrhhht05MgRx7Ju3bpc912/fr369OmjgQMHavv27YqKilJUVJR+/vnnq7jyldE9DQAAPJ6XG/VPFytWTKGhoXnad+rUqercubNGjhwpSXr22We1bNkyTZ8+XbNmzSrQuKg0AgAAuFB6erpOnz7ttKSnp+e6//79+xUeHq6qVavqnnvuUUJCQq77btiwQe3bt3dq69SpkzZs2FBg8V9E0ggAADyeK7unY2NjFRQU5LTExsbmGEdkZKTmzp2rpUuXaubMmYqPj1fLli31119/5bh/YmKiypcv79RWvnx5JSYmXv2bkQu6pwEAAFxo9OjRiomJcWqz2+057tulSxfHv9evX1+RkZGKiIjQBx98oIEDB7o0TjMkjQAAAC4c0mi323NNEs2UKlVK119/vQ4cOJDj9tDQUB09etSp7ejRo3keE5kfdE8DAAC4qdTUVB08eFBhYWE5bm/atKlWrFjh1LZs2TI1bdq0wGMhaQQAAB7P5sJ/8mPEiBFas2aNDh06pPXr16t79+7y9vZWnz59JEn9+vXT6NGjHfs/+uijWrp0qV577TXt3btX48eP15YtWzRs2LACfX8kuqcBAADcxu+//64+ffooOTlZISEhatGihTZu3KiQkBBJUkJCgry8/lfza9asmRYtWqRnnnlGTz31lGrUqKElS5aobt26BR4bSSMAAPB47jJN4+LFi6+4ffXq1dna7rrrLt11110uiuh/SBoBAIDHc5Oc0a0xphEAAACmqDQCAABQajRFpREAAACmqDQCAACPl9+pcTwRlUYAAACYotIIAAA8nrtMuePOqDQCAADAFJVGAADg8Sg0miNpBAAAIGs0Rfc0AAAATFFpBAAAHo8pd8xRaQQAAIApKo0AAMDjMeWOOSqNAAAAMEWlEQAAeDwKjeaKZNLob/e2OgT8o0XlQKtDwCX8fPhuuIsFP/5hdQj4R/d611kdAnBNKJJJIwAAQL5QajRF0ggAADweU+6Y40EYAAAAmKLSCAAAPB5T7pij0ggAAABTVBoBAIDHo9BojkojAAAATFFpBAAAoNRoikojAAAATFFpBAAAHo95Gs1RaQQAAIApKo0AAMDjMU+jOZJGAADg8cgZzdE9DQAAAFNUGgEAACg1mqLSCAAAAFNUGgEAgMdjyh1zVBoBAABgikojAADweEy5Y45KIwAAAExRaQQAAB6PQqM5kkYAAACyRlN0TwMAAMAUlUYAAODxmHLHHJVGAAAAmKLSCAAAPB5T7pij0ggAAABTVBoBAIDHo9BojkojAAAATFFpBAAAoNRoikojAADweDYX/pMfsbGxuvnmmxUQEKBy5copKipK+/btu+Ixc+fOlc1mc1p8fX3/zduRI5JGAAAAN7FmzRoNHTpUGzdu1LJly3T+/Hl17NhRaWlpVzwuMDBQR44ccSyHDx8u8NjongYAAB7PXabcWbp0qdP63LlzVa5cOW3dulWtWrXK9TibzabQ0FCXxkalEQAAwIXS09N1+vRppyU9PT1Px6akpEiSypQpc8X9UlNTFRERoYoVK6pbt27atWvXv477ciSNAADA49lcuMTGxiooKMhpiY2NNY0pKytLw4cPV/PmzVW3bt1c96tZs6Zmz56tzz77TAsWLFBWVpaaNWum33///arei9zYDMMwCvSMbuDkmUyrQ8A/lu5LtDoEXKJ7veusDgH/6PnOj1aHgH98PPAWq0PAP3wtHDR3KOmcy84dFmDLVlm02+2y2+1XPG7IkCH65ptvtG7dOlWoUCHP1zt//rxq166tPn366Nlnn72qmHPCmEYAAAAXjmnMS4J4uWHDhunLL7/U2rVr85UwSlLx4sXVqFEjHThwIF/HmaF7GgAAwE0YhqFhw4bp008/1cqVK1WlSpV8nyMzM1M7d+5UWFhYgcZGpREAAHi8/M6n6CpDhw7VokWL9NlnnykgIECJiX8P8woKCpKfn58kqV+/frruuusc4yInTpyoJk2aqHr16jp16pReeeUVHT58WIMGDSrQ2EgaAQCAx3OXKXdmzpwpSWrTpo1T+5w5c9S/f39JUkJCgry8/tdZfPLkSQ0ePFiJiYkqXbq0GjdurPXr16tOnToFGhtJo5vZvnWLFrw7W/t271JS0nG9NGmaWrdtb3VYHmnysD5KSTqarf3mjt3U9f5HLYgIixct1Lw57ygp6biur1lLo54ao3r161sdVpF2Q1iAejYIVfWy/gr299Gz3/6ijYdOSZK8vWzqd/N1uqliKYUG2pWWkam4P05r7qbfdOLMeWsD9yB8L4qWvDyfvHr1aqf1yZMna/LkyS6K6H8Y0+hmzp49oxrX19SI0WOsDsXjPfDCTD0+6yPHct/Tr0iS6kS2tjgyz7T0m6/16suxevDhoVr84aeqWbOWhjw4UMnJyVaHVqT5FvNSfPIZzVyX/dcl7MW8VK2sv97b9qf+7+Ndev67/aoQ5Kuxna+3IFLPxPei4Lhyyp2igqTRzTRr0UoPDX1UbW6lumg1/8BSCihVxrH8sm2DSpcPV+U6DawOzSPNnzdHPe7spajuPVWtenU9M26CfH19teSTj60OrUjb+luK5m/+QxsOncy27UxGpp75ap/W/XpCf6Sc075jaZr5w2HVCPFXSEkfC6L1PHwvUJjcLmksgtNGogi4cOG8dqxbrkZtusjmLgNfPMj5jAzt2b1LTZo2c7R5eXmpSZNm2vHTdgsjw+X8fbyVZRhKTb9gdShFHt+LgmWzuW4pKtwuabTb7dqzZ4/VYQBO9m7+QefSUtWwdSerQ/FIJ0+dVGZmpoKDg53ag4ODlZSUZFFUuFxxb5sGRFbUmgPJOns+y+pwijy+Fyhslj0IExMTk2N7ZmamXnzxRceXYNKkSVc8T3p6erZZ1tMzi+V7Ek3gSrav+lo1Gt6iwDJlrQ4FcEveXjaNbl9dkjTj+0PWBgNclSJUEnQRy5LGKVOmqEGDBipVqpRTu2EY2rNnj/z9/fPUDRgbG6sJEyY4tT3x1BiNenpcQYYLD3bqeKJ+3blNdz8+wXxnuETpUqXl7e2dbXB/cnKyypYlkbeat5dNo9pXU0iAXU99sZcqYyHhe4HCZln39AsvvKCUlBSNGTNGq1atcize3t6aO3euVq1apZUrV5qeZ/To0UpJSXFaHhsxqhBeATzF9tVL5R9USjUaNbE6FI9V3MdHtevcoE0bNzjasrKytGnTBtVv0MjCyHAxYQwP8tXTX+7VX4xlLDR8LwoWYxrNWVZpHDVqlNq1a6d7771Xd9xxh2JjY1W8ePF8nyen33PMPJNZUGEWujNn0vT7bwmO9T//+EO/7NujwMAghYaFWxiZZ8rKylLcmqVq0KqjvL29rQ7Ho90XPUBjnnpSN9xQV3Xr1deC+fN09uxZRXXvYXVoRZpvMS+FB/k61kMD7KoaXEJ/pV/QiTPn9VSH6qpWtoQmfPOLvG02lfb7+7/jf6Vf0IUsHmx0Nb4XBacI5XYuY+nk3jfffLO2bt2qoUOH6qabbtLChQs9/snUPbt3aejg/o71qa+9JEm67Y4ojZ34gkVRea5fd25VStIxNWrTxepQPF7nLrfp5IkTen36NCUlHVfNWrX1+htvK5huOJeqEeKvF/9T27E+uFmEJGn5vuNauOUPNalcWpI0/a56TseN+nyPdh75q/AC9VB8L1CYbIabzHGzePFiDR8+XMePH9fOnTv/1U/fnLyGK41FzdJ9iVaHgEt0r3ed1SHgHz3f+dHqEPCPjwfeYnUI+IevhaWsIykZLjt3WFDRmLfUbX5GsHfv3mrRooW2bt2qiIgIq8MBAADAJdwmaZSkChUqqEKFClaHAQAAPIyNUY2m3G5ybwAAALgft6o0AgAAWIJCoykqjQAAADBFpREAAHg8Co3mSBoBAIDH8/BpovOE7mkAAACYotIIAAA8HlPumKPSCAAAAFNUGgEAACg0mqLSCAAAAFNUGgEAgMej0GiOSiMAAABMUWkEAAAej3kazZE0AgAAj8eUO+bongYAAIApKo0AAMDj0T1tjkojAAAATJE0AgAAwBRJIwAAAEwxphEAAHg8xjSao9IIAAAAU1QaAQCAx2OeRnMkjQAAwOPRPW2O7mkAAACYotIIAAA8HoVGc1QaAQAAYIpKIwAAAKVGU1QaAQAAYIpKIwAA8HhMuWOOSiMAAABMUWkEAAAej3kazVFpBAAAgCkqjQAAwONRaDRH0ggAAEDWaIruaQAAAJgiaQQAAB7P5sJ/rsaMGTNUuXJl+fr6KjIyUj/++OMV9//www9Vq1Yt+fr6ql69evr666+v6rpXQtIIAADgRt5//33FxMRo3Lhx2rZtmxo0aKBOnTrp2LFjOe6/fv169enTRwMHDtT27dsVFRWlqKgo/fzzzwUal80wDKNAz+gGTp7JtDoE/GPpvkSrQ8Alute7zuoQ8I+e71y5aoDC8/HAW6wOAf/wtfBJi3MXXHfu/L6uyMhI3XzzzZo+fbokKSsrSxUrVtQjjzyiUaNGZdv/7rvvVlpamr788ktHW5MmTdSwYUPNmjXrX8V+KSqNAAAALpSenq7Tp087Lenp6Tnum5GRoa1bt6p9+/aONi8vL7Vv314bNmzI8ZgNGzY47S9JnTp1ynX/q1Ukn54uXcLb6hD+tfT0dMXGxmr06NGy2+1Wh3PV+jS69itbReVeFAVF6V589eC1Xd0qSveiKOB+/HuurHKOfy5WEyZMcGobN26cxo8fn23fpKQkZWZmqnz58k7t5cuX1969e3M8f2JiYo77JyYWbG8flUY3lZ6ergkTJuT6fyIoPNwL98G9cB/cC/fC/XBvo0ePVkpKitMyevRoq8PKtyJZaQQAAHAXdrs9zxXgsmXLytvbW0ePHnVqP3r0qEJDQ3M8JjQ0NF/7Xy0qjQAAAG7Cx8dHjRs31ooVKxxtWVlZWrFihZo2bZrjMU2bNnXaX5KWLVuW6/5Xi0ojAACAG4mJiVF0dLRuuukm3XLLLZoyZYrS0tI0YMAASVK/fv103XXXKTY2VpL06KOPqnXr1nrttdfUtWtXLV68WFu2bNGbb75ZoHGRNLopu92ucePGMaDZDXAv3Af3wn1wL9wL96Noufvuu3X8+HGNHTtWiYmJatiwoZYuXep42CUhIUFeXv/rLG7WrJkWLVqkZ555Rk899ZRq1KihJUuWqG7dugUaV5GcpxEAAAAFizGNAAAAMEXSCAAAAFMkjQAAADBF0ggAAABTJI1uaMaMGapcubJ8fX0VGRmpH3/80eqQPNLatWt1xx13KDw8XDabTUuWLLE6JI8VGxurm2++WQEBASpXrpyioqK0b98+q8PySDNnzlT9+vUVGBiowMBANW3aVN98843VYUHSiy++KJvNpuHDh1sdCoookkY38/777ysmJkbjxo3Ttm3b1KBBA3Xq1EnHjh2zOjSPk5aWpgYNGmjGjBlWh+Lx1qxZo6FDh2rjxo1atmyZzp8/r44dOyotLc3q0DxOhQoV9OKLL2rr1q3asmWLbr31VnXr1k27du2yOjSPtnnzZr3xxhuqX7++1aGgCGPKHTcTGRmpm2++WdOnT5f09yzwFStW1COPPKJRo0ZZHJ3nstls+vTTTxUVFWV1KJB0/PhxlStXTmvWrFGrVq2sDsfjlSlTRq+88ooGDhxodSgeKTU1VTfeeKNef/11Pffcc2rYsKGmTJlidVgogqg0upGMjAxt3bpV7du3d7R5eXmpffv22rBhg4WRAe4lJSVF0t/JCqyTmZmpxYsXKy0trcB/rgx5N3ToUHXt2tXpbwfgCvwijBtJSkpSZmamY8b3i8qXL6+9e/daFBXgXrKysjR8+HA1b968wH/tAHmzc+dONW3aVOfOnVPJkiX16aefqk6dOlaH5ZEWL16sbdu2afPmzVaHAg9A0gjgmjJ06FD9/PPPWrdundWheKyaNWsqLi5OKSkp+uijjxQdHa01a9aQOBay3377TY8++qiWLVsmX19fq8OBByBpdCNly5aVt7e3jh496tR+9OhRhYaGWhQV4D6GDRumL7/8UmvXrlWFChWsDsdj+fj4qHr16pKkxo0ba/PmzZo6dareeOMNiyPzLFu3btWxY8d04403OtoyMzO1du1aTZ8+Xenp6fL29rYwQhQ1jGl0Iz4+PmrcuLFWrFjhaMvKytKKFSsYLwSPZhiGhg0bpk8//VQrV65UlSpVrA4Jl8jKylJ6errVYXicdu3aaefOnYqLi3MsN910k+655x7FxcWRMKLAUWl0MzExMYqOjtZNN92kW265RVOmTFFaWpoGDBhgdWgeJzU1VQcOHHCsx8fHKy4uTmXKlFGlSpUsjMzzDB06VIsWLdJnn32mgIAAJSYmSpKCgoLk5+dncXSeZfTo0erSpYsqVaqkv/76S4sWLdLq1av17bffWh2axwkICMg2rtff31/BwcGM94VLkDS6mbvvvlvHjx/X2LFjlZiYqIYNG2rp0qXZHo6B623ZskVt27Z1rMfExEiSoqOjNXfuXIui8kwzZ86UJLVp08apfc6cOerfv3/hB+TBjh07pn79+unIkSMKCgpS/fr19e2336pDhw5WhwbAxZinEQAAAKYY0wgAAABTJI0AAAAwRdIIAAAAUySNAAAAMEXSCAAAAFMkjQAAADBF0ggAAABTJI0AAAAwRdIIoMD0799fUVFRjvU2bdpo+PDhhR7H6tWrZbPZdOrUKZdd4/LXejUKI04AKCgkjUAR179/f9lsNtlsNvn4+Kh69eqaOHGiLly44PJrf/LJJ3r22WfztG9hJ1CVK1fWlClTCuVaAFAU8NvTgAfo3Lmz5syZo/T0dH399dcaOnSoihcvrtGjR2fbNyMjQz4+PgVy3TJlyhTIeQAA1qPSCHgAu92u0NBQRUREaMiQIWrfvr0+//xzSf/rZn3++ecVHh6umjVrSpJ+++039erVS6VKlVKZMmXUrVs3HTp0yHHOzMxMxcTEqFSpUgoODtYTTzyhy3/K/vLu6fT0dD355JOqWLGi7Ha7qlevrnfeeUeHDh1S27ZtJUmlS5eWzWZT//79JUlZWVmKjY1VlSpV5OfnpwYNGuijjz5yus7XX3+t66+/Xn5+fmrbtq1TnFcjMzNTAwcOdFyzZs2amjp1ao77TpgwQSEhIQoMDNRDDz2kjIwMx7a8xA4A1woqjYAH8vPzU3JysmN9xYoVCgwM1LJlyyRJ58+fV6dOndS0aVN9//33KlasmJ577jl17txZO3bskI+Pj1577TXNnTtXs2fPVu3atfXaa6/p008/1a233prrdfv166cNGzZo2rRpatCggeLj45WUlKSKFSvq448/Vs+ePbVv3z4FBgbKz89PkhQbG6sFCxZo1qxZqlGjhtauXat7771XISEhat26tX777Tf16NFDQ4cO1QMPPKAtW7bo8ccf/1fvT1ZWlipUqKAPP/xQwcHBWr9+vR544AGFhYWpV69eTu+br6+vVq9erUOHDmnAgAEKDg7W888/n6fYAeCaYgAo0qKjo41u3boZhmEYWVlZxrJlywy73W6MGDHCsb18+fJGenq645j58+cbNWvWNLKyshxt6enphp+fn/Htt98ahmEYYWFhxssvv+zYfv78eaNChQqOaxmGYbRu3dp49NFHDcMwjH379hmSjGXLluUY56pVqwxJxsmTJx1t586dM0qUKGGsX7/ead+BAwcaffr0MQzDMEaPHm3UqVPHafuTTz6Z7VyXi4iIMCZPnpzr9ssNHTrU6Nmzp2M9OjraKFOmjJGWluZomzlzplGyZEkjMzMzT7Hn9JoBwF1RaQQ8wJdffqmSJUvq/PnzysrKUt++fTV+/HjH9nr16jmNY/zpp5904MABBQQEOJ3n3LlzOnjwoFJSUnTkyBFFRkY6thUrVkw33XRTti7qi+Li4uTt7Z2vCtuBAwd05swZdejQwak9IyNDjRo1kiTt2bPHKQ5Jatq0aZ6vkZsZM2Zo9uzZSkhI0NmzZ5WRkaGGDRs67dOgQQOVKFHC6bqpqan67bfflJqaaho7AFxLSBoBD9C2bVvNnDlTPj4+Cg8PV7Fizl99f39/p/XU1FQ1btxYCxcuzHaukJCQq4rhYndzfqSmpkqSvvrqK1133XVO2+x2+1XFkReLFy/WiBEj9Nprr6lp06YKCAjQK6+8ok2bNuX5HFbFDgCuQtIIeAB/f39Vr149z/vfeOONev/991WuXDkFBgbmuE9YWJg2bdqkVq1aSZIuXLigrVu36sYbb8xx/3r16ikrK0tr1qxR+/bts22/WOnMzMx0tNWpU0d2u10JCQm5Vihr167teKjnoo0bN5q/yCv44Ycf1KxZMz388MOOtoMHD2bb76efftLZs2cdCfHGjRtVsmRJVaxYUWXKlDGNHQCuJTw9DSCbe+65R2XLllW3bt30/fffKz4+XqtXr9b//d//6ffff5ckPfroo3rxxRe1ZMkS7d27Vw8//PAV51isXLmyoqOjdf/992vJkiWOc37wwQeSpIiICNlsNn355Zc6fvy4UlNTFRAQoBEjRuixxx7TvHnzdPDgQW3btk3//e9/NW/ePEnSQw89pP3792vkyJHat2+fFi1apLlz5+bpdf7xxx+Ki4tzWk6ePKkaNWpoy5Yt+vbbb/XLL79ozJgx2rx5c7bjMzIyNHDgQO3evVtff/21xo0bp2HDhsnLyytPsQPANcXqQZUAXOvSB2Hys/3IkSNGv379jLJlyxp2u92oWrWqMXjwYCMlJcUwjL8ffHn00UeNwMBAo1SpUkZMTIzRr1+/XB+EMQzDOHv2rPHYY48ZYWFhho+Pj1G9enVj9uzZju0TJ040QkNDDZvNZkRHRxuG8ffDO1OmTDFq1qxpFC9e3AgJCTE6depkrFmzxnHcF198YVSvXt2w2+1Gy5YtjdmzZ+fpQRhJ2Zb58+cb586dM/r3728EBQUZpUqVMoYMGWKMGjXKaNCgQbb3bezYsUZwcLBRsmRJY/Dgwca5c+cc+5jFzoMwAK4lNsPIZdQ6AAAA8A+6pwEAAGCKpBEAAACmSBoBAABgiqQRAAAApkgaAQAAYIqkEQAAAKZIGgEAAGCKpBEAAACmSBoBAABgiqQRAAAApkgaAQAAYOr/Acl6EhU4G4cUAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_binary_models(df, models):\n",
    "    \"\"\"\n",
    "    Evaluate binary classification models on the balanced sample\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for model_name, (model, is_multi, model_type) in models.items():\n",
    "        if not is_multi:  # Only evaluate binary models\n",
    "            print(f\"\\nEvaluating {model_name}...\")\n",
    "            predictions = []\n",
    "            \n",
    "            for text in df['text']:\n",
    "                if model_type == 'finetuning':\n",
    "                    pred = int(model.predict(text)[0][1] > 0.5)\n",
    "                else:  # lstm\n",
    "                    pred = get_prediction_lstm(model, text)\n",
    "                predictions.append(pred)\n",
    "            \n",
    "            results[model_name] = {\n",
    "                'predictions': predictions,\n",
    "                'report': classification_report(df['label'], predictions),\n",
    "                'confusion_matrix': confusion_matrix(df['label'], predictions)\n",
    "            }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def evaluate_multifactorial_models(df, models):\n",
    "    \"\"\"\n",
    "    Evaluate multifactorial classification models on the balanced sample\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for model_name, (model, is_multi, model_type) in models.items():\n",
    "        if is_multi:  # Only evaluate multifactorial models\n",
    "            print(f\"\\nEvaluating {model_name}...\")\n",
    "            predictions = []\n",
    "            \n",
    "            for text in df['text']:\n",
    "                if model_type == 'finetuning':\n",
    "                    pred = model.predict(text)['predicted_label']\n",
    "                else:  # lstm\n",
    "                    pred = get_prediction_lstm_multifactorial(model, text)\n",
    "                predictions.append(pred)\n",
    "            \n",
    "            results[model_name] = {\n",
    "                'predictions': predictions,\n",
    "                'report': classification_report(df['nivel_risa'], predictions),\n",
    "                'confusion_matrix': confusion_matrix(df['nivel_risa'], predictions)\n",
    "            }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Load the balanced datasets\n",
    "binary_df = pd.read_csv(\"data/balanced_sample.csv\")\n",
    "multi_df = pd.read_csv(\"data/balanced_sample_multifactorial.csv\")\n",
    "\n",
    "# Define models dictionary (as provided)\n",
    "models = {\n",
    "    'GPT Binary': (model_5k_gpt_finetuning_binary, False, 'finetuning'),\n",
    "    'LSTM2 Binary': (classifier_lstm2_binary, False, 'lstm'),\n",
    "    'LSTM1 Binary': (classifier_lstm1_binary, False, 'lstm'),\n",
    "    'GPT Multifactorial': (model_12k_gpt_finetuning_multifactorial, True, 'finetuning'),\n",
    "    'LSTM2 Multifactorial': (classifier_lstm2_multifactorial, True, 'lstm'),\n",
    "    'LSTM1 Multifactorial': (classifier_lstm1_multifactorial, True, 'lstm')\n",
    "}\n",
    "\n",
    "# Evaluate models\n",
    "binary_results = evaluate_binary_models(binary_df, models)\n",
    "multi_results = evaluate_multifactorial_models(multi_df, models)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nBinary Classification Results:\")\n",
    "print(\"==============================\")\n",
    "for model_name, result in binary_results.items():\n",
    "    print(f\"\\n{model_name}\")\n",
    "    print(\"-\" * len(model_name))\n",
    "    print(result['report'])\n",
    "\n",
    "print(\"\\nMultifactorial Classification Results:\")\n",
    "print(\"====================================\")\n",
    "for model_name, result in multi_results.items():\n",
    "    print(f\"\\n{model_name}\")\n",
    "    print(\"-\" * len(model_name))\n",
    "    print(result['report'])\n",
    "\n",
    "# Create confusion matrix visualizations\n",
    "def plot_confusion_matrix(cm, title):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "for model_name, result in binary_results.items():\n",
    "    plot_confusion_matrix(result['confusion_matrix'], f'Confusion Matrix - {model_name}')\n",
    "\n",
    "for model_name, result in multi_results.items():\n",
    "    plot_confusion_matrix(result['confusion_matrix'], f'Confusion Matrix - {model_name}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, classification_report\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, is_multifactorial=False):\n",
    "    \"\"\"\n",
    "    Calculate performance metrics ensuring consistent lengths\n",
    "    \"\"\"\n",
    "    # Convert inputs to lists and ensure same length\n",
    "    y_true = list(y_true)\n",
    "    y_pred = list(y_pred)\n",
    "    \n",
    "    # Verify we have valid data\n",
    "    if len(y_true) != len(y_pred):\n",
    "        print(f\"Warning: Inconsistent lengths - y_true: {len(y_true)}, y_pred: {len(y_pred)}\")\n",
    "        # Take the minimum length to ensure consistency\n",
    "        min_len = min(len(y_true), len(y_pred))\n",
    "        y_true = y_true[:min_len]\n",
    "        y_pred = y_pred[:min_len]\n",
    "    \n",
    "    # Remove any invalid entries (like NaN)\n",
    "    valid_indices = [i for i in range(len(y_true)) \n",
    "                    if pd.notna(y_true[i]) and pd.notna(y_pred[i])]\n",
    "    y_true = [y_true[i] for i in valid_indices]\n",
    "    y_pred = [y_pred[i] for i in valid_indices]\n",
    "    \n",
    "    if is_multifactorial:\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "        recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    else:\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'recall': recall,\n",
    "        'n_samples': len(y_true)\n",
    "    }\n",
    "\n",
    "def print_detailed_results(y_true, y_pred, task_name):\n",
    "    \"\"\"\n",
    "    Print detailed classification report\n",
    "    \"\"\"\n",
    "    print(f\"\\n{task_name} Classification Report:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Binary Classification Metrics:\n",
      "============================\n",
      "Accuracy: 0.9231\n",
      "F1-Score: 0.9231\n",
      "Recall: 0.9474\n",
      "Number of samples: 39\n",
      "\n",
      "Multifactorial Classification Metrics:\n",
      "================================\n",
      "Accuracy: 0.3043\n",
      "F1-Score: 0.2736\n",
      "Recall: 0.3043\n",
      "Number of samples: 92\n",
      "\n",
      "Binary Classification Report:\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92        20\n",
      "           1       0.90      0.95      0.92        19\n",
      "\n",
      "    accuracy                           0.92        39\n",
      "   macro avg       0.92      0.92      0.92        39\n",
      "weighted avg       0.92      0.92      0.92        39\n",
      "\n",
      "\n",
      "Multifactorial Classification Report:\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.54      0.70      0.61        20\n",
      "         2.0       0.29      0.50      0.37        18\n",
      "         3.0       0.33      0.25      0.29        16\n",
      "         4.0       0.50      0.05      0.10        19\n",
      "         5.0       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.30        92\n",
      "   macro avg       0.28      0.25      0.23        92\n",
      "weighted avg       0.34      0.30      0.27        92\n",
      "\n",
      "\n",
      "Summary:\n",
      "========\n",
      "          Task  Accuracy  F1_Score  Recall  Samples\n",
      "        Binary    0.9231    0.9231  0.9474       39\n",
      "Multifactorial    0.3043    0.2736  0.3043       92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load datasets\n",
    "binary_original = pd.read_csv(\"data/balanced_sample.csv\")\n",
    "binary_gpt = pd.read_csv(\"data/balanced_sample_gpt_answers.csv\")\n",
    "multi_original = pd.read_csv(\"data/balanced_sample_multifactorial.csv\")\n",
    "\n",
    "multi_gpt = pd.read_csv(\"data/balanced_sample_multifactorial_gpt_answers.csv\")\n",
    "\n",
    "# Clean data to ensure valid comparisons\n",
    "def clean_data(df):\n",
    "    \"\"\"Remove any rows with NaN values\"\"\"\n",
    "    return df.dropna()\n",
    "\n",
    "binary_original = clean_data(binary_original)\n",
    "binary_gpt = clean_data(binary_gpt)\n",
    "multi_original = clean_data(multi_original)\n",
    "multi_gpt = clean_data(multi_gpt)\n",
    "\n",
    "# Ensure matching indices\n",
    "binary_indices = binary_original.index.intersection(binary_gpt.index)\n",
    "multi_indices = multi_original.index.intersection(multi_gpt.index)\n",
    "\n",
    "# Calculate metrics for binary classification\n",
    "binary_metrics = calculate_metrics(\n",
    "    binary_original.loc[binary_indices, 'label'],\n",
    "    binary_gpt.loc[binary_indices, 'label']\n",
    ")\n",
    "\n",
    "# Calculate metrics for multifactorial classification\n",
    "multi_metrics = calculate_metrics(\n",
    "    multi_original.loc[multi_indices, 'nivel_risa'],\n",
    "    multi_gpt.loc[multi_indices, 'nivel_risa'],\n",
    "    is_multifactorial=True\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(\"\\nBinary Classification Metrics:\")\n",
    "print(\"============================\")\n",
    "print(f\"Accuracy: {binary_metrics['accuracy']:.4f}\")\n",
    "print(f\"F1-Score: {binary_metrics['f1_score']:.4f}\")\n",
    "print(f\"Recall: {binary_metrics['recall']:.4f}\")\n",
    "print(f\"Number of samples: {binary_metrics['n_samples']}\")\n",
    "\n",
    "print(\"\\nMultifactorial Classification Metrics:\")\n",
    "print(\"================================\")\n",
    "print(f\"Accuracy: {multi_metrics['accuracy']:.4f}\")\n",
    "print(f\"F1-Score: {multi_metrics['f1_score']:.4f}\")\n",
    "print(f\"Recall: {multi_metrics['recall']:.4f}\")\n",
    "print(f\"Number of samples: {multi_metrics['n_samples']}\")\n",
    "\n",
    "# Print detailed classification reports\n",
    "print_detailed_results(\n",
    "    binary_original.loc[binary_indices, 'label'],\n",
    "    binary_gpt.loc[binary_indices, 'label'],\n",
    "    \"Binary\"\n",
    ")\n",
    "\n",
    "print_detailed_results(\n",
    "    multi_original.loc[multi_indices, 'nivel_risa'],\n",
    "    multi_gpt.loc[multi_indices, 'nivel_risa'],\n",
    "    \"Multifactorial\"\n",
    ")\n",
    "\n",
    "# Create summary DataFrame\n",
    "summary_df = pd.DataFrame({\n",
    "    'Task': ['Binary', 'Multifactorial'],\n",
    "    'Accuracy': [binary_metrics['accuracy'], multi_metrics['accuracy']],\n",
    "    'F1_Score': [binary_metrics['f1_score'], multi_metrics['f1_score']],\n",
    "    'Recall': [binary_metrics['recall'], multi_metrics['recall']],\n",
    "    'Samples': [binary_metrics['n_samples'], multi_metrics['n_samples']]\n",
    "})\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "print(\"========\")\n",
    "print(summary_df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
