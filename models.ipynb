{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.14.0\n",
      "Keras version: 2.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Implementation and Performance Analysis Notebook\n",
    "\n",
    "This notebook serves as a comprehensive guide for analyzing and comparing the performance of different humor classification models across multimedia and natural text data. It provides an in-depth examination of binary and multifactorial classification approaches using two main architectures:\n",
    "\n",
    "1. Fine-tuned BERT Models:\n",
    "   - Binary classification (humor vs. non-humor)\n",
    "   - Multifactorial classification (humor intensity levels 1-5)\n",
    "   - Variants trained on different dataset sizes and captioning methods\n",
    "\n",
    "2. LSTM-based Architectures:\n",
    "   - Single-layer LSTM implementation\n",
    "   - Dual-layer LSTM implementation\n",
    "   - Both architectures combined with BERT embeddings\n",
    "\n",
    "Each section includes:\n",
    "- Model loading and configuration\n",
    "- Performance evaluation metrics (accuracy, F1-score, recall)\n",
    "- Comparative analysis between multimedia and natural text data\n",
    "- Detailed error analysis and prediction samples\n",
    "\n",
    "For implementation details and the complete steps to train these models yourself, please refer to the instructions provided in the README.md file. This notebook focuses on model evaluation and analysis rather than training, assuming pre-trained models are available.\n",
    "\n",
    "Note: This notebook requires access to trained model checkpoints and the complete dataset with both multimedia and natural text samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dataframes(file_humour, file_no_humour, one_hot:bool = False):\n",
    "    \"\"\"\n",
    "    Combine humor and non-humor datasets into a single dataset.\n",
    "    \n",
    "    Args:\n",
    "        file_humour (str): Path to CSV file containing humor data\n",
    "        file_no_humour (str): Path to CSV file containing non-humor data\n",
    "        \n",
    "    Returns:\n",
    "        Dataset: Combined dataset with humor and non-humor examples\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if one_hot:\n",
    "            df_humor = pd.read_csv(file_humour)\n",
    "            df_humor.rename(columns={\"Chistes\": \"text\"}, inplace=True)\n",
    "            df_humor.drop(columns=[\"id_chiste\"], inplace=True)\n",
    "            \n",
    "            # Create label encoder for nivel_risa\n",
    "            label_encoder = LabelEncoder()\n",
    "            df_humor['nivel_risa_encoded'] = label_encoder.fit_transform(df_humor['nivel_risa'])\n",
    "            \n",
    "            # Store the original mapping\n",
    "            label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "            print(\"Label mapping:\", label_mapping)\n",
    "            \n",
    "            dataset = Dataset.from_pandas(df_humor)\n",
    "            return dataset, label_encoder\n",
    "        else:\n",
    "            df_no_humor = pd.read_csv(file_no_humour)\n",
    "            df_no_humor[\"nivel_risa\"] = 0\n",
    "            \n",
    "            df_humor = pd.read_csv(file_humour)\n",
    "            df_humor.rename(columns={\"Chistes\": \"text\"}, inplace=True)\n",
    "            df_humor['label'] = 1\n",
    "            df_humor.drop(columns=[\"id_chiste\"], inplace=True)\n",
    "            \n",
    "            df_combined = pd.concat([df_humor, df_no_humor], ignore_index=True)\n",
    "            return Dataset.from_pandas(df_combined)\n",
    "    except Exception as e:\n",
    "        print(f\"Error on combine_dataframes: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = combine_dataframes(\"data/classification/complete_dataset_chistes.csv\",\"data/classification/data_with_no_humour.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'nivel_risa', 'label'],\n",
       "    num_rows: 19417\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c30d4ac2bb47388ab0a9604c3415cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19417 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-large-cased',  unk_token=\"[UNK]\")\n",
    "\n",
    "def tokenize_function(examples, column: str ='label'):\n",
    "    \"\"\"\n",
    "    Tokenizes text data and adds corresponding labels from a specified column.\n",
    "\n",
    "    Args:\n",
    "        examples (dict): Dictionary containing text samples to tokenize. Must have a 'text' key \n",
    "            containing the text to be tokenized.\n",
    "        column (str, optional): Name of the column containing the labels. Defaults to 'label'.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing:\n",
    "            - All tokenizer outputs (input_ids, attention_mask, etc.)\n",
    "            - 'labels': List of labels copied from the specified column\n",
    "\n",
    "    Notes:\n",
    "        - Uses a global 'tokenizer' object which must be defined before calling this function\n",
    "        - Truncates sequences to max_length=64 tokens\n",
    "        - Uses padding='max_length' to pad all sequences to the same length\n",
    "        \n",
    "    Example:\n",
    "        >>> data = {'text': ['sample text'], 'label': [1]}\n",
    "        >>> tokenized = tokenize_function(data)\n",
    "        >>> print(tokenized.keys())\n",
    "        dict_keys(['input_ids', 'attention_mask', 'labels'])\n",
    "    \"\"\"\n",
    "    tokenized = tokenizer(\n",
    "        examples['text'],\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=64\n",
    "    )\n",
    "    tokenized['labels'] = examples[column]  \n",
    "    return tokenized\n",
    "\n",
    "encoded_dataset = dataset.map(tokenize_function, batched=True)\n",
    "vocab_size = tokenizer.vocab_size\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28996"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver los tokens problem치ticos\n",
    "problematic_tokens = []\n",
    "for i, tokens in enumerate(encoded_dataset['input_ids']):\n",
    "    if max(tokens) >= vocab_size:\n",
    "        problematic_tokens.append((i, max(tokens)))\n",
    "        print(f\"Ejemplo {i}, token problem치tico: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'nivel_risa', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 19417\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'nivel_risa', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 12231\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'nivel_risa', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 1360\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'nivel_risa', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 5826\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_validation_test_split = encoded_dataset.train_test_split(test_size=0.3, seed=42)\n",
    "\n",
    "train_validation_split = train_validation_test_split['train'].train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "final_split = DatasetDict({\n",
    "    'train': train_validation_split['train'],  # 70% * 0.9 = 63% del total\n",
    "    'validation': train_validation_split['test'],  # 70% * 0.1 = 7% del total\n",
    "    'test': train_validation_test_split['test']  # 30% del total\n",
    "})\n",
    "\n",
    "# Revisar tama침os\n",
    "print(final_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({\n",
    "    'text': final_split['test']['text'],\n",
    "    'label': final_split['test']['labels']\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "test_df.to_csv('data/testing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12231"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_split['train'].num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar una muestra aleatoria de 500 ejemplos para entrenamiento y 100 para validaci칩n\n",
    "train_sample = final_split['train'].shuffle(seed=42).select(range(500))\n",
    "validation_sample = final_split['validation'].shuffle(seed=42).select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Temp\\ipykernel_43424\\2023103589.py:33: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = df.groupby(column).apply(lambda x: x.sample(n=num_samples, random_state=42))\n"
     ]
    }
   ],
   "source": [
    "def sample_dataset(dataset, column, num_samples=20):\n",
    "    \"\"\"\n",
    "    Creates a balanced sample of data by sampling an equal number of records from each category.\n",
    "\n",
    "    Args:\n",
    "        dataset (Union[Dataset, pd.DataFrame]): Input dataset, can be either a Hugging Face Dataset \n",
    "            or pandas DataFrame.\n",
    "        column (str): Name of the column to stratify by (e.g., class labels).\n",
    "        num_samples (int, optional): Number of samples to take from each unique value in the specified \n",
    "            column. Defaults to 20.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame containing the balanced sample with index reset.\n",
    "        \n",
    "    Notes:\n",
    "        - Uses random_state=42 for reproducibility\n",
    "        - If a category has fewer samples than requested, may raise ValueError\n",
    "        - Automatically converts Hugging Face Dataset to pandas DataFrame if needed\n",
    "        \n",
    "    Example:\n",
    "        >>> df = pd.DataFrame({'text': ['a', 'b', 'c', 'd'], 'label': [0, 0, 1, 1]})\n",
    "        >>> balanced = sample_dataset(df, 'label', num_samples=1)\n",
    "        >>> print(balanced)\n",
    "           text  label\n",
    "        0    a      0\n",
    "        1    c      1\n",
    "    \"\"\"\n",
    "    if isinstance(dataset, Dataset):\n",
    "        df = dataset.to_pandas()\n",
    "    else:\n",
    "        df = dataset\n",
    "    \n",
    "    sampled_df = df.groupby(column).apply(lambda x: x.sample(n=num_samples, random_state=42))\n",
    "    return sampled_df.reset_index(drop=True)\n",
    "\n",
    "# Function to get predictions with proper tensor handling\n",
    "def get_prediction(model, text):\n",
    "    \"\"\"\n",
    "    Generates a single class prediction for a given text using a PyTorch model.\n",
    "\n",
    "    Args:\n",
    "        model: PyTorch model with a predict method that returns probabilities.\n",
    "        text (str): Input text to classify.\n",
    "\n",
    "    Returns:\n",
    "        int: Predicted class index (argmax of model probabilities).\n",
    "\n",
    "    Notes:\n",
    "        - Disables gradient computation for inference efficiency\n",
    "        - Assumes model.predict() returns a tensor of class probabilities\n",
    "        - Automatically handles tensor-to-numpy conversion\n",
    "        \n",
    "    Example:\n",
    "        >>> predicted_class = get_prediction(model, \"sample text\")\n",
    "        >>> print(predicted_class)\n",
    "        1\n",
    "    \"\"\"\n",
    "    # Get prediction probabilities\n",
    "    with torch.no_grad():  # Disable gradient tracking\n",
    "        probs = model.predict(text)\n",
    "        # Detach from computation graph and convert to numpy\n",
    "        return probs.detach().numpy().argmax()\n",
    "\n",
    "# Sample 20 rows per class\n",
    "sampled_data = sample_dataset(dataset, column=\"label\", num_samples=20)\n",
    "\n",
    "# Extract texts and labels\n",
    "texts = sampled_data[\"text\"].tolist()\n",
    "true_labels = sampled_data[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only Label - Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred,binary:bool=True):\n",
    "    \"\"\"\n",
    "    Compute evaluation metrics for model predictions.\n",
    "    \n",
    "    Args:\n",
    "        eval_pred (tuple): Tuple of predictions and labels\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing accuracy metric\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if binary:\n",
    "            predictions, labels = eval_pred\n",
    "            predictions = np.argmax(predictions, axis=1)\n",
    "            return {\"accuracy\": accuracy_score(labels, predictions)}\n",
    "        else:\n",
    "            predictions, labels = eval_pred\n",
    "            predictions = np.argmax(predictions, axis=1)\n",
    "            accuracy = accuracy_score(labels, predictions)\n",
    "            \n",
    "            label_encoder = LabelEncoder()\n",
    "            \n",
    "            # Convert numeric predictions back to original labels for better understanding\n",
    "            pred_original = label_encoder.inverse_transform(predictions)\n",
    "            labels_original = label_encoder.inverse_transform(labels)\n",
    "            \n",
    "            return {\n",
    "                \"accuracy\": accuracy,\n",
    "                \"predictions\": pred_original.tolist()[:5],  # Show first 5 predictions\n",
    "                \"true_labels\": labels_original.tolist()[:5]  # Show first 5 true labels\n",
    "            }\n",
    "                \n",
    "    except Exception as e:\n",
    "            print(f\"Error on compute_metrics: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification \n",
    "\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-large-cased', num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 游뱅 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"steps\",\n",
    "    learning_rate=5.0e-05,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    use_cpu = False,\n",
    "    fp16=True,\n",
    "    save_total_limit=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizer(name_or_path='bert-large-cased', vocab_size=28996, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_sample,      \n",
    "    eval_dataset=validation_sample,  \n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo con captioning de GPT - 1000 data train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cargar el modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from models.finetuning import FineTuning\n",
    "\n",
    "# Initialize and load the model\n",
    "model_1k_gpt_finetuning = FineTuning(num_labels=2)\n",
    "model_path = r\"models\\binary\\complete_dataset_chistes_finetuning_binary_model_1000_300\"\n",
    "model_1k_gpt_finetuning.load_model(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 0 20]\n",
      " [ 0 20]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.50      1.00      0.67        20\n",
      "\n",
      "    accuracy                           0.50        40\n",
      "   macro avg       0.25      0.50      0.33        40\n",
      "weighted avg       0.25      0.50      0.33        40\n",
      "\n",
      "\n",
      "Sample Predictions:\n",
      "\n",
      "Text: para Mar칤a de la Piedad una existencia de abandonada. De repente, todo en torno de ella --la enferme...\n",
      "True Label: 0\n",
      "Predicted: 1\n",
      "\n",
      "Text: Hospital General y un cesante, a quien llamaban don Cleto. Don Cleto Meana era el fil칩sofo de la cas...\n",
      "True Label: 0\n",
      "Predicted: 1\n",
      "\n",
      "Text: v칤 hecho minero, Mas nunca tuvo el pobre mina buena: Busquemos una agora en otro canto, Que ya cansa...\n",
      "True Label: 0\n",
      "Predicted: 1\n",
      "\n",
      "Text: Una mano blanca y fr칤a, blanca como la nieve y como la nieve fr칤a, toc칩 su mano. Y sinti칩 Augusto qu...\n",
      "True Label: 0\n",
      "Predicted: 1\n",
      "\n",
      "Text: nada!--rugi칩 el Capit치n con suma nobleza.--춰Pues no faltaba m치s, estando yo en el mundo![290]--Ciert...\n",
      "True Label: 0\n",
      "Predicted: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = [get_prediction(model_1k_gpt_finetuning, text) for text in texts]\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "class_report = classification_report(true_labels, predictions)\n",
    "\n",
    "# Display results\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Optional: Display predictions alongside texts\n",
    "print(\"\\nSample Predictions:\")\n",
    "for text, true_label, pred in zip(texts[:5], true_labels[:5], predictions[:5]):\n",
    "    print(f\"\\nText: {text[:100]}...\")  # Show first 100 chars\n",
    "    print(f\"True Label: {true_label}\")\n",
    "    print(f\"Predicted: {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metrics evaluation on validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Results for finetuning_bert (binary):\n",
      "--------------------------------------------------\n",
      "eval_loss: 0.6927055716514587\n",
      "eval_accuracy: 0.5183823529411765\n",
      "eval_f1_score: 0.6828087167070218\n",
      "eval_f1_score_micro: 0.5183823529411765\n",
      "eval_recall: 1.0\n",
      "eval_runtime: 3.5107\n",
      "eval_samples_per_second: 387.388\n",
      "eval_steps_per_second: 48.423\n",
      "epoch: 4.12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\binary\\evaluation\\finetuning_bert_complete_dataset_chistes_1000_validation_results.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Results for finetuning_bert (binary):\n",
      "--------------------------------------------------\n",
      "eval_loss: 0.6937559843063354\n",
      "eval_accuracy: 0.5092687950566427\n",
      "eval_f1_score: 0.6748549982940976\n",
      "eval_f1_score_micro: 0.5092687950566427\n",
      "eval_recall: 1.0\n",
      "eval_runtime: 14.9526\n",
      "eval_samples_per_second: 389.63\n",
      "eval_steps_per_second: 48.754\n",
      "epoch: 4.12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\binary\\testing\\finetuning_bert_binary_complete_dataset_chistes_1000_test_evaluation.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo con captioning de GPT - 5000 data train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from models.finetuning import FineTuning\n",
    "\n",
    "# Initialize and load the model\n",
    "model_5k_gpt_finetuning_binary = FineTuning(num_labels=2)\n",
    "model_path = r\"models\\binary\\complete_dataset_chistes_finetuning_binary_model_5000_300\"\n",
    "model_5k_gpt_finetuning_binary.load_model(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[20  0]\n",
      " [ 5 15]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        20\n",
      "           1       1.00      0.75      0.86        20\n",
      "\n",
      "    accuracy                           0.88        40\n",
      "   macro avg       0.90      0.88      0.87        40\n",
      "weighted avg       0.90      0.88      0.87        40\n",
      "\n",
      "\n",
      "Sample Predictions:\n",
      "\n",
      "Text: para Mar칤a de la Piedad una existencia de abandonada. De repente, todo en torno de ella --la enferme...\n",
      "True Label: 0\n",
      "Predicted: 0\n",
      "\n",
      "Text: Hospital General y un cesante, a quien llamaban don Cleto. Don Cleto Meana era el fil칩sofo de la cas...\n",
      "True Label: 0\n",
      "Predicted: 0\n",
      "\n",
      "Text: v칤 hecho minero, Mas nunca tuvo el pobre mina buena: Busquemos una agora en otro canto, Que ya cansa...\n",
      "True Label: 0\n",
      "Predicted: 0\n",
      "\n",
      "Text: Una mano blanca y fr칤a, blanca como la nieve y como la nieve fr칤a, toc칩 su mano. Y sinti칩 Augusto qu...\n",
      "True Label: 0\n",
      "Predicted: 0\n",
      "\n",
      "Text: nada!--rugi칩 el Capit치n con suma nobleza.--춰Pues no faltaba m치s, estando yo en el mundo![290]--Ciert...\n",
      "True Label: 0\n",
      "Predicted: 0\n"
     ]
    }
   ],
   "source": [
    "predictions = [get_prediction(model_5k_gpt_finetuning_binary, text) for text in texts]\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "class_report = classification_report(true_labels, predictions)\n",
    "\n",
    "# Display results\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Optional: Display predictions alongside texts\n",
    "print(\"\\nSample Predictions:\")\n",
    "for text, true_label, pred in zip(texts[:5], true_labels[:5], predictions[:5]):\n",
    "    print(f\"\\nText: {text[:100]}...\")  # Show first 100 chars\n",
    "    print(f\"True Label: {true_label}\")\n",
    "    print(f\"Predicted: {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metrics on validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Results for finetuning_bert (binary):\n",
      "--------------------------------------------------\n",
      "eval_loss: 0.35674652457237244\n",
      "eval_accuracy: 0.8455882352941176\n",
      "eval_f1_score: 0.825\n",
      "eval_f1_score_micro: 0.8455882352941176\n",
      "eval_recall: 0.7021276595744681\n",
      "eval_runtime: 3.6226\n",
      "eval_samples_per_second: 375.423\n",
      "eval_steps_per_second: 46.928\n",
      "epoch: 0.824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\binary\\evaluation\\finetuning_bert_complete_dataset_chistes_5000_validation_results.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metrics on testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Results for finetuning_bert (binary):\n",
      "--------------------------------------------------\n",
      "eval_loss: 0.3687657415866852\n",
      "eval_accuracy: 0.8405423961551665\n",
      "eval_f1_score: 0.8145338390896386\n",
      "eval_f1_score_micro: 0.8405423961551665\n",
      "eval_recall: 0.6875631951466128\n",
      "eval_runtime: 14.7873\n",
      "eval_samples_per_second: 393.987\n",
      "eval_steps_per_second: 49.299\n",
      "epoch: 0.824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\binary\\testing\\finetuning_bert_binary_complete_dataset_chistes_5000_test_evaluation.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo con captioning de GPT - All data train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from models.finetuning import FineTuning\n",
    "\n",
    "# Initialize and load the model\n",
    "model_12k_gpt_finetuning = FineTuning(num_labels=2)\n",
    "model_path = r\"models\\binary\\complete_dataset_chistes_finetuning_binary_model_12231_300\"\n",
    "model_12k_gpt_finetuning.load_model(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[20  0]\n",
      " [20  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67        20\n",
      "           1       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.50        40\n",
      "   macro avg       0.25      0.50      0.33        40\n",
      "weighted avg       0.25      0.50      0.33        40\n",
      "\n",
      "\n",
      "Sample Predictions:\n",
      "\n",
      "Text: para Mar칤a de la Piedad una existencia de abandonada. De repente, todo en torno de ella --la enferme...\n",
      "True Label: 0\n",
      "Predicted: 0\n",
      "\n",
      "Text: Hospital General y un cesante, a quien llamaban don Cleto. Don Cleto Meana era el fil칩sofo de la cas...\n",
      "True Label: 0\n",
      "Predicted: 0\n",
      "\n",
      "Text: v칤 hecho minero, Mas nunca tuvo el pobre mina buena: Busquemos una agora en otro canto, Que ya cansa...\n",
      "True Label: 0\n",
      "Predicted: 0\n",
      "\n",
      "Text: Una mano blanca y fr칤a, blanca como la nieve y como la nieve fr칤a, toc칩 su mano. Y sinti칩 Augusto qu...\n",
      "True Label: 0\n",
      "Predicted: 0\n",
      "\n",
      "Text: nada!--rugi칩 el Capit치n con suma nobleza.--춰Pues no faltaba m치s, estando yo en el mundo![290]--Ciert...\n",
      "True Label: 0\n",
      "Predicted: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = [get_prediction(model_12k_gpt_finetuning, text) for text in texts]\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "class_report = classification_report(true_labels, predictions)\n",
    "\n",
    "# Display results\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Optional: Display predictions alongside texts\n",
    "print(\"\\nSample Predictions:\")\n",
    "for text, true_label, pred in zip(texts[:5], true_labels[:5], predictions[:5]):\n",
    "    print(f\"\\nText: {text[:100]}...\")  # Show first 100 chars\n",
    "    print(f\"True Label: {true_label}\")\n",
    "    print(f\"Predicted: {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metrics on validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Results for finetuning_bert (binary):\n",
      "--------------------------------------------------\n",
      "eval_loss: 0.6962682604789734\n",
      "eval_accuracy: 0.48161764705882354\n",
      "eval_f1_score: 0.0\n",
      "eval_f1_score_micro: 0.48161764705882354\n",
      "eval_recall: 0.0\n",
      "eval_runtime: 3.2242\n",
      "eval_samples_per_second: 421.809\n",
      "eval_steps_per_second: 52.726\n",
      "epoch: 0.6638325703073904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\binary\\evaluation\\finetuning_bert_complete_dataset_chistes_12231_validation_results.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metrics on testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Results for finetuning_bert (binary):\n",
      "--------------------------------------------------\n",
      "eval_loss: 0.6953372359275818\n",
      "eval_accuracy: 0.49073120494335737\n",
      "eval_f1_score: 0.0\n",
      "eval_f1_score_micro: 0.49073120494335737\n",
      "eval_recall: 0.0\n",
      "eval_runtime: 13.7737\n",
      "eval_samples_per_second: 422.981\n",
      "eval_steps_per_second: 52.927\n",
      "epoch: 0.6638325703073904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\binary\\testing\\finetuning_bert_binary_complete_dataset_chistes_12231_test_evaluation.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo con captioning de blip - All data train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from models.finetuning import FineTuning\n",
    "\n",
    "# Initialize and load the model\n",
    "model_12k_blip_finetuning_binary = FineTuning(num_labels=2)\n",
    "model_path = r\"models\\binary\\captionning_blip_finetuning_binary_model_12225_300\"\n",
    "model_12k_blip_finetuning_binary.load_model(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 0 20]\n",
      " [ 0 20]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.50      1.00      0.67        20\n",
      "\n",
      "    accuracy                           0.50        40\n",
      "   macro avg       0.25      0.50      0.33        40\n",
      "weighted avg       0.25      0.50      0.33        40\n",
      "\n",
      "\n",
      "Sample Predictions:\n",
      "\n",
      "Text: para Mar칤a de la Piedad una existencia de abandonada. De repente, todo en torno de ella --la enferme...\n",
      "True Label: 0\n",
      "Predicted: 1\n",
      "\n",
      "Text: Hospital General y un cesante, a quien llamaban don Cleto. Don Cleto Meana era el fil칩sofo de la cas...\n",
      "True Label: 0\n",
      "Predicted: 1\n",
      "\n",
      "Text: v칤 hecho minero, Mas nunca tuvo el pobre mina buena: Busquemos una agora en otro canto, Que ya cansa...\n",
      "True Label: 0\n",
      "Predicted: 1\n",
      "\n",
      "Text: Una mano blanca y fr칤a, blanca como la nieve y como la nieve fr칤a, toc칩 su mano. Y sinti칩 Augusto qu...\n",
      "True Label: 0\n",
      "Predicted: 1\n",
      "\n",
      "Text: nada!--rugi칩 el Capit치n con suma nobleza.--춰Pues no faltaba m치s, estando yo en el mundo![290]--Ciert...\n",
      "True Label: 0\n",
      "Predicted: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = [get_prediction(model_12k_blip_finetuning_binary, text) for text in texts]\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "class_report = classification_report(true_labels, predictions)\n",
    "\n",
    "# Display results\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Optional: Display predictions alongside texts\n",
    "print(\"\\nSample Predictions:\")\n",
    "for text, true_label, pred in zip(texts[:5], true_labels[:5], predictions[:5]):\n",
    "    print(f\"\\nText: {text[:100]}...\")  # Show first 100 chars\n",
    "    print(f\"True Label: {true_label}\")\n",
    "    print(f\"Predicted: {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metrics on evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Results for finetuning_bert (binary):\n",
      "--------------------------------------------------\n",
      "eval_loss: 0.6977542638778687\n",
      "eval_accuracy: 0.4952170713760118\n",
      "eval_f1_score: 0.6624015748031497\n",
      "eval_f1_score_micro: 0.4952170713760118\n",
      "eval_recall: 1.0\n",
      "eval_runtime: 3.7709\n",
      "eval_samples_per_second: 360.39\n",
      "eval_steps_per_second: 45.082\n",
      "epoch: 0.3368214519293656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\binary\\evaluation\\finetuning_bert_captionning_blip_12225_validation_results.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metrics on testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Results for finetuning_bert (binary):\n",
      "--------------------------------------------------\n",
      "eval_loss: 0.6942014098167419\n",
      "eval_accuracy: 0.5145997938852628\n",
      "eval_f1_score: 0.6795191653436153\n",
      "eval_f1_score_micro: 0.5145997938852628\n",
      "eval_recall: 1.0\n",
      "eval_runtime: 16.1916\n",
      "eval_samples_per_second: 359.568\n",
      "eval_steps_per_second: 44.961\n",
      "epoch: 0.3368214519293656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\binary\\testing\\finetuning_bert_binary_captionning_blip_12225_test_evaluation.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_lstm(classifier, text: str):\n",
    "    \"\"\"\n",
    "    Generates binary predictions for text using a BERT-tokenized LSTM classifier.\n",
    "    \n",
    "    Args:\n",
    "        classifier: LSTM classifier with encode_data and predict methods.\n",
    "                   Must accept BERT tokenized inputs and return probabilities.\n",
    "        text (str): Raw text input to classify.\n",
    "    \n",
    "    Returns:\n",
    "        int: Binary prediction (0 or 1) based on 0.5 threshold.\n",
    "    \n",
    "    Notes:\n",
    "        - Uses bert-large-cased tokenizer\n",
    "        - Truncates/pads sequences to 64 tokens\n",
    "        - Returns numpy array format with a dummy label\n",
    "        - Assumes classifier.encode_data() returns tuple of (input_ids, attention_mask, token_type_ids)\n",
    "        - Assumes classifier.predict() returns probability scores\n",
    "        \n",
    "    Workflow:\n",
    "        1. Tokenizes input text using BERT tokenizer\n",
    "        2. Formats tokens into required structure with dummy label\n",
    "        3. Encodes data using classifier's encode_data method\n",
    "        4. Gets probability predictions\n",
    "        5. Applies 0.5 threshold to get binary prediction\n",
    "        \n",
    "    Example:\n",
    "        >>> prediction = get_prediction_lstm(lstm_classifier, \"Sample text to classify\")\n",
    "        >>> print(prediction)  # Prints 0 or 1\n",
    "        1\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-large-cased')\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=64,\n",
    "        return_tensors='np'\n",
    "    )\n",
    "    \n",
    "    # Create properly formatted input\n",
    "    single_item = [{\n",
    "        'input_ids': tokens['input_ids'][0],\n",
    "        'attention_mask': tokens['attention_mask'][0],\n",
    "        'token_type_ids': tokens['token_type_ids'][0],\n",
    "        'labels': 0  # dummy label\n",
    "    }]\n",
    "    \n",
    "    # Get encoded input and predictions\n",
    "    encoded_input = classifier.encode_data(single_item)\n",
    "    probs = classifier.predict(encoded_input[0], encoded_input[1], encoded_input[2])\n",
    "    \n",
    "    return (probs > 0.5).astype(int)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datasets import DatasetDict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizer(name_or_path='bert-large-cased', vocab_size=28996, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'nivel_risa', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 19417\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'nivel_risa', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 12231\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample_1 = final_split['train']\n",
    "train_sample_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'nivel_risa', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 1360\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_sample_1 = final_split['validation']\n",
    "validation_sample_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertModel\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert_model = TFBertModel.from_pretrained('bert-large-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARCHITECTURE 1 - LSTM 2 One Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import load_model\n",
    "from models.encoder_only_lstm import LSTM_1Classifier, LSTM_2Classifier\n",
    "from keras.utils import custom_object_scope\n",
    "\n",
    "# Initialize classifier\n",
    "classifier_lstm2_binary = LSTM_2Classifier(bert_path='bert-large-cased', max_length=64)\n",
    "\n",
    "# Get the custom BertLayer class\n",
    "BertLayer = classifier_lstm2_binary.BertLayer\n",
    "\n",
    "# Load the model with custom_object_scope\n",
    "with custom_object_scope({'BertLayer': BertLayer}):\n",
    "    classifier_lstm2_binary.model = load_model('models/binary/lstm2_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 8s 8s/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 422ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 312ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "Confusion Matrix:\n",
      "[[20  0]\n",
      " [ 0 20]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        40\n",
      "   macro avg       1.00      1.00      1.00        40\n",
      "weighted avg       1.00      1.00      1.00        40\n",
      "\n",
      "\n",
      "Sample Predictions:\n",
      "\n",
      "Text: para Mar칤a de la Piedad una existencia de abandonada. De repente, todo en torno de ella --la enferme...\n",
      "True Label: 0\n",
      "Predicted: [0]\n",
      "\n",
      "Text: Hospital General y un cesante, a quien llamaban don Cleto. Don Cleto Meana era el fil칩sofo de la cas...\n",
      "True Label: 0\n",
      "Predicted: [0]\n",
      "\n",
      "Text: v칤 hecho minero, Mas nunca tuvo el pobre mina buena: Busquemos una agora en otro canto, Que ya cansa...\n",
      "True Label: 0\n",
      "Predicted: [0]\n",
      "\n",
      "Text: Una mano blanca y fr칤a, blanca como la nieve y como la nieve fr칤a, toc칩 su mano. Y sinti칩 Augusto qu...\n",
      "True Label: 0\n",
      "Predicted: [0]\n",
      "\n",
      "Text: nada!--rugi칩 el Capit치n con suma nobleza.--춰Pues no faltaba m치s, estando yo en el mundo![290]--Ciert...\n",
      "True Label: 0\n",
      "Predicted: [0]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = [get_prediction_lstm(classifier_lstm2_binary, text) for text in texts]\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "class_report = classification_report(true_labels, predictions)\n",
    "\n",
    "# Display results\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Display sample predictions\n",
    "print(\"\\nSample Predictions:\")\n",
    "for text, true_label, pred in zip(texts[:5], true_labels[:5], predictions[:5]):\n",
    "    print(f\"\\nText: {text[:100]}...\")  # Show first 100 chars\n",
    "    print(f\"True Label: {true_label}\")\n",
    "    print(f\"Predicted: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Results for lstm2 (binary):\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.9895\n",
      "F1 Score: 0.9897\n",
      "Recall: 0.9862\n",
      "\n",
      "Debug Information:\n",
      "Unique predicted classes: [0 1]\n",
      "Unique true labels: [0 1]\n",
      "Number of samples: 5826\n",
      "\n",
      "Class Distribution:\n",
      "Predicted positives: 2946\n",
      "Predicted negatives: 2880\n",
      "Actual positives: 2967\n",
      "Actual negatives: 2859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\binary\\testing\\lstm2_binary_test_evaluation.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)      [(None, 64)]                 0         []                            \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer  [(None, 64)]                 0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " token_type_ids (InputLayer  [(None, 64)]                 0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bert_layer (BertLayer)      (None, 64, 1024)             3335792   ['input_ids[0][0]',           \n",
      "                                                          64         'attention_mask[0][0]',      \n",
      "                                                                     'token_type_ids[0][0]']      \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, 64, 1024)             0         ['bert_layer[0][0]',          \n",
      "                                                                     'bert_layer[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 64, 2048)             0         ['bert_layer[0][0]',          \n",
      "                                                                     'attention[0][0]']           \n",
      "                                                                                                  \n",
      " bidirectional (Bidirection  (None, 512)                  4720640   ['concatenate[0][0]']         \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    513       ['bidirectional[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 338300417 (1.26 GB)\n",
      "Trainable params: 4721153 (18.01 MB)\n",
      "Non-trainable params: 333579264 (1.24 GB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_lstm2_binary.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Results for lstm2 (binary):\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.9934\n",
      "F1 Score: 0.9936\n",
      "Recall: 0.9929\n",
      "\n",
      "Debug Information:\n",
      "Number of validation samples: 1360\n",
      "Unique predicted classes: [0 1]\n",
      "Unique true labels: [0 1]\n",
      "\n",
      "Class Distribution:\n",
      "Predicted positives: 704\n",
      "Predicted negatives: 656\n",
      "Actual positives: 705\n",
      "Actual negatives: 655\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\binary\\evaluation\\lstm2_validation_results.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture 2 - LSTM 1 Two layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Initialize classifier\n",
    "classifier_lstm1_binary = LSTM_1Classifier(bert_path='bert-large-cased', max_length=64)\n",
    "\n",
    "# Get the custom BertLayer class\n",
    "BertLayer = classifier_lstm1_binary.BertLayer\n",
    "\n",
    "# Load the model with custom_object_scope\n",
    "with custom_object_scope({'BertLayer': BertLayer}):\n",
    "    classifier_lstm1_binary.model = load_model('models/binary/lstm1_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 8s 8s/step\n",
      "1/1 [==============================] - 0s 462ms/step\n",
      "1/1 [==============================] - 0s 403ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 435ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 408ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 449ms/step\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 478ms/step\n",
      "1/1 [==============================] - 0s 422ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 426ms/step\n",
      "1/1 [==============================] - 0s 450ms/step\n",
      "1/1 [==============================] - 0s 422ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "Confusion Matrix:\n",
      "[[20  0]\n",
      " [ 0 20]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        40\n",
      "   macro avg       1.00      1.00      1.00        40\n",
      "weighted avg       1.00      1.00      1.00        40\n",
      "\n",
      "\n",
      "Sample Predictions:\n",
      "\n",
      "Text: para Mar칤a de la Piedad una existencia de abandonada. De repente, todo en torno de ella --la enferme...\n",
      "True Label: 0\n",
      "Predicted: [0]\n",
      "\n",
      "Text: Hospital General y un cesante, a quien llamaban don Cleto. Don Cleto Meana era el fil칩sofo de la cas...\n",
      "True Label: 0\n",
      "Predicted: [0]\n",
      "\n",
      "Text: v칤 hecho minero, Mas nunca tuvo el pobre mina buena: Busquemos una agora en otro canto, Que ya cansa...\n",
      "True Label: 0\n",
      "Predicted: [0]\n",
      "\n",
      "Text: Una mano blanca y fr칤a, blanca como la nieve y como la nieve fr칤a, toc칩 su mano. Y sinti칩 Augusto qu...\n",
      "True Label: 0\n",
      "Predicted: [0]\n",
      "\n",
      "Text: nada!--rugi칩 el Capit치n con suma nobleza.--춰Pues no faltaba m치s, estando yo en el mundo![290]--Ciert...\n",
      "True Label: 0\n",
      "Predicted: [0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make predictions\n",
    "predictions = [get_prediction_lstm(classifier_lstm1_binary, text) for text in texts]\n",
    "\n",
    "# Calculate metrics\n",
    "conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "class_report = classification_report(true_labels, predictions)\n",
    "\n",
    "# Display results\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Display sample predictions\n",
    "print(\"\\nSample Predictions:\")\n",
    "for text, true_label, pred in zip(texts[:5], true_labels[:5], predictions[:5]):\n",
    "    print(f\"\\nText: {text[:100]}...\")  # Show first 100 chars\n",
    "    print(f\"True Label: {true_label}\")\n",
    "    print(f\"Predicted: {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results on testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Results for lstm1 (binary):\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.9827\n",
      "F1 Score: 0.9827\n",
      "Recall: 0.9690\n",
      "\n",
      "Debug Information:\n",
      "Unique predicted classes: [0 1]\n",
      "Unique true labels: [0 1]\n",
      "Number of samples: 5826\n",
      "\n",
      "Class Distribution:\n",
      "Predicted positives: 2884\n",
      "Predicted negatives: 2942\n",
      "Actual positives: 2967\n",
      "Actual negatives: 2859\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\binary\\testing\\lstm1_binary_test_evaluation.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results on evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Results for lstm1 (binary):\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.9926\n",
      "F1 Score: 0.9929\n",
      "Recall: 0.9872\n",
      "\n",
      "Debug Information:\n",
      "Number of validation samples: 1360\n",
      "Unique predicted classes: [0 1]\n",
      "Unique true labels: [0 1]\n",
      "\n",
      "Class Distribution:\n",
      "Predicted positives: 697\n",
      "Predicted negatives: 663\n",
      "Actual positives: 705\n",
      "Actual negatives: 655\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\binary\\evaluation\\lstm1_validation_results.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)      [(None, 64)]                 0         []                            \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer  [(None, 64)]                 0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " token_type_ids (InputLayer  [(None, 64)]                 0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bert_layer (BertLayer)      (None, 64, 1024)             3335792   ['input_ids[0][0]',           \n",
      "                                                          64         'attention_mask[0][0]',      \n",
      "                                                                     'token_type_ids[0][0]']      \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, 64, 1024)             0         ['bert_layer[0][0]',          \n",
      "                                                                     'bert_layer[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 64, 2048)             0         ['bert_layer[0][0]',          \n",
      "                                                                     'attention[0][0]']           \n",
      "                                                                                                  \n",
      " bidirectional (Bidirection  (None, 64, 512)              4720640   ['concatenate[0][0]']         \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " dropout_73 (Dropout)        (None, 64, 512)              0         ['bidirectional[0][0]']       \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirecti  (None, 512)                  1574912   ['dropout_73[0][0]']          \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    513       ['bidirectional_1[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 339875329 (1.27 GB)\n",
      "Trainable params: 6296065 (24.02 MB)\n",
      "Non-trainable params: 333579264 (1.24 GB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_lstm1_binary.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multifactorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Temp\\ipykernel_43424\\2212130348.py:43: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = df.groupby(column).apply(lambda x: x.sample(n=num_samples, random_state=42))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Function to sample 20 rows per class\n",
    "def sample_dataset(dataset, column, num_samples=20):\n",
    "    \"\"\"\n",
    "    Creates a balanced dataset by sampling an equal number of rows from each class category.\n",
    "    \n",
    "    Args:\n",
    "        dataset (Union[Dataset, pd.DataFrame]): Input dataset, can be either a Hugging Face Dataset \n",
    "            or pandas DataFrame.\n",
    "        column (str): Name of the column containing class labels to stratify by.\n",
    "        num_samples (int, optional): Number of samples to draw from each unique class. \n",
    "            Defaults to 20.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: A balanced DataFrame containing the sampled data with:\n",
    "            - Equal number of samples per class\n",
    "            - Reset index\n",
    "            - All original columns preserved\n",
    "    \n",
    "    Notes:\n",
    "        - Uses random_state=42 for reproducible sampling\n",
    "        - If a class has fewer samples than num_samples, will raise ValueError\n",
    "        - Automatically converts Hugging Face Dataset to pandas DataFrame if needed\n",
    "        - Returns a new DataFrame; does not modify the input dataset\n",
    "    \n",
    "    Example:\n",
    "        >>> # For binary classification\n",
    "        >>> data = pd.DataFrame({'text': ['a', 'b', 'c', 'd'], 'label': [0, 0, 1, 1]})\n",
    "        >>> balanced = sample_dataset(data, column='label', num_samples=1)\n",
    "        >>> print(balanced['label'].value_counts())\n",
    "        0    1\n",
    "        1    1\n",
    "    \"\"\"\n",
    "    # Convert Dataset to a pandas DataFrame if necessary\n",
    "    if isinstance(dataset, Dataset):\n",
    "        df = dataset.to_pandas()\n",
    "    else:\n",
    "        df = dataset\n",
    "\n",
    "    sampled_df = df.groupby(column).apply(lambda x: x.sample(n=num_samples, random_state=42))\n",
    "    return sampled_df.reset_index(drop=True)\n",
    "\n",
    "# Sample 20 rows per class\n",
    "sampled_data = sample_dataset(dataset, column=\"nivel_risa\", num_samples=20)\n",
    "\n",
    "# Extract texts and labels\n",
    "texts = sampled_data[\"text\"].tolist()  # Assuming the column with text data is 'text'\n",
    "true_labels = sampled_data[\"nivel_risa\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>nivel_risa</th>\n",
       "      <th>nivel_risa_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No hay vuelta que darle dijo el que dormia en ...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La que me gusta se ha quitado la foto de perfi...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Que haces cuando ves un negro desangrarse en l...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>El profesor de la materia de relleno: De ma침an...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Imagen de Bob Esponja vestido como un ganster,...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>쯈u칠 le dice una pizza a otra pizza en A침o Nue...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>쯈u칠 hace un esquiador cuando quiere contar un...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>쮺u치l es el animal m치s r치pido en el atletismo?...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>- 쯈u칠 hace un sombrero en una clase de histor...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>쯈u칠 hace una hiena en la escuela? 춰R칤e en tod...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows 칑 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  nivel_risa  \\\n",
       "0   No hay vuelta que darle dijo el que dormia en ...           4   \n",
       "1   La que me gusta se ha quitado la foto de perfi...           4   \n",
       "2   Que haces cuando ves un negro desangrarse en l...           4   \n",
       "3   El profesor de la materia de relleno: De ma침an...           4   \n",
       "4   Imagen de Bob Esponja vestido como un ganster,...           4   \n",
       "..                                                ...         ...   \n",
       "95  쯈u칠 le dice una pizza a otra pizza en A침o Nue...           1   \n",
       "96  쯈u칠 hace un esquiador cuando quiere contar un...           1   \n",
       "97  쮺u치l es el animal m치s r치pido en el atletismo?...           1   \n",
       "98  - 쯈u칠 hace un sombrero en una clase de histor...           1   \n",
       "99  쯈u칠 hace una hiena en la escuela? 춰R칤e en tod...           1   \n",
       "\n",
       "    nivel_risa_encoded  \n",
       "0                    3  \n",
       "1                    3  \n",
       "2                    3  \n",
       "3                    3  \n",
       "4                    3  \n",
       "..                 ...  \n",
       "95                   0  \n",
       "96                   0  \n",
       "97                   0  \n",
       "98                   0  \n",
       "99                   0  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data.to_csv(\"data/balanced_sample_multifactorial.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping: {1: 0, 2: 1, 3: 2, 4: 3, 5: 4}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset, label_encoder = combine_dataframes(\n",
    "    \"data/classification/complete_dataset_chistes.csv\",\n",
    "    \"data/classification/data_with_no_humour.csv\",one_hot=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validation_test_split = encoded_dataset.train_test_split(test_size=0.3, seed=42)\n",
    "train_validation_split = train_validation_test_split['train'].train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "final_split = DatasetDict({\n",
    "    'train': train_validation_split['train'],\n",
    "    'validation': train_validation_split['test'],\n",
    "    'test': train_validation_test_split['test']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'nivel_risa', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 12231\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'nivel_risa', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1360\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'nivel_risa', 'label', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 5826\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = final_split['train'].shuffle(seed=42).select(range(500))\n",
    "validation_sample = final_split['validation'].shuffle(seed=42).select(range(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41388225411745a5a1b313bc4427a761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9933 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_dataset = dataset.map(\n",
    "    lambda x: tokenize_function(x, column='nivel_risa_encoded'), \n",
    "    batched=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nivel_risa categories: 5\n"
     ]
    }
   ],
   "source": [
    "num_labels = len(label_encoder.classes_)\n",
    "print(f\"Number of nivel_risa categories: {num_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-large-cased', \n",
    "    num_labels=num_labels  # Set number of labels to match nivel_risa categories\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_multifactorial(binary:bool=True, encoder=None):\n",
    "    \"\"\"\n",
    "    Compute evaluation metrics for model predictions.\n",
    "    \n",
    "    Args:\n",
    "        binary (bool): Whether to compute metrics for binary classification\n",
    "        encoder: LabelEncoder instance for non-binary classification\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing metrics\n",
    "    \"\"\"\n",
    "    def compute(eval_pred):\n",
    "        try:\n",
    "            if binary:\n",
    "                predictions, labels = eval_pred\n",
    "                predictions = np.argmax(predictions, axis=1)\n",
    "                return {\"accuracy\": accuracy_score(labels, predictions)}\n",
    "            else:\n",
    "                predictions, labels = eval_pred\n",
    "                predictions = np.argmax(predictions, axis=1)\n",
    "                accuracy = accuracy_score(labels, predictions)\n",
    "                \n",
    "                # Use the passed encoder\n",
    "                pred_original = encoder.inverse_transform(predictions)\n",
    "                labels_original = encoder.inverse_transform(labels)\n",
    "                \n",
    "                # Convert lists to strings to avoid TensorBoard warning\n",
    "                pred_examples = ','.join(map(str, pred_original[:5]))\n",
    "                label_examples = ','.join(map(str, labels_original[:5]))\n",
    "                \n",
    "                return {\n",
    "                    \"accuracy\": accuracy,\n",
    "                    \"predictions_sample\": pred_examples,  # Now a string\n",
    "                    \"true_labels_sample\": label_examples,  # Now a string\n",
    "                    # Add some additional scalar metrics\n",
    "                    \"pred_mean\": predictions.mean(),\n",
    "                    \"pred_std\": predictions.std(),\n",
    "                }\n",
    "                    \n",
    "        except Exception as e:\n",
    "                print(f\"Error on compute_metrics: {e}\")\n",
    "    \n",
    "    return compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 游뱅 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./finetuning_multifactorial_model',\n",
    "    evaluation_strategy=\"steps\",\n",
    "    learning_rate=5.0e-05,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    use_cpu=False,\n",
    "    fp16=True,\n",
    "    save_total_limit=1,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_sample,\n",
    "    eval_dataset=validation_sample,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics_multifactorial(encoder=label_encoder),  \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['para Mar칤a de la Piedad una existencia de abandonada. De repente, todo en torno de ella --la enfermedad del marido, achaques de los hijos, tristezas de sus d칤as, la costura--',\n",
       " 'Hospital General y un cesante, a quien llamaban don Cleto. Don Cleto Meana era el fil칩sofo de la casa, era un hombre bien educado y culto, que hab칤a ca칤do en',\n",
       " 'v칤 hecho minero, Mas nunca tuvo el pobre mina buena: Busquemos una agora en otro canto, Que ya cansa decir en este tanto. CANTO SEXTO. _Viene Obispo al Paraguay. Muere',\n",
       " 'Una mano blanca y fr칤a, blanca como la nieve y como la nieve fr칤a, toc칩 su mano. Y sinti칩 Augusto que se derramaba por su ser todo como un fluido',\n",
       " 'nada!--rugi칩 el Capit치n con suma nobleza.--춰Pues no faltaba m치s, estando yo en el mundo![290]--Cierto es que el pobre 츼lvaro...--yo no quiero quitarle su m칠rito,--en cuanto supo[291] la fatal ocurrencia se',\n",
       " 'aqu칤 estuvieres, p칤delo; que por este buen servicio que me has hecho, se har치 por ti. Yo, como no esperaba tal ganancia, lleno de placer tom칠 mis ducados resplandecientes, y',\n",
       " 'empacadas. Pedimos _t칠_, que genu칤namente se pronuncia _Cham_: tendi칩 el sirviente el mantel y nos pusimos en tren de hacer la libacion Asi치tica. Colocaron en la mesa panecillos y dulces:',\n",
       " 'pasarlo muy mal si uno de ellos le acertaba; mas los denuestos continuaron a m치s y mejor, mientras se iba aplacando lentamente la c칩lera. --춰El demonio del capellanzote!... 춰Si pensar치',\n",
       " 'se quer칤a hacer. Yo, que deseaba mucho saber lo que pasaba acerca de mi muerto, llegueme cuanto pude a la tumba y aun hall칠 una piedra en que puse los',\n",
       " 'las exequias, y le daremos sepultura. Su duelo toca tambi칠n a toda la raza de Cadmo; y en punto a justicia a las veces el pueblo muda de pareceres. SEGUNDO',\n",
       " 'multiplicarse y precipitarse los acontecimientos, concluye por carecer de magnitud y hasta de espacio. Un viaje de varios d칤as no acertamos siquiera a concebirlo; una obra lenta nos irrita. Pizarro',\n",
       " 'la esperanza de poder derribar uno o varios combatientes; mientras que el soldado antiguo, sobre todo el conquistador, ahorraba tentativas y daba directo con su espada en el pecho enemigo.',\n",
       " 'los enemigos. Estos son los capitanes de quienes hago memoria por el pronto; mas no te he dicho sino una peque침a parte de las muchas desgracias que nos rodean. ATOSSA',\n",
       " 'las cuales no se ve siempre delante de los ojos una capa flaca y moribunda, en que las noches no se pasan esperando las horas de los remedios... Hab칤a sido',\n",
       " 'no es cosa de creer que un hombre solo matase a tres tan valientes mancebos. Por tanto, mi parecer es que la verdad se sepa por cuesti칩n de tormento, porque',\n",
       " 'La lucha de la independencia hizo escuela; en las contiendas fratricidas, el partidario vivi칩 sobre el bien del enemigo, y al fin, la riqueza p칰blica entera desapareci칩 en la vor치gine',\n",
       " 'ya cogerla, y acelera sus pasos alargando el hocico, y 칠sta dudando estar cogida escapa de las mordeduras, y dexa burlada la boca que le va 치 los alcances; del',\n",
       " 'pon칤an a peligro de su salud. Entonces llev치ronme por medio del teatro los ministros de la justicia como a un carnero que quieren sacrificar, y pusi칠ronme delante del asiento de',\n",
       " 'bien, solitarios y modestos sus bienes, pocos o muchos, disimuladamente los encubren, y reciamente defienden, y con peligro de su sangre y vida los fortalecen. El mismo negocio que ahora',\n",
       " 'armas y esgrima; hay una diferencia monstruosa que es necesario suplir con una t치ctica especial. Dice a sus soldados de infanter칤a que omitan los tajos y cuchilladas, y a sus',\n",
       " '쯈u칠 hace un futbolista despu칠s de comerse una pizza? Pedir un cambio porque se siente lleno.',\n",
       " 'Hoy estamos (una gallina) y ma침ana no se sabe (un sancocho)',\n",
       " 'Una ruleta con temas incomodos como \"conspiraciones,\" \"astrologia,\" \"opiniones no deseadas,\" y \"memes,\" mientras una persona pregunta: \"Por donde empezamos?\"',\n",
       " '쯈u칠 hace un jugador de Resident Evil despu칠s de un susto? 춰Guarda su partida!',\n",
       " '쯇or qu칠 los jugadores de billar son buenos en estrategia? 춰Porque siempre tienen un 치ngulo!',\n",
       " 'Dos compadres en un bar: - Que le vas a regalar a tu novia de San Valentin? - Un collar. - Que bonito, yo aun la llevo suelta.',\n",
       " '쯇or qu칠 los caballos no viajan en tren? Porque prefieren galopar.',\n",
       " ' 쯈u칠 le dice un 치rbol a otro?\\n 쯈u칠 pasa tronco?\\n',\n",
       " 'Bob Esponja congelado y asustado en una habitacion de hielo.',\n",
       " 'Imagen de Cheems, el famoso meme de perro, acostado con expresion de resignacion. El texto dice \"Jueves\", indicando probablemente el cansancio tipico de mediados de semana.',\n",
       " '쯈u칠 le dijo un corredor al otro? 춰No te detengas hasta la l칤nea de final!',\n",
       " '쮺칩mo se relaja un inform치tico? 춰Con una taza de hacking!',\n",
       " '쯈u칠 hace un personaje de FIFA cuando quiere bailar? 춰Practica su Celebration!',\n",
       " 'Mam치, en el cole me llaman robot. 쯏 c칩mo es eso, hijo? Porque siempre sigo 칩rdenes en modo autom치tico.',\n",
       " '쯇or qu칠 los fantasmas del futuro no asustan? 춰Porque ya no tienen bater칤a!',\n",
       " '쯈u칠 le dice una pizza a otra pizza en A침o Nuevo? 춰Feliz a침o y que nos partan la salsa!',\n",
       " '쯈u칠 hace un esquiador cuando quiere contar un chiste? Un descenso r치pido.',\n",
       " '쮺u치l es el animal m치s r치pido en el atletismo? El chita. 춰Sin duda!',\n",
       " '- 쯈u칠 hace un sombrero en una clase de historia? - Remonta el tiempo.',\n",
       " '쯈u칠 hace una hiena en la escuela? 춰R칤e en todos los chistes de la clase!',\n",
       " '- 춰Ni침os, no jugu칠is con fuego!\\n...y Fuego se quedo sin amigos',\n",
       " 'C칩mo puedes meter 1000 jud칤os en un vocho??? En el cenicero',\n",
       " '쯇or qu칠 el rey Arturo no va de vacaciones? 춰Porque tiene una mesa redonda todo el a침o!',\n",
       " 'Un antrop칩logo est치 realizando unos estudios en una tribu africana, y es llamado por el jefe de la tribu que le dice muy enfadado:\\n- Venir aqu칤 antrop칩logo. Haber nacido ni침o blanco en tribu.\\nEl antrop칩logo intenta quitarse el muerto de encima y le responde, se침alando a un reba침o de ovejas:\\n- Mire jefe, en gen칠tica todo es posible. Mire ese reba침o de ovejas blancas, ver치 usted que entre ellas ha nacido una oveja negra.\\nEl jefe, sofocado, le contesta:\\n- Antrop칩logo, yo no decir nada de ni침o blanco. T칰 no decir nada de oveja negra...',\n",
       " 'Un perro con una sonrisa picara y una expresion de \"burlona\" con el texto que dice: \"si me vas a clavar algo que no sea el visto\", rodeado de corazones naranjas.',\n",
       " 'Cual es el animal m치s r치pido del planeta?  el elefante por qu칠 va en vocho',\n",
       " '쯇or qu칠 las hadas no usan paraguas? 춰Porque siempre est치n bajo techo encantado!',\n",
       " '댹쮺칩mo te reconocer칠? Si quieres le digo a mam치 que me vaya a recoger ella al colegio, pap치. S칤, mejor.',\n",
       " 'Cuando me hace falta una decima para pasar la materia y no s칠 si el sistema aproxima: orando.',\n",
       " 'Una captura de pantalla de un titular en ingles que habla sobre una \"piscina de la muerte\" en el fondo del mar. La imagen incluye una burla con una referencia al Hombre Arania.',\n",
       " ' 쯇or qu칠 la ensalada siempre est치 fresca?\\n Porque siempre se viste bien.\\n',\n",
       " 'Yo creyendo que tengo mi semestre bajo control. Mi semestre: una foto de un hombre cogiendo una botella por su tapa y la botella cayendo y solo se le queda la tapa en la mano.',\n",
       " 'En una representaci칩n teatral un hijo le pregunta a su padre:\\n- 쯇or qu칠 le hechas tierra al pirata en los ojos?\\n- Porque el pirata ha gritado: tierra a la vista!',\n",
       " 'Paises donde celebran que eliminaron a brasil porque hace 10 a침os era gol de yepes: Colombia',\n",
       " 'Un borracho ve a un grupo de \"bautistas\" dentro de un r칤o practicando el rito del Bautismo. \\nS칤n p칠nsarselo dos veces, el borrachito entra dando traspi칠s dentro del agua, se acerca al predicador y se queda a su lado. \\nEntonces el predicador se gira, ve al viejo borracho y le pregunta: \\n-Se침or, 쯘st치 usted preparado para encontrar a Jes칰s? \\nEl borrachito se da la vuelta y dice: \\n-Si, lo estoy. \\nEl predicador entonces sumerge al tipo dentro del agua, lo vuelve a sacar y le pregunta: \\n-쮿a encontrado a Jes칰s? \\n-No -responde el borracho. \\nEl predicador lo vuelve a sumergir un poco m치s de tiempo y cuando lo saca le pregunta: \\n-Y, ahora, hermano, 쯛as encontrado a Jes칰s?. \\n-No  vuelve a responder el borracho. \\nEnfadado, el pastor lo agarra, sumerge la cabeza dentro del agua durante casi un minuto y enojado le pregunta otra vez: \\n-Por la gracia de Dios!!! 쯛as encontrado a Jes칰s ya? \\nEl viejo borracho se seca los ojos y medio ahogado le implora: \\n-No, carajo!!!...pero....est치 seguro que se cay칩 por aqu칤?',\n",
       " '*Ni침os, comeros el bocadillo de tortilla* Y Tortilla se qued칩 sin bocadillo.',\n",
       " 'listo para el 3er parcial. Yo: quiero ir a casa.',\n",
       " 'en el restaurante:\\n-쯨ino de la casa,se침or? \\n-쯫 a ti que te importa de donde vengo?',\n",
       " ' 쮺u치l es el colmo de un meteor칩logo?\\n No tener tiempo.\\n',\n",
       " '쯇or qu칠 los faraones siempre estaban radiantes? 춰Porque eran iluminaciones hist칩ricas!',\n",
       " 'Una imagen de un gatito con los ojos llorosos y un texto que pregunta: \"Komo se desaktiba el modo triste\". Representa un estado emocional triste pero de una manera dulce y exagerada.',\n",
       " ' En qu칠 se parecen una \"boda\" y un \"divorcio\"?\\n\\n - En que en la boda todo es arroz\\n y en el divorcio todo es \"paella\" .\\n',\n",
       " ' 쮺칩mo sacas a Superman del agua?\\n Pues oxidado porque es el hombre de acero.\\n',\n",
       " 'Las mujeres que buscan a un hombre detallista, sensible, atento, delicado... deben saber que ese tipo de hombre TAMBI칄N busca hombres.',\n",
       " 'Esto son 2 Leperos en un tren, y uno saca un cigarro y se pone a fumar,en esto que el amigo le pregunta:\\n-쯊ienes mas?\\nDespues de 20 minutos de pensar,el otro lepero dice:\\n-No,TENGO MENOS',\n",
       " 'Sabes con que perdi칩 un beb칠 boxeador? Con qu칠 So Bas est치',\n",
       " ' - Mar칤a, dime la verdad, cuantos a침os tienes?\\n\\n - 25.\\n - Pero si me dijiste 25 el a침o pasado!\\n- A ver si te piensas que soy de esas que primero dice una cosa y despu칠s otra.\\n',\n",
       " 'ㄷlto, control de drogas  Gracias agente, no me f칤o ni un pelo de mi camello.',\n",
       " '-Papa, por qu칠 envuelves al hamster en cinta aislante?? -Para que cuando le meta la polla no estalle hijo.',\n",
       " 'Cuando estoy hablando con un colombiana y me empieza a insultar (triple mil hijueputa . Treinta .). Yo llevando una calculadora en mi mano',\n",
       " '쮺omo se dice en aleman autobus? ...subenpagenestrugenbagen',\n",
       " '쯈ui칠n invento las fracciones? \\n- Enrique octavo',\n",
       " 'Esta el esposo despidi칠ndose de su esposa para irse a trabajar. Le dice a su esposa:\\n- Mi amor te alistas en la noche porque te voy a dar asta por las orejas. \\nY ella asustada contesta. \\n- Ayy mi amor por ah칤 no porque me quedo sorda\\nY el responde.\\n- Mmmmm no te has quedado muda',\n",
       " '댹쯄e podr칤a poner las sobras para el perro, por favor?  춰Bieeeen, Pap치 va a comprar un peeerrrooo!',\n",
       " ' 쯈u칠 le dice un sem치foro a otro?\\n No me mires, me estoy cambiando.\\n',\n",
       " '  쯋sted domina el ingl칠s?\\n\\n  Hombre, si es bajito y se deja\\n',\n",
       " ' 쯈u칠 dice una cereza mir치ndose al espejo?\\n 쮺er칠 eza?.\\n',\n",
       " '- Cual es el animal que a la vez son dos animales?\\n- El gato, porque es gato y ara침a.\\n- No, tu hermana, porque es zorra y cobra.',\n",
       " 'En la calle:\\n- Usted es un gilipollas, un idiota y un imb칠cil!\\n- 춰Oiga, oiga!, 쯘so son bromas o insultos?\\n- 춰Insultos!\\n- Ah, bueno, es que no aguanto las bromas de nadie.',\n",
       " '- Oye, 쯇ero a ti no te cae mal tu suegra?\\n- Si.\\n-Y entonces, 쯇or qu칠 llevas su foto en la pitillera?\\n- Es que estoy intentando dejar de fumar.',\n",
       " 'No hay vuelta que darle dijo el que dormia en un muro',\n",
       " 'La que me gusta se ha quitado la foto de perfil y no le llegan los mensajes, creo que le gusto',\n",
       " 'Que haces cuando ves un negro desangrarse en la calle? Dejar de re칤r y pegarle otro tiro.',\n",
       " 'El profesor de la materia de relleno: De ma침ana un informe de lecturs del pdf que mand칠 - El profesor que tiene la materia del nombre de la carrera: qu칠 secci칩n es esta?',\n",
       " 'Imagen de Bob Esponja vestido como un ganster, con un sombrero verde, traje a rayas y sosteniendo un abanico de billetes, luciendo relojes y joyas.',\n",
       " 'Lleg칩 un pastor alem치n... ... y nadie entendi칩 la misa.',\n",
       " 'Yo: Hab칤a una vez un osito que fue a la plaza, se subi칩 a la hamaca y se cay칩. Les dio gracia? Ustedes: No Yo: Al osito tampoco',\n",
       " 'Un hombre mirando con incredulidad al texto que describe la traicion de un companiero de videojuego que desmantela un clan al ser ascendido a co-lider.',\n",
       " 'Un asiento de auto lleno de objetos variados: un telefono, un bote de te helado \"Twisted Tea\", un frasco de vitamina C, un desinfectante de manos, un arma de fuego con peluca rubia encima, un vibrador p\\x9crpura y otros objetos. El mensaje transmite humor sobre estar preparado para cualquier eventualidad de manera absurda.',\n",
       " ' 쮺칩mo llamas a un ni침o sin amigos?\\n Uno solo.\\n',\n",
       " 'El machismo es gay, es decir tratas mejor a un hombre que a una mujer, te lo quieres coger o que?',\n",
       " 'Cual es la diferencia entre Vinicius y un gorila? Que el gorila no se ilusiona tan f치cil',\n",
       " 'Un meme donde un personaje animado con una expresion seria observa a alguien que prefiere jugar baloncesto en lugar de un juego tradicional llamado \"Indian booty bumping\".',\n",
       " 'Un perro mordiendo un zapato que cubre su hocico, dandole la apariencia de un ornitorrinco.',\n",
       " ' 쮺u치l es el plan de pensiones de un asesino en serie?\\n Matricularse en un curso de gerontolog칤a.\\n',\n",
       " ' 쯈u칠 tiene en com칰n un beb칠 y una sand칤a?\\n Que los dos son blancos por dentro.\\n',\n",
       " '쮺omo se dice suegra en Ruso? STORBA',\n",
       " ' 쮺u치l es la diferencia entre un mexicano y un ninja?\\n El ninja puede saltar muros sin lastimarse.\\n',\n",
       " 'Un cachorro disfrazado de bruja con texto: \"Dulce o yo?\" y alguien respondiendo: \"JAJAJAJA DULCES\".',\n",
       " ' 쯇or qu칠 el CEO de Enron se suicid칩?\\n Porque no quer칤a pagar la luz.\\n',\n",
       " \"Una escena de entrevista de trabajo, utilizando una pintura renacentista donde alguien responde 뇔've always been passionate about not starving to death칍, resaltando la respuesta ironica sobre las necesidades basicas.\",\n",
       " 'Un perro Shiba Inu visto desde abajo, con una expresion seria y el texto \"Hey, you left me on read haha...\", expresando frustracion comica.',\n",
       " ' 쮺u치l es la diferencia entre un gay y un sacerdote?\\n Que el sacerdote no se come a los ni침os.\\n',\n",
       " ' 쯉abes por qu칠 los ni침os con c치ncer no pueden jugar en los parques?\\n Porque los perros se los comen.\\n',\n",
       " 'Cuando tengo problemas: Mi problema con los exclusivos Cuando no tengo problemas: Por qu칠 Mario funciona y las otras mascota no?',\n",
       " ' 쯇or qu칠 las feministas no pueden ir a la playa?\\n Porque siempre quieren hacer olas.\\n',\n",
       " ' 쮺u치l es el plan de pensiones de un mexicano?\\n Morir joven.\\n',\n",
       " ' 쯈u칠 es lo que m치s le gusta a una mujer golpeada?\\n Nada, porque ya es sorda.\\n',\n",
       " ' 쮺u치l es el objeto favorito de un can칤bal?\\n El tenedor.\\n',\n",
       " ' 쯈u칠 es lo peor de tener sexo con una adolescente?\\n Tener que limpiarle la silla de ruedas despu칠s.\\n',\n",
       " ' 쯇or qu칠 los ni침os con c치ncer nunca juegan a las escondidas?\\n Porque a nadie le gusta buscarlos.\\n',\n",
       " ' 쯈u칠 es lo m치s divertido de tener un beb칠 con s칤ndrome de Down?\\n Que nunca vas a tener que preocuparte por que te lo roben.\\n',\n",
       " 'Insultos que tendr치n m치s peso en generaciones futuras: Tu pap치 ten칤a una pagina de memes',\n",
       " ' 쮺u치l es la diferencia entre una prostituta y un objeto sexual?\\n Uno es un objeto que se puede comprar y vender, y el otro es un objeto sexual.\\n',\n",
       " 'No importa el tama침o del p치jaro sino que tan duro le des a la cerda.-Angry birds',\n",
       " ' 쮺u치l es el regalo perfecto para un amigo que est치 pasando por un duelo?\\n Un paquete de pa침uelos y una tarjeta que dice \"Lo siento, pero no tanto\".\\n',\n",
       " 'Una ilustracion fantasiosa de un herrero musculoso que parece estar afilando una espada mientras un mono esta sentado con un aire de resignacion, aniadiendo un toque absurdo.',\n",
       " ' 쮺칩mo se llama un ni침o jud칤o con c치ncer?\\n Ceniza.\\n',\n",
       " ' 쯇or qu칠 las mujeres no pueden hacer chistes de humor negro?\\n Porque no saben lo que es gracioso hasta que se lo explican tres veces.\\n',\n",
       " ' 쯈u칠 hace una abuela en una monta침a rusa?\\n Recolectar las dentaduras postizas que se les caen a los dem치s pasajeros.\\n']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model trained with 1000 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from models.finetuning import MultifactorialFineTuning\n",
    "\n",
    "# Initialize the class (you'll need to specify num_labels)\n",
    "model_1k_gpt = MultifactorialFineTuning(num_labels=6)  # Since it's a multifactorial model with 6 classes\n",
    "\n",
    "# Load the saved model\n",
    "model_path = \"models/multifactorial/complete_dataset_chistes_finetuning_multifactorial_model_1000_300\"\n",
    "model_1k_gpt.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      1.00      0.29        20\n",
      "           1       0.00      0.00      0.00        20\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.00      0.00      0.00        20\n",
      "           4       0.00      0.00      0.00        20\n",
      "           5       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.17       120\n",
      "   macro avg       0.03      0.17      0.05       120\n",
      "weighted avg       0.03      0.17      0.05       120\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = [np.argmax(model_1k_gpt.predict(text)) for text in texts]\n",
    "\n",
    "conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "# Display results\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Optionally, print a classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results on evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Results for finetuning_bert (multifactorial):\n",
      "--------------------------------------------------\n",
      "eval_loss: 1.3677188158035278\n",
      "eval_accuracy: 0.48161764705882354\n",
      "eval_f1_score: 0.3131112246387389\n",
      "eval_f1_score_micro: 0.48161764705882354\n",
      "eval_recall: 0.48161764705882354\n",
      "eval_predictions_sample: 0,0,0,0,0\n",
      "eval_true_labels_sample: 0,0,3,3,0\n",
      "eval_pred_mean: 0.0\n",
      "eval_pred_std: 0.0\n",
      "eval_runtime: 3.281\n",
      "eval_samples_per_second: 414.504\n",
      "eval_steps_per_second: 51.813\n",
      "epoch: 4.12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\multifactorial\\evaluation\\finetuning_bert_complete_dataset_chistes_1000_validation_results.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results on test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Results for finetuning_bert (multifactorial):\n",
      "--------------------------------------------------\n",
      "eval_loss: 1.3475522994995117\n",
      "eval_accuracy: 0.49073120494335737\n",
      "eval_f1_score: 0.32308589866046256\n",
      "eval_f1_score_micro: 0.49073120494335737\n",
      "eval_recall: 0.49073120494335737\n",
      "eval_predictions_sample: 0,0,0,0,0\n",
      "eval_true_labels_sample: 2,0,1,0,3\n",
      "eval_pred_mean: 0.0\n",
      "eval_pred_std: 0.0\n",
      "eval_runtime: 14.0747\n",
      "eval_samples_per_second: 413.934\n",
      "eval_steps_per_second: 51.795\n",
      "epoch: 4.12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\multifactorial\\testing\\finetuning_bert_multifactorial_complete_dataset_chistes_1000_test_evaluation.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model trained with 5000 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from models.finetuning import MultifactorialFineTuning\n",
    "\n",
    "# Initialize the class (you'll need to specify num_labels)\n",
    "model_5k_gpt = MultifactorialFineTuning(num_labels=6)  # Since it's a multifactorial model with 6 classes\n",
    "\n",
    "# Load the saved model\n",
    "model_path = \"models/multifactorial/complete_dataset_chistes_finetuning_multifactorial_model_5000_300\"\n",
    "model_5k_gpt.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      1.00      0.29        20\n",
      "           1       0.00      0.00      0.00        20\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.00      0.00      0.00        20\n",
      "           4       0.00      0.00      0.00        20\n",
      "           5       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.17       120\n",
      "   macro avg       0.03      0.17      0.05       120\n",
      "weighted avg       0.03      0.17      0.05       120\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = [np.argmax(model_5k_gpt.predict(text)) for text in texts]\n",
    "\n",
    "conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "# Display results\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Optionally, print a classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results on evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Results for finetuning_bert (multifactorial):\n",
      "--------------------------------------------------\n",
      "eval_loss: 1.3914062976837158\n",
      "eval_accuracy: 0.48161764705882354\n",
      "eval_f1_score: 0.3131112246387389\n",
      "eval_f1_score_micro: 0.48161764705882354\n",
      "eval_recall: 0.48161764705882354\n",
      "eval_predictions_sample: 0,0,0,0,0\n",
      "eval_true_labels_sample: 0,0,3,3,0\n",
      "eval_pred_mean: 0.0\n",
      "eval_pred_std: 0.0\n",
      "eval_runtime: 3.2542\n",
      "eval_samples_per_second: 417.925\n",
      "eval_steps_per_second: 52.241\n",
      "epoch: 1.032\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\multifactorial\\evaluation\\finetuning_bert_complete_dataset_chistes_5000_validation_results.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results on testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Results for finetuning_bert (multifactorial):\n",
      "--------------------------------------------------\n",
      "eval_loss: 1.369434118270874\n",
      "eval_accuracy: 0.49073120494335737\n",
      "eval_f1_score: 0.32308589866046256\n",
      "eval_f1_score_micro: 0.49073120494335737\n",
      "eval_recall: 0.49073120494335737\n",
      "eval_predictions_sample: 0,0,0,0,0\n",
      "eval_true_labels_sample: 2,0,1,0,3\n",
      "eval_pred_mean: 0.0\n",
      "eval_pred_std: 0.0\n",
      "eval_runtime: 13.874\n",
      "eval_samples_per_second: 419.922\n",
      "eval_steps_per_second: 52.544\n",
      "epoch: 1.032\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Path to the file\n",
    "file_path = r\"models\\multifactorial\\testing\\finetuning_bert_multifactorial_complete_dataset_chistes_5000_test_evaluation.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model trained with the whole train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from models.finetuning import MultifactorialFineTuning\n",
    "\n",
    "# Initialize the class (you'll need to specify num_labels)\n",
    "model_12k_gpt_finetuning_multifactorial = MultifactorialFineTuning(num_labels=6)  # Since it's a multifactorial model with 6 classes\n",
    "\n",
    "# Load the saved model\n",
    "model_path = \"models/multifactorial/complete_dataset_chistes_finetuning_multifactorial_model_12231_300\"\n",
    "model_12k_gpt_finetuning_multifactorial.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      1.00      0.29        20\n",
      "           1       0.00      0.00      0.00        20\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.00      0.00      0.00        20\n",
      "           4       0.00      0.00      0.00        20\n",
      "           5       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.17       120\n",
      "   macro avg       0.03      0.17      0.05       120\n",
      "weighted avg       0.03      0.17      0.05       120\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = [np.argmax(model_12k_gpt_finetuning_multifactorial.predict(text)) for text in texts]\n",
    "\n",
    "conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "# Display results\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Optionally, print a classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results on evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Results for finetuning_bert (multifactorial):\n",
      "--------------------------------------------------\n",
      "eval_loss: 0.8678938746452332\n",
      "eval_accuracy: 0.5911764705882353\n",
      "eval_f1_score: 0.512193443974577\n",
      "eval_f1_score_micro: 0.5911764705882353\n",
      "eval_recall: 0.5911764705882353\n",
      "eval_predictions_sample: 0,0,3,3,0\n",
      "eval_true_labels_sample: 0,0,3,3,0\n",
      "eval_pred_mean: 1.5198529411764705\n",
      "eval_pred_std: 1.4998686144881637\n",
      "eval_runtime: 3.2495\n",
      "eval_samples_per_second: 418.53\n",
      "eval_steps_per_second: 52.316\n",
      "epoch: 0.3368214519293656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\multifactorial\\evaluation\\finetuning_bert_complete_dataset_chistes_12231_validation_results.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Results for finetuning_bert (multifactorial):\n",
      "--------------------------------------------------\n",
      "eval_loss: 0.8716588020324707\n",
      "eval_accuracy: 0.6071060762100927\n",
      "eval_f1_score: 0.5261256894074561\n",
      "eval_f1_score_micro: 0.6071060762100927\n",
      "eval_recall: 0.6071060762100927\n",
      "eval_predictions_sample: 3,0,3,0,3\n",
      "eval_true_labels_sample: 2,0,1,0,3\n",
      "eval_pred_mean: 1.4871266735324409\n",
      "eval_pred_std: 1.4999447581379988\n",
      "eval_runtime: 13.9483\n",
      "eval_samples_per_second: 417.686\n",
      "eval_steps_per_second: 52.264\n",
      "epoch: 0.3368214519293656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\multifactorial\\testing\\finetuning_bert_multifactorial_complete_dataset_chistes_12231_test_evaluation.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning captioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from models.finetuning import MultifactorialFineTuning\n",
    "\n",
    "# Initialize the class (you'll need to specify num_labels)\n",
    "model_12k_VIT_finetuning_multifactorial = MultifactorialFineTuning(num_labels=6)  # Since it's a multifactorial model with 6 classes\n",
    "\n",
    "# Load the saved model\n",
    "model_path = \"models/multifactorial/captionning_vlt_finetuning_multifactorial_model_12225_300\"\n",
    "model_12k_VIT_finetuning_multifactorial.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]\n",
      " [20  0  0  0  0  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      1.00      0.29        20\n",
      "           1       0.00      0.00      0.00        20\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.00      0.00      0.00        20\n",
      "           4       0.00      0.00      0.00        20\n",
      "           5       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.17       120\n",
      "   macro avg       0.03      0.17      0.05       120\n",
      "weighted avg       0.03      0.17      0.05       120\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "predictions = [np.argmax(model_12k_VIT_finetuning_multifactorial.predict(text)) for text in texts]\n",
    "\n",
    "conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "# Display results\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Optionally, print a classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results on evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Results for finetuning_bert (multifactorial):\n",
      "--------------------------------------------------\n",
      "eval_loss: 1.3453768491744995\n",
      "eval_accuracy: 0.5047829286239882\n",
      "eval_f1_score: 0.33866121177120384\n",
      "eval_f1_score_micro: 0.5047829286239882\n",
      "eval_recall: 0.5047829286239882\n",
      "eval_predictions_sample: 0,0,0,0,0\n",
      "eval_true_labels_sample: 2,2,0,0,2\n",
      "eval_pred_mean: 0.0\n",
      "eval_pred_std: 0.0\n",
      "eval_runtime: 3.5247\n",
      "eval_samples_per_second: 385.561\n",
      "eval_steps_per_second: 48.231\n",
      "epoch: 0.3368214519293656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\multifactorial\\evaluation\\finetuning_bert_captionning_vlt_12225_validation_results.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Results for finetuning_bert (multifactorial):\n",
      "--------------------------------------------------\n",
      "eval_loss: 1.366455316543579\n",
      "eval_accuracy: 0.4854002061147372\n",
      "eval_f1_score: 0.31723889511569087\n",
      "eval_f1_score_micro: 0.4854002061147372\n",
      "eval_recall: 0.4854002061147372\n",
      "eval_predictions_sample: 0,0,0,0,0\n",
      "eval_true_labels_sample: 0,2,1,0,3\n",
      "eval_pred_mean: 0.0\n",
      "eval_pred_std: 0.0\n",
      "eval_runtime: 15.037\n",
      "eval_samples_per_second: 387.178\n",
      "eval_steps_per_second: 48.414\n",
      "epoch: 0.3368214519293656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\multifactorial\\testing\\finetuning_bert_multifactorial_captionning_vlt_12225_test_evaluation.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_lstm_multifactorial(classifier, text):\n",
    "    \"\"\"\n",
    "    Get predictions for multifactorial classification\n",
    "    \n",
    "    Args:\n",
    "        classifier: The trained classifier model\n",
    "        text: Input text to classify\n",
    "        \n",
    "    Returns:\n",
    "        int: Predicted class (0-5)\n",
    "    \"\"\"\n",
    "    # Initialize tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-large-cased')\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=64,\n",
    "        return_tensors='np'\n",
    "    )\n",
    "    \n",
    "    # Create properly formatted input\n",
    "    single_item = [{\n",
    "        'input_ids': tokens['input_ids'][0],\n",
    "        'attention_mask': tokens['attention_mask'][0],\n",
    "        'token_type_ids': tokens['token_type_ids'][0],\n",
    "        # For multifactorial, we use nivel_risa_encoded instead of labels\n",
    "        'nivel_risa_encoded': 0  # dummy label, will be ignored for prediction\n",
    "    }]\n",
    "    \n",
    "    # Get inputs only, ignore the encoded labels\n",
    "    input_ids = np.array([item['input_ids'] for item in single_item])\n",
    "    attention_mask = np.array([item['attention_mask'] for item in single_item])\n",
    "    token_type_ids = np.array([item['token_type_ids'] for item in single_item])\n",
    "    \n",
    "    # Make prediction\n",
    "    probs = classifier.predict(input_ids, attention_mask, token_type_ids)\n",
    "    \n",
    "    # Return class with highest probability\n",
    "    return np.argmax(probs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dataset(dataset, num_samples=20):\n",
    "    \"\"\"\n",
    "    Sample equal number of instances from each class, handling empty classes\n",
    "    \n",
    "    Args:\n",
    "        dataset: Input dataset\n",
    "        num_samples: Number of samples per class (default=20)\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Sampled dataset with equal class distribution\n",
    "    \"\"\"\n",
    "    # Convert Dataset to DataFrame if necessary\n",
    "    if not isinstance(dataset, pd.DataFrame):\n",
    "        df = pd.DataFrame(dataset)\n",
    "    else:\n",
    "        df = dataset\n",
    "    \n",
    "    # First check which classes are present\n",
    "    present_classes = df['nivel_risa'].unique()\n",
    "    print(f\"Classes present in dataset: {sorted(present_classes)}\")\n",
    "    print(f\"Class distribution:\\n{df['nivel_risa'].value_counts().sort_index()}\")\n",
    "    \n",
    "    # Sample from each present class\n",
    "    sampled_dfs = []\n",
    "    for class_label in present_classes:\n",
    "        class_data = df[df['nivel_risa'] == class_label]\n",
    "        n_available = len(class_data)\n",
    "        \n",
    "        if n_available == 0:\n",
    "            print(f\"Warning: No samples found for class {class_label}\")\n",
    "            continue\n",
    "            \n",
    "        if n_available >= num_samples:\n",
    "            sampled_class = class_data.sample(n=num_samples, random_state=42)\n",
    "        else:\n",
    "            print(f\"Warning: Only {n_available} samples available for class {class_label}, sampling with replacement\")\n",
    "            sampled_class = class_data.sample(n=num_samples, replace=True, random_state=42)\n",
    "        \n",
    "        sampled_dfs.append(sampled_class)\n",
    "    \n",
    "    if not sampled_dfs:\n",
    "        raise ValueError(\"No valid samples found in any class\")\n",
    "    \n",
    "    # Combine all sampled data\n",
    "    sampled_df = pd.concat(sampled_dfs, ignore_index=True)\n",
    "    print(f\"\\nFinal sampled distribution:\\n{sampled_df['nivel_risa'].value_counts().sort_index()}\")\n",
    "    \n",
    "    return sampled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(classifier, sampled_data):\n",
    "    \"\"\"\n",
    "    Evaluate classifier performance on sampled data\n",
    "    \n",
    "    Args:\n",
    "        classifier: Trained classifier model\n",
    "        sampled_data: DataFrame with sampled data\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (confusion_matrix, classification_report, sample_predictions)\n",
    "    \"\"\"\n",
    "    texts = sampled_data['text'].tolist()\n",
    "    true_labels = sampled_data['nivel_risa'].tolist()\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = []\n",
    "    for i, text in enumerate(texts):\n",
    "        try:\n",
    "            pred = get_prediction_lstm_multifactorial(classifier, text)\n",
    "            predictions.append(pred)\n",
    "            if i < 5:  # Print first few predictions for debugging\n",
    "                print(f\"\\nPrediction {i+1}:\")\n",
    "                print(f\"Text: {text[:100]}...\")\n",
    "                print(f\"True label: {true_labels[i]}\")\n",
    "                print(f\"Predicted: {pred}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error predicting text: {text[:100]}...\")\n",
    "            print(f\"Error details: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if not predictions:\n",
    "        raise ValueError(\"No valid predictions were made\")\n",
    "    \n",
    "    # Calculate metrics\n",
    "    conf_matrix = confusion_matrix(true_labels[:len(predictions)], predictions)\n",
    "    class_report = classification_report(true_labels[:len(predictions)], predictions)\n",
    "    \n",
    "    # Get sample predictions for display\n",
    "    sample_preds = []\n",
    "    for i in range(min(5, len(predictions))):\n",
    "        sample_preds.append({\n",
    "            'text': texts[i][:100],\n",
    "            'true_label': true_labels[i],\n",
    "            'predicted': predictions[i]\n",
    "        })\n",
    "    \n",
    "    return conf_matrix, class_report, sample_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BaseClassifier:\n",
    "    def __init__(self, bert_path='bert-large-cased', max_length=64, multifactorial= False):\n",
    "        \"\"\"\n",
    "        Base class for BERT-based classification models.\n",
    "        \n",
    "        Provides common functionality for model initialization, data encoding,\n",
    "        training, prediction, and evaluation. Serves as parent class for specific\n",
    "        classifier implementations.\n",
    "        \n",
    "        Attributes:\n",
    "            bert_path (str): Path to pre-trained BERT model\n",
    "            max_length (int): Maximum sequence length for input texts\n",
    "            model: The Keras model instance\n",
    "            multifactorial (bool): Whether model handles multiple classes\n",
    "        \"\"\"\n",
    "        self.bert_path = bert_path\n",
    "        self.max_length = max_length\n",
    "        self.model = None\n",
    "        self.multifactorial = multifactorial\n",
    "        \n",
    "    class BertLayer(keras.layers.Layer):\n",
    "        \"\"\"\n",
    "        Custom Keras layer wrapping BERT model.\n",
    "        \n",
    "        Creates a non-trainable BERT layer that outputs the last hidden states\n",
    "        of the model for use in downstream tasks.\n",
    "        \n",
    "        Args:\n",
    "            bert_path (str): Path to pre-trained BERT model\n",
    "            **kwargs: Additional arguments passed to parent Layer class\n",
    "        \"\"\"\n",
    "        def __init__(self, bert_path='bert-large-cased', **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "            # Specify output_hidden_states=True to get all hidden states\n",
    "            self.bert = TFBertModel.from_pretrained(bert_path, output_hidden_states=True)\n",
    "            self.bert.trainable = False\n",
    "            \n",
    "        def call(self, inputs):\n",
    "            input_ids, attention_mask, token_type_ids = inputs\n",
    "            outputs = self.bert(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids,                \n",
    "            )\n",
    "            # Use the last hidden state instead of pooler output\n",
    "            return outputs.last_hidden_state\n",
    "    \n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        Abstract method to define model architecture.\n",
    "        \n",
    "        Must be implemented by subclasses to create their specific model architectures.\n",
    "        \n",
    "        Raises:\n",
    "            NotImplementedError: If subclass doesn't implement this method\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"Subclasses must implement build_model\")\n",
    "    \n",
    "    def encode_data(self, dataset):\n",
    "        \"\"\"\n",
    "        Encode input data for model processing.\n",
    "        \n",
    "        Args:\n",
    "            dataset: Dataset containing input_ids, attention_mask, token_type_ids, and labels\n",
    "            \n",
    "        Returns:\n",
    "            tuple: For binary classification:\n",
    "                - input_ids (np.array)\n",
    "                - attention_mask (np.array)\n",
    "                - token_type_ids (np.array)\n",
    "                - labels (np.array)\n",
    "            For multifactorial:\n",
    "                - Same as above but labels are one-hot encoded for 6 categories\n",
    "        \"\"\"\n",
    "        if self.multifactorial:\n",
    "            input_ids = np.array([item[\"input_ids\"] for item in dataset])\n",
    "            attention_mask = np.array([item[\"attention_mask\"] for item in dataset])\n",
    "            token_type_ids = np.array([item[\"token_type_ids\"] for item in dataset])\n",
    "            # Get labels and convert to one-hot encoding\n",
    "            labels = np.array([item[\"nivel_risa_encoded\"] for item in dataset])\n",
    "            # Convert to one-hot encoding for 6 categories (0-5)\n",
    "            one_hot_labels = np.eye(6)[labels]\n",
    "            return input_ids, attention_mask, token_type_ids, one_hot_labels\n",
    "        \n",
    "        else:\n",
    "            input_ids = np.array([item[\"input_ids\"] for item in dataset])\n",
    "            attention_mask = np.array([item[\"attention_mask\"] for item in dataset])\n",
    "            token_type_ids = np.array([item[\"token_type_ids\"] for item in dataset])\n",
    "            labels = np.array([item[\"labels\"] for item in dataset])\n",
    "            return input_ids, attention_mask, token_type_ids, labels\n",
    "    \n",
    "    def train(self, train_dataset, validation_dataset, epochs=10, batch_size=16, patience=3):\n",
    "        \"\"\"\n",
    "        Train the model on provided datasets.\n",
    "        \n",
    "        Args:\n",
    "            train_dataset: Training data\n",
    "            validation_dataset: Validation data\n",
    "            epochs (int): Number of training epochs\n",
    "            batch_size (int): Batch size for training\n",
    "            patience (int): Early stopping patience\n",
    "            \n",
    "        Returns:\n",
    "            keras.callbacks.History: Training history\n",
    "        \"\"\"\n",
    "        train_inputs = self.encode_data(train_dataset)\n",
    "        val_inputs = self.encode_data(validation_dataset)\n",
    "        early_stopping = keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', patience=patience, restore_best_weights=True, mode='min'\n",
    "        )\n",
    "        history = self.model.fit(\n",
    "            x=[train_inputs[0], train_inputs[1], train_inputs[2]],\n",
    "            y=train_inputs[3],\n",
    "            validation_data=( [val_inputs[0], val_inputs[1], val_inputs[2]], val_inputs[3] ),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=[early_stopping]\n",
    "        )\n",
    "        return history\n",
    "    \n",
    "    def predict(self, input_ids, attention_mask, token_type_ids):\n",
    "        \"\"\"\n",
    "        Make predictions using the trained model.\n",
    "        \n",
    "        Args:\n",
    "            input_ids: BERT input token IDs\n",
    "            attention_mask: BERT attention mask\n",
    "            token_type_ids: BERT token type IDs\n",
    "            \n",
    "        Returns:\n",
    "            np.array: Model predictions\n",
    "        \"\"\"\n",
    "        return self.model.predict([input_ids, attention_mask, token_type_ids])\n",
    "    \n",
    "    def evaluate(self, test_dataset):\n",
    "        \"\"\"\n",
    "        Evaluate model performance on test dataset.\n",
    "        \n",
    "        Args:\n",
    "            test_dataset: Test data to evaluate on\n",
    "            \n",
    "        Returns:\n",
    "            dict: Evaluation metrics (loss and accuracy)\n",
    "        \"\"\"\n",
    "        test_inputs = self.encode_data(test_dataset)\n",
    "        results = self.model.evaluate(\n",
    "            [test_inputs[0], test_inputs[1], test_inputs[2]],\n",
    "            test_inputs[3]\n",
    "        )\n",
    "        return dict(zip(self.model.metrics_names, results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM 1 AND LSTM 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_2_MultiFactorial(BaseClassifier):\n",
    "    \"\"\"\n",
    "    Multi-class classifier combining BERT with single bidirectional LSTM layer.\n",
    "    \n",
    "    Architecture:\n",
    "        1. BERT layer for text encoding\n",
    "        2. Self-attention layer\n",
    "        3. Concatenation of BERT output and attention\n",
    "        4. Single bidirectional LSTM\n",
    "        5. Six unit softmax output for multi-class classification\n",
    "    \"\"\"\n",
    "    \n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        Creates a multi-class classification model combining BERT with single LSTM layer.\n",
    "        \n",
    "        Architecture:\n",
    "            1. Input layers:\n",
    "                - input_ids: Token indices of input sequence (shape: [batch_size, 64])\n",
    "                - attention_mask: Mask for padding (shape: [batch_size, 64])\n",
    "                - token_type_ids: Segment tokens (shape: [batch_size, 64])\n",
    "            \n",
    "            2. BERT Layer:\n",
    "                - Non-trainable BERT-large-cased model\n",
    "                - Outputs last hidden states\n",
    "            \n",
    "            3. Attention mechanism:\n",
    "                - Self-attention on BERT outputs\n",
    "                - Helps focus on relevant parts of input\n",
    "            \n",
    "            4. Feature combination:\n",
    "                - Concatenates BERT outputs with attention outputs\n",
    "                - Enriches representation with attention information\n",
    "            \n",
    "            5. LSTM layer:\n",
    "                - Single Bidirectional LSTM with 256 units\n",
    "                - Returns final sequence state\n",
    "                - Total 512 features (256 * 2 directions)\n",
    "            \n",
    "            6. Output:\n",
    "                - Dense layer with 6 units (one per class)\n",
    "                - Softmax activation for multi-class classification\n",
    "        \n",
    "        Returns:\n",
    "            keras.Model: Compiled model with inputs [input_ids, attention_mask, token_type_ids]\n",
    "                        and multi-class classification output (6 classes)\n",
    "        \"\"\"\n",
    "        input_ids = keras.layers.Input(shape=(64,), dtype='int32', name='input_ids')\n",
    "        attention_mask = keras.layers.Input(shape=(64,), dtype='int32', name='attention_mask')\n",
    "        token_type_ids = keras.layers.Input(shape=(64,), dtype='int32', name='token_type_ids')\n",
    "        \n",
    "        bert_layer = self.BertLayer(self.bert_path)\n",
    "        sequence_output = bert_layer([input_ids, attention_mask, token_type_ids])\n",
    "        \n",
    "        attention = keras.layers.Attention()([sequence_output, sequence_output])\n",
    "        \n",
    "        merge_layer = keras.layers.Concatenate()([sequence_output, attention])\n",
    "        \n",
    "        LSTM1_layer = keras.layers.Bidirectional(\n",
    "            keras.layers.LSTM(units=256)\n",
    "        )(merge_layer)\n",
    "            \n",
    "        output_layer = keras.layers.Dense(units=6, activation='softmax')(LSTM1_layer)\n",
    "        \n",
    "        self.model = keras.Model(\n",
    "            inputs=[input_ids, attention_mask, token_type_ids],\n",
    "            outputs=output_layer\n",
    "        )\n",
    "        return self.model\n",
    "    \n",
    "    \n",
    "class LSTM_1_MultiFactorial(BaseClassifier):\n",
    "    \"\"\"\n",
    "    Multi-class classifier combining BERT with dual bidirectional LSTM layers.\n",
    "    \n",
    "    Architecture:\n",
    "        1. BERT layer for text encoding\n",
    "        2. Self-attention layer\n",
    "        3. Concatenation of BERT output and attention\n",
    "        4. First bidirectional LSTM with sequence return\n",
    "        5. Dropout layer\n",
    "        6. Second bidirectional LSTM\n",
    "        7. Six unit softmax output for multi-class classification\n",
    "    \"\"\"\n",
    "    \n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        Creates a multi-class classification model combining BERT with dual LSTM layers.\n",
    "        \n",
    "        Architecture:\n",
    "            1. Input layers:\n",
    "                - input_ids: Token indices of input sequence (shape: [batch_size, 64])\n",
    "                - attention_mask: Mask for padding (shape: [batch_size, 64])\n",
    "                - token_type_ids: Segment tokens (shape: [batch_size, 64])\n",
    "            \n",
    "            2. BERT Layer:\n",
    "                - Non-trainable BERT-large-cased model\n",
    "                - Outputs last hidden states\n",
    "            \n",
    "            3. Attention mechanism:\n",
    "                - Self-attention on BERT outputs\n",
    "                - Helps focus on relevant parts of input\n",
    "            \n",
    "            4. Feature combination:\n",
    "                - Concatenates BERT outputs with attention outputs\n",
    "                - Enriches representation with attention information\n",
    "            \n",
    "            5. First LSTM layer:\n",
    "                - Bidirectional LSTM with 256 units\n",
    "                - Returns sequences for hierarchical processing\n",
    "                - Total 512 features (256 * 2 directions)\n",
    "            \n",
    "            6. Regularization:\n",
    "                - Dropout layer with 0.3 rate\n",
    "                - Prevents overfitting\n",
    "            \n",
    "            7. Second LSTM layer:\n",
    "                - Bidirectional LSTM with 256 units\n",
    "                - Returns final sequence state\n",
    "                - Total 512 features (256 * 2 directions)\n",
    "            \n",
    "            8. Output:\n",
    "                - Dense layer with 6 units (one per class)\n",
    "                - Softmax activation for multi-class classification\n",
    "        \n",
    "        Returns:\n",
    "            keras.Model: Compiled model with inputs [input_ids, attention_mask, token_type_ids]\n",
    "                        and multi-class classification output (6 classes)\n",
    "        \"\"\"\n",
    "        input_ids = keras.layers.Input(shape=(64,), dtype='int32', name='input_ids')\n",
    "        attention_mask = keras.layers.Input(shape=(64,), dtype='int32', name='attention_mask')\n",
    "        token_type_ids = keras.layers.Input(shape=(64,), dtype='int32', name='token_type_ids')\n",
    "        \n",
    "        bert_layer = self.BertLayer(self.bert_path)\n",
    "        sequence_output = bert_layer([input_ids, attention_mask, token_type_ids])\n",
    "        \n",
    "        attention = keras.layers.Attention()([sequence_output, sequence_output])\n",
    "        \n",
    "        merge_layer = keras.layers.Concatenate()([sequence_output, attention])\n",
    "        \n",
    "        LSTM1_layer = keras.layers.Bidirectional(\n",
    "            keras.layers.LSTM(units=256, return_sequences=True)\n",
    "        )(merge_layer)\n",
    "        \n",
    "        dropout_layer = keras.layers.Dropout(rate=0.3)(LSTM1_layer)\n",
    "        \n",
    "        LSTM2_layer = keras.layers.Bidirectional(\n",
    "            keras.layers.LSTM(units=256)\n",
    "        )(dropout_layer)\n",
    "        \n",
    "        output_layer = keras.layers.Dense(units=6, activation='softmax')(LSTM2_layer)\n",
    "        \n",
    "        self.model = keras.Model(\n",
    "            inputs=[input_ids, attention_mask, token_type_ids],\n",
    "            outputs=output_layer\n",
    "        )\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Initialize classifier\n",
    "\n",
    "from models.encoder_only_lstm import LSTM_2_MultiFactorial, LSTM_1_MultiFactorial\n",
    "\n",
    "classifier_lstm2_multifactorial = LSTM_2_MultiFactorial(bert_path='bert-large-cased', max_length=64)\n",
    "\n",
    "# Get the custom BertLayer class\n",
    "BertLayer = classifier_lstm2_multifactorial.BertLayer\n",
    "\n",
    "# Load the model with custom_object_scope\n",
    "with custom_object_scope({'BertLayer': BertLayer}):\n",
    "    classifier_lstm2_multifactorial.model = load_model('models/multifactorial/lstm2_model.h5')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)      [(None, 64)]                 0         []                            \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer  [(None, 64)]                 0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " token_type_ids (InputLayer  [(None, 64)]                 0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bert_layer_2 (BertLayer)    (None, 64, 1024)             3335792   ['input_ids[0][0]',           \n",
      "                                                          64         'attention_mask[0][0]',      \n",
      "                                                                     'token_type_ids[0][0]']      \n",
      "                                                                                                  \n",
      " attention_2 (Attention)     (None, 64, 1024)             0         ['bert_layer_2[0][0]',        \n",
      "                                                                     'bert_layer_2[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 64, 2048)             0         ['bert_layer_2[0][0]',        \n",
      " )                                                                   'attention_2[0][0]']         \n",
      "                                                                                                  \n",
      " bidirectional_3 (Bidirecti  (None, 512)                  4720640   ['concatenate_2[0][0]']       \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 6)                    3078      ['bidirectional_3[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 338302982 (1.26 GB)\n",
      "Trainable params: 4723718 (18.02 MB)\n",
      "Non-trainable params: 333579264 (1.24 GB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_lstm2_multifactorial.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling dataset...\n",
      "Classes present in dataset: [1, 2, 3, 4, 5]\n",
      "Class distribution:\n",
      "nivel_risa\n",
      "1    1216\n",
      "2    4627\n",
      "3    2897\n",
      "4     988\n",
      "5     205\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final sampled distribution:\n",
      "nivel_risa\n",
      "1    20\n",
      "2    20\n",
      "3    20\n",
      "4    20\n",
      "5    20\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Making predictions...\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "\n",
      "Prediction 1:\n",
      "Text: No hay vuelta que darle dijo el que dormia en un muro...\n",
      "True label: 4\n",
      "Predicted: 2\n",
      "1/1 [==============================] - 1s 503ms/step\n",
      "\n",
      "Prediction 2:\n",
      "Text: La que me gusta se ha quitado la foto de perfil y no le llegan los mensajes, creo que le gusto...\n",
      "True label: 4\n",
      "Predicted: 4\n",
      "1/1 [==============================] - 0s 477ms/step\n",
      "\n",
      "Prediction 3:\n",
      "Text: Que haces cuando ves un negro desangrarse en la calle? Dejar de re칤r y pegarle otro tiro....\n",
      "True label: 4\n",
      "Predicted: 2\n",
      "1/1 [==============================] - 0s 453ms/step\n",
      "\n",
      "Prediction 4:\n",
      "Text: El profesor de la materia de relleno: De ma침ana un informe de lecturs del pdf que mand칠 - El profeso...\n",
      "True label: 4\n",
      "Predicted: 3\n",
      "1/1 [==============================] - 0s 458ms/step\n",
      "\n",
      "Prediction 5:\n",
      "Text: Imagen de Bob Esponja vestido como un ganster, con un sombrero verde, traje a rayas y sosteniendo un...\n",
      "True label: 4\n",
      "Predicted: 2\n",
      "1/1 [==============================] - 0s 440ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 392ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 398ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 466ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 372ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 437ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 381ms/step\n",
      "1/1 [==============================] - 0s 402ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 473ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 430ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 487ms/step\n",
      "1/1 [==============================] - 1s 516ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 0  0  0  0  0  0]\n",
      " [ 0  0 19  1  0  0]\n",
      " [ 0  0 18  2  0  0]\n",
      " [ 0  0 17  3  0  0]\n",
      " [ 0  0 14  3  3  0]\n",
      " [ 1  0 13  4  2  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00        20\n",
      "           2       0.22      0.90      0.36        20\n",
      "           3       0.23      0.15      0.18        20\n",
      "           4       0.60      0.15      0.24        20\n",
      "           5       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.24       100\n",
      "   macro avg       0.18      0.20      0.13       100\n",
      "weighted avg       0.21      0.24      0.16       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Sample dataset\n",
    "    print(\"\\nSampling dataset...\")\n",
    "    sampled_data = sample_dataset(dataset, num_samples=20)\n",
    "    \n",
    "    print(\"\\nMaking predictions...\")\n",
    "    # Evaluate predictions\n",
    "    conf_matrix, class_report, sample_preds = evaluate_predictions(classifier_lstm2_multifactorial, sampled_data)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(class_report)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error during execution: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Results for lstm2 (multifactorial):\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.7294\n",
      "F1 Score: 0.6718\n",
      "Recall: 0.7294\n",
      "\n",
      "Debug Information:\n",
      "Number of validation samples: 1360\n",
      "Unique predicted classes: [0 1 2 3 4]\n",
      "Unique true labels: [0 1 2 3 4 5]\n",
      "\n",
      "Class Distribution:\n",
      "Predicted class counts:\n",
      "Class 0: 663\n",
      "Class 1: 1\n",
      "Class 2: 611\n",
      "Class 3: 78\n",
      "Class 4: 7\n",
      "\n",
      "True class counts:\n",
      "Class 0: 655\n",
      "Class 1: 92\n",
      "Class 2: 334\n",
      "Class 3: 192\n",
      "Class 4: 74\n",
      "Class 5: 13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\multifactorial\\evaluation\\lstm2_validation_results.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Results for lstm2 (multifactorial):\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.7259\n",
      "F1 Score: 0.6722\n",
      "Recall: 0.7259\n",
      "\n",
      "Debug Information:\n",
      "Unique predicted classes: [0 1 2 3 4]\n",
      "Unique true labels: [0 1 2 3 4 5]\n",
      "Number of samples: 5826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\multifactorial\\testing\\lstm2_multifactorial_test_evaluation.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "classifier_lstm1_multifactorial = LSTM_1_MultiFactorial(bert_path='bert-large-cased', max_length=64)\n",
    "\n",
    "# Get the custom BertLayer class\n",
    "BertLayer = classifier_lstm1_multifactorial.BertLayer\n",
    "\n",
    "# Load the model with custom_object_scope\n",
    "with custom_object_scope({'BertLayer': BertLayer}):\n",
    "    classifier_lstm1_multifactorial.model = load_model('models/multifactorial/lstm1_model.h5')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)      [(None, 64)]                 0         []                            \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer  [(None, 64)]                 0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " token_type_ids (InputLayer  [(None, 64)]                 0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bert_layer_1 (BertLayer)    (None, 64, 1024)             3335792   ['input_ids[0][0]',           \n",
      "                                                          64         'attention_mask[0][0]',      \n",
      "                                                                     'token_type_ids[0][0]']      \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, 64, 1024)             0         ['bert_layer_1[0][0]',        \n",
      "                                                                     'bert_layer_1[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 64, 2048)             0         ['bert_layer_1[0][0]',        \n",
      " )                                                                   'attention_1[0][0]']         \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirecti  (None, 64, 512)              4720640   ['concatenate_1[0][0]']       \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " dropout_146 (Dropout)       (None, 64, 512)              0         ['bidirectional_1[0][0]']     \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirecti  (None, 512)                  1574912   ['dropout_146[0][0]']         \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 6)                    3078      ['bidirectional_2[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 339877894 (1.27 GB)\n",
      "Trainable params: 6298630 (24.03 MB)\n",
      "Non-trainable params: 333579264 (1.24 GB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_lstm1_multifactorial.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling dataset...\n",
      "Classes present in dataset: [1, 2, 3, 4, 5]\n",
      "Class distribution:\n",
      "nivel_risa\n",
      "1    1216\n",
      "2    4627\n",
      "3    2897\n",
      "4     988\n",
      "5     205\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final sampled distribution:\n",
      "nivel_risa\n",
      "1    20\n",
      "2    20\n",
      "3    20\n",
      "4    20\n",
      "5    20\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Making predictions...\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "\n",
      "Prediction 1:\n",
      "Text: No hay vuelta que darle dijo el que dormia en un muro...\n",
      "True label: 4\n",
      "Predicted: 2\n",
      "1/1 [==============================] - 0s 457ms/step\n",
      "\n",
      "Prediction 2:\n",
      "Text: La que me gusta se ha quitado la foto de perfil y no le llegan los mensajes, creo que le gusto...\n",
      "True label: 4\n",
      "Predicted: 4\n",
      "1/1 [==============================] - 0s 434ms/step\n",
      "\n",
      "Prediction 3:\n",
      "Text: Que haces cuando ves un negro desangrarse en la calle? Dejar de re칤r y pegarle otro tiro....\n",
      "True label: 4\n",
      "Predicted: 4\n",
      "1/1 [==============================] - 0s 416ms/step\n",
      "\n",
      "Prediction 4:\n",
      "Text: El profesor de la materia de relleno: De ma침ana un informe de lecturs del pdf que mand칠 - El profeso...\n",
      "True label: 4\n",
      "Predicted: 2\n",
      "1/1 [==============================] - 0s 417ms/step\n",
      "\n",
      "Prediction 5:\n",
      "Text: Imagen de Bob Esponja vestido como un ganster, con un sombrero verde, traje a rayas y sosteniendo un...\n",
      "True label: 4\n",
      "Predicted: 1\n",
      "1/1 [==============================] - 0s 424ms/step\n",
      "1/1 [==============================] - 0s 409ms/step\n",
      "1/1 [==============================] - 0s 416ms/step\n",
      "1/1 [==============================] - 0s 434ms/step\n",
      "1/1 [==============================] - 0s 427ms/step\n",
      "1/1 [==============================] - 0s 408ms/step\n",
      "1/1 [==============================] - 0s 413ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "1/1 [==============================] - 0s 428ms/step\n",
      "1/1 [==============================] - 0s 442ms/step\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "1/1 [==============================] - 0s 449ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 426ms/step\n",
      "1/1 [==============================] - 0s 413ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 424ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 392ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 482ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 392ms/step\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "1/1 [==============================] - 0s 435ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 438ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 387ms/step\n",
      "1/1 [==============================] - 0s 394ms/step\n",
      "1/1 [==============================] - 0s 359ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 447ms/step\n",
      "1/1 [==============================] - 0s 379ms/step\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 394ms/step\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "1/1 [==============================] - 0s 468ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 432ms/step\n",
      "1/1 [==============================] - 0s 440ms/step\n",
      "1/1 [==============================] - 0s 416ms/step\n",
      "1/1 [==============================] - 0s 403ms/step\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "1/1 [==============================] - 0s 414ms/step\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "1/1 [==============================] - 0s 379ms/step\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 2 17  1  0  0]\n",
      " [ 0 20  0  0  0]\n",
      " [ 0 18  1  1  0]\n",
      " [ 2 10  1  7  0]\n",
      " [ 1  7  0 12  0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.10      0.16        20\n",
      "           2       0.28      1.00      0.43        20\n",
      "           3       0.33      0.05      0.09        20\n",
      "           4       0.35      0.35      0.35        20\n",
      "           5       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.30       100\n",
      "   macro avg       0.27      0.30      0.21       100\n",
      "weighted avg       0.27      0.30      0.21       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Sample dataset\n",
    "    print(\"\\nSampling dataset...\")\n",
    "    sampled_data = sample_dataset(dataset, num_samples=20)\n",
    "    \n",
    "    print(\"\\nMaking predictions...\")\n",
    "    # Evaluate predictions\n",
    "    conf_matrix, class_report, sample_preds = evaluate_predictions(classifier_lstm1_multifactorial, sampled_data)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(class_report)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error during execution: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluation on validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation Results for lstm1 (multifactorial):\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.7309\n",
      "F1 Score: 0.6804\n",
      "Recall: 0.7309\n",
      "\n",
      "Debug Information:\n",
      "Number of validation samples: 1360\n",
      "Unique predicted classes: [0 1 2 3 4]\n",
      "Unique true labels: [0 1 2 3 4 5]\n",
      "\n",
      "Class Distribution:\n",
      "Predicted class counts:\n",
      "Class 0: 665\n",
      "Class 1: 25\n",
      "Class 2: 596\n",
      "Class 3: 37\n",
      "Class 4: 37\n",
      "\n",
      "True class counts:\n",
      "Class 0: 655\n",
      "Class 1: 92\n",
      "Class 2: 334\n",
      "Class 3: 192\n",
      "Class 4: 74\n",
      "Class 5: 13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\multifactorial\\evaluation\\lstm1_validation_results.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluation on testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Evaluation Results for lstm1 (multifactorial):\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.7245\n",
      "F1 Score: 0.6699\n",
      "Recall: 0.7245\n",
      "\n",
      "Debug Information:\n",
      "Unique predicted classes: [0 1 2 3 4]\n",
      "Unique true labels: [0 1 2 3 4 5]\n",
      "Number of samples: 5826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the file\n",
    "file_path = r\"models\\multifactorial\\testing\\lstm1_multifactorial_test_evaluation.txt\"\n",
    "\n",
    "# Open the file and read its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Display the content in the notebook cell\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXT VS MULTIMEDIA TEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are keeping the best model of finetuning captioning which would be the one with GPT meaning that for the binary it would be the one from 5000 data and for the multifactorial the one with all data, the other models we are using are the 2 encoder only classifiers with LSTMs layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, classification_report\n",
    "from typing import Dict, List, Tuple, Any\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sample_stratified_data(dataset: Dataset, \n",
    "                          start_idx: int, \n",
    "                          end_idx: int, \n",
    "                          samples_per_category: int = 20,\n",
    "                          is_multifactorial: bool = False) -> Dataset:\n",
    "    \"\"\"\n",
    "    Creates a stratified sample of data from a specific index range, ensuring balanced representation \n",
    "    across categories.\n",
    "\n",
    "    Args:\n",
    "        dataset (Dataset): Input Hugging Face dataset to sample from.\n",
    "        start_idx (int): Starting index of the range to sample from.\n",
    "        end_idx (int): Ending index (exclusive) of the range to sample from.\n",
    "        samples_per_category (int, optional): Number of samples to select from each category. \n",
    "            Defaults to 20.\n",
    "        is_multifactorial (bool, optional): If True, samples from categories 1-5. If False, samples \n",
    "            from binary categories 0-1. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        Dataset: A new Hugging Face Dataset containing:\n",
    "            - For binary (is_multifactorial=False): 40 total samples (20 each from categories 0,1)\n",
    "            - For multifactorial (is_multifactorial=True): 100 total samples (20 each from \n",
    "              categories 1-5)\n",
    "\n",
    "    Notes:\n",
    "        - Expects 'nivel_risa' as the category column name\n",
    "        - Prints detailed sampling statistics during execution\n",
    "        - Uses sampling with replacement if a category has fewer samples than requested\n",
    "        - Only samples from categories that are present in the specified index range\n",
    "        - For binary classification, target categories are [0,1]\n",
    "        - For multifactorial classification, target categories are [1,2,3,4,5]\n",
    "\n",
    "    Example:\n",
    "        >>> # Binary classification example\n",
    "        >>> binary_sample = sample_stratified_data(dataset, 0, 1000, samples_per_category=20)\n",
    "        >>> print(len(binary_sample))  # Should print 40 (20 samples 칑 2 categories)\n",
    "        \n",
    "        >>> # Multifactorial classification example\n",
    "        >>> multi_sample = sample_stratified_data(dataset, 0, 1000, samples_per_category=20, \n",
    "        ...                                       is_multifactorial=True)\n",
    "        >>> print(len(multi_sample))  # Should print 100 (20 samples 칑 5 categories)\n",
    "    \"\"\"\n",
    "    subset = dataset.select(range(start_idx, end_idx))\n",
    "    \n",
    "    # Check what categories are present in the data\n",
    "    all_labels = [item['nivel_risa'] for item in subset]\n",
    "    unique_labels = sorted(set(all_labels))\n",
    "    print(f\"Categories present in range {start_idx}-{end_idx}: {unique_labels}\")\n",
    "    \n",
    "    # For binary classification (0,1) or multifactorial (1-5)\n",
    "    if is_multifactorial:\n",
    "        target_categories = [cat for cat in range(1, 6) if cat in unique_labels]\n",
    "    else:\n",
    "        target_categories = [cat for cat in [0, 1] if cat in unique_labels]\n",
    "    \n",
    "    sampled_data = []\n",
    "    for category in target_categories:\n",
    "        category_data = [i for i, item in enumerate(subset) if item['nivel_risa'] == category]\n",
    "        n_available = len(category_data)\n",
    "        \n",
    "        print(f\"Category {category}: {n_available} samples available\")\n",
    "        \n",
    "        if n_available > 0:\n",
    "            if n_available >= samples_per_category:\n",
    "                selected_indices = random.sample(category_data, samples_per_category)\n",
    "            else:\n",
    "                print(f\"Warning: Only {n_available} samples available for category {category}, sampling with replacement\")\n",
    "                selected_indices = random.choices(category_data, k=samples_per_category)\n",
    "            sampled_data.extend([subset[i] for i in selected_indices])\n",
    "    \n",
    "    result_dataset = Dataset.from_list(sampled_data)\n",
    "    \n",
    "    # Print distribution of samples\n",
    "    final_distribution = {}\n",
    "    for item in result_dataset:\n",
    "        category = item['nivel_risa']\n",
    "        final_distribution[category] = final_distribution.get(category, 0) + 1\n",
    "    \n",
    "    print(\"\\nFinal sample distribution:\")\n",
    "    for category in sorted(final_distribution.keys()):\n",
    "        print(f\"Category {category}: {final_distribution[category]} samples\")\n",
    "    print(f\"Total samples: {len(result_dataset)}\")\n",
    "    \n",
    "    return result_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(model, text, is_multifactorial=False, model_type='finetuning'):\n",
    "    \"\"\"\n",
    "    Generates predictions for a single text input using either a fine-tuned or LSTM model.\n",
    "\n",
    "    Args:\n",
    "        model: Trained model object that implements a predict method.\n",
    "            - For finetuning: Must return probabilities or predicted labels\n",
    "            - For LSTM: Must be compatible with get_prediction_lstm functions\n",
    "        text (str): Input text to classify.\n",
    "        is_multifactorial (bool, optional): If True, performs multi-class classification (1-5).\n",
    "            If False, performs binary classification (0-1). Defaults to False.\n",
    "        model_type (str, optional): Type of model to use. Must be either 'finetuning' or 'lstm'.\n",
    "            Defaults to 'finetuning'.\n",
    "\n",
    "    Returns:\n",
    "        Union[int, None]: \n",
    "            - For binary classification: 0 or 1\n",
    "            - For multifactorial: Integer from 1-5\n",
    "            - None if prediction fails\n",
    "    \n",
    "    Raises:\n",
    "        Exception: Catches and logs any prediction errors, returning None instead of failing.\n",
    "\n",
    "    Notes:\n",
    "        - For finetuning models:\n",
    "            - Binary: Returns 1 if probability > 0.5, else 0\n",
    "            - Multifactorial: Returns predicted label directly\n",
    "        - For LSTM models:\n",
    "            - Uses separate prediction functions for binary and multifactorial cases\n",
    "        - Truncates error messages for long texts to first 100 characters\n",
    "        \n",
    "    Example:\n",
    "        >>> # Binary classification with fine-tuned model\n",
    "        >>> result = predict_text(model, \"Sample text\", is_multifactorial=False)\n",
    "        >>> print(result)  # Prints 0 or 1\n",
    "        \n",
    "        >>> # Multifactorial classification with LSTM model\n",
    "        >>> result = predict_text(model, \"Sample text\", is_multifactorial=True, model_type='lstm')\n",
    "        >>> print(result)  # Prints 1-5\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if model_type == 'finetuning':\n",
    "            if is_multifactorial:\n",
    "                result = model.predict(text)\n",
    "                return result['predicted_label']\n",
    "            else:\n",
    "                probs = model.predict(text)\n",
    "                return int(probs[0][1] > 0.5)\n",
    "        else:  # LSTM\n",
    "            if is_multifactorial:\n",
    "                return get_prediction_lstm_multifactorial(model, text)\n",
    "            else:\n",
    "                return get_prediction_lstm(model, text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error predicting text: {text[:100]}...\")\n",
    "        print(f\"Error details: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data, is_multifactorial=False, model_type='finetuning'):\n",
    "    \"\"\"\n",
    "    Evaluates model performance on a dataset by computing accuracy, F1-score, and recall metrics.\n",
    "\n",
    "    Args:\n",
    "       model: Trained model object that implements prediction functionality. Should be compatible\n",
    "           with predict_text() function.\n",
    "       data (List[Dict]): List of dictionaries containing text samples and labels. Each dict must\n",
    "           have 'text' and 'nivel_risa' keys.\n",
    "       is_multifactorial (bool, optional): If True, performs multi-class evaluation (classes 1-5).\n",
    "           If False, performs binary evaluation (0-1). Defaults to False.\n",
    "       model_type (str, optional): Type of model to evaluate - either 'finetuning' or 'lstm'.\n",
    "           Defaults to 'finetuning'.\n",
    "\n",
    "    Returns:\n",
    "       Dict[str, float]: Dictionary containing evaluation metrics:\n",
    "           - 'accuracy': Overall classification accuracy\n",
    "           - 'f1_score': F1-score (weighted average for multi-class)\n",
    "           - 'recall': Recall score (weighted average for multi-class) \n",
    "           - 'n_samples': Number of successfully processed samples\n",
    "\n",
    "    Raises:\n",
    "       ValueError: If no valid predictions could be made on the input data.\n",
    "\n",
    "    Notes:\n",
    "       - Handles failed predictions gracefully by skipping them\n",
    "       - Uses weighted averaging for multi-class metrics to handle class imbalance\n",
    "       - Sets zero_division=0 for F1 and recall calculations to handle edge cases\n",
    "       - Truncates true labels if some predictions fail\n",
    "       - Prints progress and final metrics to stdout\n",
    "       \n",
    "    Example:\n",
    "       >>> test_data = [{'text': 'sample text', 'nivel_risa': 1}, ...]\n",
    "       >>> metrics = evaluate_model(model, test_data, is_multifactorial=True)\n",
    "       >>> print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    \"\"\"\n",
    "    texts = [item['text'] for item in data]\n",
    "    true_labels = [item['nivel_risa'] for item in data]\n",
    "    predictions = []\n",
    "    \n",
    "    print(f\"Evaluating {len(texts)} samples...\")\n",
    "    \n",
    "    for text in texts:\n",
    "        pred = predict_text(model, text, is_multifactorial, model_type)\n",
    "        if pred is not None:\n",
    "            predictions.append(pred)\n",
    "    \n",
    "    if not predictions:\n",
    "        raise ValueError(\"No valid predictions were made\")\n",
    "    \n",
    "    # Truncate true_labels to match predictions length\n",
    "    true_labels = true_labels[:len(predictions)]\n",
    "    \n",
    "    if is_multifactorial:\n",
    "        # Use weighted average for multiclass metrics to handle class imbalance\n",
    "        f1 = f1_score(true_labels, predictions, average='weighted', zero_division=0)\n",
    "        recall = recall_score(true_labels, predictions, average='weighted', zero_division=0)\n",
    "    else:\n",
    "        f1 = f1_score(true_labels, predictions, zero_division=0)\n",
    "        recall = recall_score(true_labels, predictions, zero_division=0)\n",
    "    \n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    \n",
    "    print(f\"Processed {len(predictions)} predictions out of {len(texts)} samples\")\n",
    "    print(f\"Metrics - Accuracy: {accuracy:.4f}, F1: {f1:.4f}, Recall: {recall:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'recall': recall,\n",
    "        'n_samples': len(predictions)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_performance(dataset, models):\n",
    "    \"\"\"\n",
    "    Compares multiple models' performance on multimedia and natural text data splits by evaluating\n",
    "    their accuracy, F1-score, and recall metrics.\n",
    "\n",
    "    Args:\n",
    "        dataset (Dataset): Hugging Face dataset containing text samples and labels.\n",
    "        models (Dict[str, Tuple]): Dictionary mapping model names to tuples containing:\n",
    "            - model: The trained model object\n",
    "            - is_multifactorial (bool): Whether model does multi-class classification\n",
    "            - model_type (str): Type of model ('finetuning' or 'lstm')\n",
    "            Example format: {\n",
    "                'model_name': (model_object, is_multifactorial, model_type)\n",
    "            }\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing evaluation results with columns:\n",
    "            - model: Name of the model\n",
    "            - data_type: Either 'multimedia' (indices 0-2006) or 'natural_text' (indices 2007+)\n",
    "            - accuracy: Classification accuracy\n",
    "            - f1_score: F1 score \n",
    "            - recall: Recall score\n",
    "            - n_samples: Number of samples evaluated\n",
    "\n",
    "    Notes:\n",
    "        - Splits data into two parts:\n",
    "            - Multimedia: First 2006 samples\n",
    "            - Natural text: Remaining samples (2007 onwards)\n",
    "        - Uses stratified sampling to get 20 samples per category from each split\n",
    "        - Handles errors independently for each model and data split\n",
    "        - Prints progress and error information during execution\n",
    "        - Missing results from failed evaluations will not appear in output DataFrame\n",
    "\n",
    "    Example:\n",
    "        >>> models_dict = {\n",
    "        ...     'BERT': (bert_model, False, 'finetuning'),\n",
    "        ...     'LSTM': (lstm_model, True, 'lstm')\n",
    "        ... }\n",
    "        >>> results_df = compare_models_performance(dataset, models_dict)\n",
    "        >>> print(results_df.groupby(['model', 'data_type'])['accuracy'].mean())\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    total_samples = len(dataset)\n",
    "    print(f\"Total dataset size: {total_samples}\")\n",
    "    \n",
    "    for model_name, (model, is_multifactorial, model_type) in models.items():\n",
    "        print(f\"\\nEvaluating {model_name}...\")\n",
    "        \n",
    "        try:\n",
    "            print(\"\\nSampling multimedia data (0-2006)...\")\n",
    "            multimedia_data = sample_stratified_data(dataset, 0, 2006, 20, is_multifactorial)\n",
    "            multimedia_metrics = evaluate_model(model, multimedia_data, is_multifactorial, model_type)\n",
    "            results.append({\n",
    "                'model': model_name,\n",
    "                'data_type': 'multimedia',\n",
    "                **multimedia_metrics\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating {model_name} on multimedia data: {str(e)}\")\n",
    "        \n",
    "        try:\n",
    "            print(\"\\nSampling natural text data (2007-end)...\")\n",
    "            natural_text_data = sample_stratified_data(dataset, 2007, total_samples, 20, is_multifactorial)\n",
    "            natural_metrics = evaluate_model(model, natural_text_data, is_multifactorial, model_type)\n",
    "            results.append({\n",
    "                'model': model_name,\n",
    "                'data_type': 'natural_text',\n",
    "                **natural_metrics\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating {model_name} on natural text data: {str(e)}\")\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset size: 9933\n",
      "\n",
      "Evaluating GPT Binary...\n",
      "\n",
      "Sampling multimedia data (0-2006)...\n",
      "Categories present in range 0-2006: [1, 2, 3, 4, 5]\n",
      "Category 1: 286 samples available\n",
      "\n",
      "Final sample distribution:\n",
      "Category 1: 20 samples\n",
      "Total samples: 20\n",
      "Evaluating 20 samples...\n",
      "Processed 20 predictions out of 20 samples\n",
      "Metrics - Accuracy: 0.7000, F1: 0.8235, Recall: 0.7000\n",
      "\n",
      "Sampling natural text data (2007-end)...\n",
      "Categories present in range 2007-9933: [1, 2, 3, 4, 5]\n",
      "Category 1: 930 samples available\n",
      "\n",
      "Final sample distribution:\n",
      "Category 1: 20 samples\n",
      "Total samples: 20\n",
      "Evaluating 20 samples...\n",
      "Processed 20 predictions out of 20 samples\n",
      "Metrics - Accuracy: 0.9500, F1: 0.9744, Recall: 0.9500\n",
      "\n",
      "Evaluating LSTM2 Binary...\n",
      "\n",
      "Sampling multimedia data (0-2006)...\n",
      "Categories present in range 0-2006: [1, 2, 3, 4, 5]\n",
      "Category 1: 286 samples available\n",
      "\n",
      "Final sample distribution:\n",
      "Category 1: 20 samples\n",
      "Total samples: 20\n",
      "Evaluating 20 samples...\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 469ms/step\n",
      "1/1 [==============================] - 0s 437ms/step\n",
      "1/1 [==============================] - 0s 444ms/step\n",
      "1/1 [==============================] - 0s 448ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 413ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 400ms/step\n",
      "1/1 [==============================] - 0s 455ms/step\n",
      "1/1 [==============================] - 0s 398ms/step\n",
      "1/1 [==============================] - 0s 398ms/step\n",
      "1/1 [==============================] - 0s 424ms/step\n",
      "Processed 20 predictions out of 20 samples\n",
      "Metrics - Accuracy: 1.0000, F1: 1.0000, Recall: 1.0000\n",
      "\n",
      "Sampling natural text data (2007-end)...\n",
      "Categories present in range 2007-9933: [1, 2, 3, 4, 5]\n",
      "Category 1: 930 samples available\n",
      "\n",
      "Final sample distribution:\n",
      "Category 1: 20 samples\n",
      "Total samples: 20\n",
      "Evaluating 20 samples...\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 397ms/step\n",
      "1/1 [==============================] - 0s 397ms/step\n",
      "1/1 [==============================] - 0s 468ms/step\n",
      "1/1 [==============================] - 0s 422ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 465ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "Processed 20 predictions out of 20 samples\n",
      "Metrics - Accuracy: 1.0000, F1: 1.0000, Recall: 1.0000\n",
      "\n",
      "Evaluating LSTM1 Binary...\n",
      "\n",
      "Sampling multimedia data (0-2006)...\n",
      "Categories present in range 0-2006: [1, 2, 3, 4, 5]\n",
      "Category 1: 286 samples available\n",
      "\n",
      "Final sample distribution:\n",
      "Category 1: 20 samples\n",
      "Total samples: 20\n",
      "Evaluating 20 samples...\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 384ms/step\n",
      "1/1 [==============================] - 0s 429ms/step\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "1/1 [==============================] - 0s 437ms/step\n",
      "1/1 [==============================] - 0s 384ms/step\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 432ms/step\n",
      "1/1 [==============================] - 0s 439ms/step\n",
      "Processed 20 predictions out of 20 samples\n",
      "Metrics - Accuracy: 1.0000, F1: 1.0000, Recall: 1.0000\n",
      "\n",
      "Sampling natural text data (2007-end)...\n",
      "Categories present in range 2007-9933: [1, 2, 3, 4, 5]\n",
      "Category 1: 930 samples available\n",
      "\n",
      "Final sample distribution:\n",
      "Category 1: 20 samples\n",
      "Total samples: 20\n",
      "Evaluating 20 samples...\n",
      "1/1 [==============================] - 0s 400ms/step\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "1/1 [==============================] - 0s 410ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 378ms/step\n",
      "1/1 [==============================] - 0s 394ms/step\n",
      "1/1 [==============================] - 0s 407ms/step\n",
      "1/1 [==============================] - 0s 424ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 400ms/step\n",
      "1/1 [==============================] - 0s 380ms/step\n",
      "1/1 [==============================] - 0s 413ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 464ms/step\n",
      "1/1 [==============================] - 0s 451ms/step\n",
      "1/1 [==============================] - 0s 430ms/step\n",
      "1/1 [==============================] - 1s 540ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "Processed 20 predictions out of 20 samples\n",
      "Metrics - Accuracy: 1.0000, F1: 1.0000, Recall: 1.0000\n",
      "\n",
      "Evaluating GPT Multifactorial...\n",
      "\n",
      "Sampling multimedia data (0-2006)...\n",
      "Categories present in range 0-2006: [1, 2, 3, 4, 5]\n",
      "Category 1: 286 samples available\n",
      "Category 2: 986 samples available\n",
      "Category 3: 543 samples available\n",
      "Category 4: 167 samples available\n",
      "Category 5: 24 samples available\n",
      "\n",
      "Final sample distribution:\n",
      "Category 1: 20 samples\n",
      "Category 2: 20 samples\n",
      "Category 3: 20 samples\n",
      "Category 4: 20 samples\n",
      "Category 5: 20 samples\n",
      "Total samples: 100\n",
      "Evaluating 100 samples...\n",
      "Processed 100 predictions out of 100 samples\n",
      "Metrics - Accuracy: 0.2000, F1: 0.0721, Recall: 0.2000\n",
      "\n",
      "Sampling natural text data (2007-end)...\n",
      "Categories present in range 2007-9933: [1, 2, 3, 4, 5]\n",
      "Category 1: 930 samples available\n",
      "Category 2: 3640 samples available\n",
      "Category 3: 2354 samples available\n",
      "Category 4: 821 samples available\n",
      "Category 5: 181 samples available\n",
      "\n",
      "Final sample distribution:\n",
      "Category 1: 20 samples\n",
      "Category 2: 20 samples\n",
      "Category 3: 20 samples\n",
      "Category 4: 20 samples\n",
      "Category 5: 20 samples\n",
      "Total samples: 100\n",
      "Evaluating 100 samples...\n",
      "Processed 100 predictions out of 100 samples\n",
      "Metrics - Accuracy: 0.1800, F1: 0.0621, Recall: 0.1800\n",
      "\n",
      "Evaluating LSTM2 Multifactorial...\n",
      "\n",
      "Sampling multimedia data (0-2006)...\n",
      "Categories present in range 0-2006: [1, 2, 3, 4, 5]\n",
      "Category 1: 286 samples available\n",
      "Category 2: 986 samples available\n",
      "Category 3: 543 samples available\n",
      "Category 4: 167 samples available\n",
      "Category 5: 24 samples available\n",
      "\n",
      "Final sample distribution:\n",
      "Category 1: 20 samples\n",
      "Category 2: 20 samples\n",
      "Category 3: 20 samples\n",
      "Category 4: 20 samples\n",
      "Category 5: 20 samples\n",
      "Total samples: 100\n",
      "Evaluating 100 samples...\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "1/1 [==============================] - 0s 410ms/step\n",
      "1/1 [==============================] - 0s 402ms/step\n",
      "1/1 [==============================] - 0s 430ms/step\n",
      "1/1 [==============================] - 0s 395ms/step\n",
      "1/1 [==============================] - 0s 399ms/step\n",
      "1/1 [==============================] - 0s 393ms/step\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 441ms/step\n",
      "1/1 [==============================] - 0s 409ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 359ms/step\n",
      "1/1 [==============================] - 0s 359ms/step\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 400ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 359ms/step\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 384ms/step\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "1/1 [==============================] - 0s 414ms/step\n",
      "1/1 [==============================] - 0s 409ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 414ms/step\n",
      "1/1 [==============================] - 0s 475ms/step\n",
      "1/1 [==============================] - 0s 438ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 1s 536ms/step\n",
      "1/1 [==============================] - 0s 395ms/step\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 468ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 372ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "Processed 100 predictions out of 100 samples\n",
      "Metrics - Accuracy: 0.2300, F1: 0.1275, Recall: 0.2300\n",
      "\n",
      "Sampling natural text data (2007-end)...\n",
      "Categories present in range 2007-9933: [1, 2, 3, 4, 5]\n",
      "Category 1: 930 samples available\n",
      "Category 2: 3640 samples available\n",
      "Category 3: 2354 samples available\n",
      "Category 4: 821 samples available\n",
      "Category 5: 181 samples available\n",
      "\n",
      "Final sample distribution:\n",
      "Category 1: 20 samples\n",
      "Category 2: 20 samples\n",
      "Category 3: 20 samples\n",
      "Category 4: 20 samples\n",
      "Category 5: 20 samples\n",
      "Total samples: 100\n",
      "Evaluating 100 samples...\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 359ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 323ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "Processed 100 predictions out of 100 samples\n",
      "Metrics - Accuracy: 0.2600, F1: 0.1866, Recall: 0.2600\n",
      "\n",
      "Evaluating LSTM1 Multifactorial...\n",
      "\n",
      "Sampling multimedia data (0-2006)...\n",
      "Categories present in range 0-2006: [1, 2, 3, 4, 5]\n",
      "Category 1: 286 samples available\n",
      "Category 2: 986 samples available\n",
      "Category 3: 543 samples available\n",
      "Category 4: 167 samples available\n",
      "Category 5: 24 samples available\n",
      "\n",
      "Final sample distribution:\n",
      "Category 1: 20 samples\n",
      "Category 2: 20 samples\n",
      "Category 3: 20 samples\n",
      "Category 4: 20 samples\n",
      "Category 5: 20 samples\n",
      "Total samples: 100\n",
      "Evaluating 100 samples...\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 359ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 1s 558ms/step\n",
      "1/1 [==============================] - 0s 494ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 429ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "1/1 [==============================] - 0s 395ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 387ms/step\n",
      "1/1 [==============================] - 0s 397ms/step\n",
      "1/1 [==============================] - 0s 381ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 448ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 393ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 437ms/step\n",
      "1/1 [==============================] - 0s 448ms/step\n",
      "1/1 [==============================] - 0s 392ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "1/1 [==============================] - 0s 427ms/step\n",
      "1/1 [==============================] - 0s 405ms/step\n",
      "1/1 [==============================] - 0s 447ms/step\n",
      "1/1 [==============================] - 0s 423ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 400ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "Processed 100 predictions out of 100 samples\n",
      "Metrics - Accuracy: 0.2200, F1: 0.1670, Recall: 0.2200\n",
      "\n",
      "Sampling natural text data (2007-end)...\n",
      "Categories present in range 2007-9933: [1, 2, 3, 4, 5]\n",
      "Category 1: 930 samples available\n",
      "Category 2: 3640 samples available\n",
      "Category 3: 2354 samples available\n",
      "Category 4: 821 samples available\n",
      "Category 5: 181 samples available\n",
      "\n",
      "Final sample distribution:\n",
      "Category 1: 20 samples\n",
      "Category 2: 20 samples\n",
      "Category 3: 20 samples\n",
      "Category 4: 20 samples\n",
      "Category 5: 20 samples\n",
      "Total samples: 100\n",
      "Evaluating 100 samples...\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 415ms/step\n",
      "1/1 [==============================] - 1s 522ms/step\n",
      "1/1 [==============================] - 0s 400ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 360ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 342ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 1s 600ms/step\n",
      "1/1 [==============================] - 0s 464ms/step\n",
      "1/1 [==============================] - 0s 427ms/step\n",
      "1/1 [==============================] - 0s 467ms/step\n",
      "1/1 [==============================] - 1s 536ms/step\n",
      "1/1 [==============================] - 0s 470ms/step\n",
      "1/1 [==============================] - 0s 410ms/step\n",
      "1/1 [==============================] - 0s 394ms/step\n",
      "1/1 [==============================] - 0s 485ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "1/1 [==============================] - 0s 425ms/step\n",
      "1/1 [==============================] - 1s 501ms/step\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 373ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 445ms/step\n",
      "1/1 [==============================] - 1s 513ms/step\n",
      "1/1 [==============================] - 0s 481ms/step\n",
      "Processed 100 predictions out of 100 samples\n",
      "Metrics - Accuracy: 0.2700, F1: 0.2006, Recall: 0.2700\n",
      "\n",
      "Results:\n",
      "                   model     data_type  accuracy  f1_score  recall  n_samples\n",
      "0             GPT Binary    multimedia    0.7000    0.8235  0.7000         20\n",
      "1             GPT Binary  natural_text    0.9500    0.9744  0.9500         20\n",
      "2           LSTM2 Binary    multimedia    1.0000    1.0000  1.0000         20\n",
      "3           LSTM2 Binary  natural_text    1.0000    1.0000  1.0000         20\n",
      "4           LSTM1 Binary    multimedia    1.0000    1.0000  1.0000         20\n",
      "5           LSTM1 Binary  natural_text    1.0000    1.0000  1.0000         20\n",
      "6     GPT Multifactorial    multimedia    0.2000    0.0721  0.2000        100\n",
      "7     GPT Multifactorial  natural_text    0.1800    0.0621  0.1800        100\n",
      "8   LSTM2 Multifactorial    multimedia    0.2300    0.1275  0.2300        100\n",
      "9   LSTM2 Multifactorial  natural_text    0.2600    0.1866  0.2600        100\n",
      "10  LSTM1 Multifactorial    multimedia    0.2200    0.1670  0.2200        100\n",
      "11  LSTM1 Multifactorial  natural_text    0.2700    0.2006  0.2700        100\n",
      "\n",
      "Summary by model type and data type:\n",
      "                                  accuracy     f1_score     recall      \\\n",
      "                                      mean std     mean std   mean std   \n",
      "model                data_type                                           \n",
      "GPT Binary           multimedia     0.7000 NaN   0.8235 NaN 0.7000 NaN   \n",
      "                     natural_text   0.9500 NaN   0.9744 NaN 0.9500 NaN   \n",
      "GPT Multifactorial   multimedia     0.2000 NaN   0.0721 NaN 0.2000 NaN   \n",
      "                     natural_text   0.1800 NaN   0.0621 NaN 0.1800 NaN   \n",
      "LSTM1 Binary         multimedia     1.0000 NaN   1.0000 NaN 1.0000 NaN   \n",
      "                     natural_text   1.0000 NaN   1.0000 NaN 1.0000 NaN   \n",
      "LSTM1 Multifactorial multimedia     0.2200 NaN   0.1670 NaN 0.2200 NaN   \n",
      "                     natural_text   0.2700 NaN   0.2006 NaN 0.2700 NaN   \n",
      "LSTM2 Binary         multimedia     1.0000 NaN   1.0000 NaN 1.0000 NaN   \n",
      "                     natural_text   1.0000 NaN   1.0000 NaN 1.0000 NaN   \n",
      "LSTM2 Multifactorial multimedia     0.2300 NaN   0.1275 NaN 0.2300 NaN   \n",
      "                     natural_text   0.2600 NaN   0.1866 NaN 0.2600 NaN   \n",
      "\n",
      "                                  n_samples            \n",
      "                                       mean  min  max  \n",
      "model                data_type                         \n",
      "GPT Binary           multimedia     20.0000   20   20  \n",
      "                     natural_text   20.0000   20   20  \n",
      "GPT Multifactorial   multimedia    100.0000  100  100  \n",
      "                     natural_text  100.0000  100  100  \n",
      "LSTM1 Binary         multimedia     20.0000   20   20  \n",
      "                     natural_text   20.0000   20   20  \n",
      "LSTM1 Multifactorial multimedia    100.0000  100  100  \n",
      "                     natural_text  100.0000  100  100  \n",
      "LSTM2 Binary         multimedia     20.0000   20   20  \n",
      "                     natural_text   20.0000   20   20  \n",
      "LSTM2 Multifactorial multimedia    100.0000  100  100  \n",
      "                     natural_text  100.0000  100  100  \n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'GPT Binary': (model_5k_gpt_finetuning_binary, False, 'finetuning'),\n",
    "    'LSTM2 Binary': (classifier_lstm2_binary, False, 'lstm'),\n",
    "    'LSTM1 Binary': (classifier_lstm1_binary, False, 'lstm'),\n",
    "    'GPT Multifactorial': (model_12k_gpt_finetuning_multifactorial, True, 'finetuning'),\n",
    "    'LSTM2 Multifactorial': (classifier_lstm2_multifactorial, True, 'lstm'),\n",
    "    'LSTM1 Multifactorial': (classifier_lstm1_multifactorial, True, 'lstm')\n",
    "}\n",
    "\n",
    "# Run comparison\n",
    "results_df = compare_models_performance(dataset, models)\n",
    "\n",
    "# Display results with better formatting\n",
    "print(\"\\nResults:\")\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "print(results_df)\n",
    "# Show detailed summary statistics\n",
    "print(\"\\nSummary by model type and data type:\")\n",
    "summary = results_df.groupby(['model', 'data_type']).agg({\n",
    "    'accuracy': ['mean', 'std'],\n",
    "    'f1_score': ['mean', 'std'],\n",
    "    'recall': ['mean', 'std'],\n",
    "    'n_samples': ['mean', 'min', 'max']\n",
    "}).round(4)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>data_type</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>n_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPT Binary</td>\n",
       "      <td>multimedia</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.8235</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPT Binary</td>\n",
       "      <td>natural_text</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSTM2 Binary</td>\n",
       "      <td>multimedia</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTM2 Binary</td>\n",
       "      <td>natural_text</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LSTM1 Binary</td>\n",
       "      <td>multimedia</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LSTM1 Binary</td>\n",
       "      <td>natural_text</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GPT Multifactorial</td>\n",
       "      <td>multimedia</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GPT Multifactorial</td>\n",
       "      <td>natural_text</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.0621</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LSTM2 Multifactorial</td>\n",
       "      <td>multimedia</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.1275</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LSTM2 Multifactorial</td>\n",
       "      <td>natural_text</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LSTM1 Multifactorial</td>\n",
       "      <td>multimedia</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.1670</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LSTM1 Multifactorial</td>\n",
       "      <td>natural_text</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>0.2006</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model     data_type  accuracy  f1_score  recall  n_samples\n",
       "0             GPT Binary    multimedia    0.7000    0.8235  0.7000         20\n",
       "1             GPT Binary  natural_text    0.9500    0.9744  0.9500         20\n",
       "2           LSTM2 Binary    multimedia    1.0000    1.0000  1.0000         20\n",
       "3           LSTM2 Binary  natural_text    1.0000    1.0000  1.0000         20\n",
       "4           LSTM1 Binary    multimedia    1.0000    1.0000  1.0000         20\n",
       "5           LSTM1 Binary  natural_text    1.0000    1.0000  1.0000         20\n",
       "6     GPT Multifactorial    multimedia    0.2000    0.0721  0.2000        100\n",
       "7     GPT Multifactorial  natural_text    0.1800    0.0621  0.1800        100\n",
       "8   LSTM2 Multifactorial    multimedia    0.2300    0.1275  0.2300        100\n",
       "9   LSTM2 Multifactorial  natural_text    0.2600    0.1866  0.2600        100\n",
       "10  LSTM1 Multifactorial    multimedia    0.2200    0.1670  0.2200        100\n",
       "11  LSTM1 Multifactorial  natural_text    0.2700    0.2006  0.2700        100"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propmts Results LLM ChatGPT vs Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mi hermana siempre me consuela. Debe ser porqu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>los platos y platitos forman una estrella. Los...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>쯈u칠 pinta un pintor cuando se aburre? Abstrac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>del presupuesto _del cielo_. Ent칩nces es cuand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mismo joven rubio de la imagen anterior, pero ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5821</th>\n",
       "      <td>Estaba en un restaurante y mientras iba al ba침...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5822</th>\n",
       "      <td>corriendo, dando brincos increibles y vueltas ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5823</th>\n",
       "      <td>con buenos parques de artiller칤a y fuertes res...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5824</th>\n",
       "      <td>y por esta causa me aflig칤a m치s que de antes. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5825</th>\n",
       "      <td>gitano. Cont칩 tambi칠n el concierto que entre P...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5826 rows 칑 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     Mi hermana siempre me consuela. Debe ser porqu...      1\n",
       "1     los platos y platitos forman una estrella. Los...      0\n",
       "2     쯈u칠 pinta un pintor cuando se aburre? Abstrac...      1\n",
       "3     del presupuesto _del cielo_. Ent칩nces es cuand...      0\n",
       "4     Mismo joven rubio de la imagen anterior, pero ...      1\n",
       "...                                                 ...    ...\n",
       "5821  Estaba en un restaurante y mientras iba al ba침...      1\n",
       "5822  corriendo, dando brincos increibles y vueltas ...      0\n",
       "5823  con buenos parques de artiller칤a y fuertes res...      0\n",
       "5824  y por esta causa me aflig칤a m치s que de antes. ...      0\n",
       "5825  gitano. Cont칩 tambi칠n el concierto que entre P...      0\n",
       "\n",
       "[5826 rows x 2 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/testing.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 text  label\n",
      "0   en ella m치s de la cuenta. Esto se iba murmuran...      0\n",
      "1   un bravo sir Rogerio, que batall칩 en compa침칤a ...      0\n",
      "2   familia; rostro enjuto, nariz aguile침a, aspect...      0\n",
      "3   Una pregunta para todos los racistas, de verda...      1\n",
      "4   por muerto a don Mart칤n, cogi칩 los cuartos del...      0\n",
      "5   todo. F츼BULA XVI. _SIRINGA TRANSFORMADA EN CA칌...      0\n",
      "6    쮺u치l es la diferencia entre un beb칠 y una bo...      1\n",
      "7   como te gustan los hombres ? Yo: lejos y callados      1\n",
      "8   Yo esperando que sean las 5pm para ver el part...      1\n",
      "9   casa y reino de nuestros padres, y esta nuestr...      0\n",
      "10   쯉abes por qu칠 los ni침os con c치ncer no pueden...      1\n",
      "11  le di por los pechos, y as칤 los despach칠 a tod...      0\n",
      "12  miraban y alababan, pero ning칰n rey, ni otro a...      0\n",
      "13   쮺칩mo se llama el mejor amigo de un robot? 춰USB!      1\n",
      "14   쯇or qu칠 la modelo fitness se hizo un tatuaje...      1\n",
      "15  ninguna sobre los destinos de la Europa y del ...      0\n",
      "16  que se encuentra en samoa, tahitiano, sandwich...      0\n",
      "17  - Se abre el tel칩n y aparecen cientos de barra...      1\n",
      "18  de libros, tiesa y rubia, con un perfil anticu...      0\n",
      "19  Estoy saliendo con una chica que podr칤a ser mi...      1\n",
      "20  sobre la tumba? 쮺u치l es el brazo que va a mov...      0\n",
      "21  sent칤 estremecerse mi pecho, porque sus palabr...      0\n",
      "22  abstenerse. No os conducir칠 yo por eminencias ...      0\n",
      "23  -쮿a visto usted como toca mi hijo el viol칤n? ...      1\n",
      "24  -쯈ue te apuestas a que hago una tortilla haci...      1\n",
      "25  porque Guillermo Borsiere, que gime hace poco ...      0\n",
      "26  - M칤re, jefe, como ayer llegu칠 tarde le he tra...      1\n",
      "27   쯈u칠 usan los magos para escribir?\\n Plumas e...      1\n",
      "28  gitanica no entrase en la c치rcel, y todos los ...      0\n",
      "29  Iban dos lombrices caminando de paseo y charla...      1\n",
      "30  Todo el mundo en ese carril ha visto destino f...      1\n",
      "31  -Jaimito, 쯤uien fue Juana de Arco? -Una droga...      1\n",
      "32  en medio de este enorme bullicio! 춰Cu치nto debe...      0\n",
      "33  쯈u칠 hace un boxeador cuando quiere descansar?...      1\n",
      "34  est치? 댹메y, ay, ay, chico, eso es m치s complica...      0\n",
      "35      쯈u칠 hace Thor en la monta침a? Martillar-bres.      1\n",
      "36  se la arrebata de su presencia, y la lleva 치 p...      0\n",
      "37  --Venga el asno, se침or hu칠sped; que tambi칠n sa...      0\n",
      "38   쯇or qu칠 el caf칠 siempre est치 estresado?\\n Po...      1\n",
      "39  -de quien est치 boquita? Y 칠sta naricita? Y 칠st...      1\n"
     ]
    }
   ],
   "source": [
    "class_0 = df[df['label'] == 0]\n",
    "class_1 = df[df['label'] == 1]\n",
    "\n",
    "# Calculate the number of samples per class for balance (10 samples each)\n",
    "n_samples = 20\n",
    "\n",
    "# Randomly sample from each class\n",
    "class_0_sampled = resample(class_0, n_samples=n_samples, random_state=42)\n",
    "class_1_sampled = resample(class_1, n_samples=n_samples, random_state=42)\n",
    "\n",
    "# Combine sampled data\n",
    "balanced_sample = pd.concat([class_0_sampled, class_1_sampled])\n",
    "\n",
    "# Shuffle the resulting dataframe\n",
    "balanced_sample = balanced_sample.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Display the selected samples\n",
    "print(balanced_sample)\n",
    "\n",
    "balanced_sample.to_csv(\"data/balanced_sample.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating GPT Binary...\n",
      "\n",
      "Evaluating LSTM2 Binary...\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 493ms/step\n",
      "1/1 [==============================] - 0s 395ms/step\n",
      "1/1 [==============================] - 0s 393ms/step\n",
      "1/1 [==============================] - 0s 425ms/step\n",
      "1/1 [==============================] - 0s 446ms/step\n",
      "1/1 [==============================] - 0s 415ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 462ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 381ms/step\n",
      "1/1 [==============================] - 0s 432ms/step\n",
      "1/1 [==============================] - 0s 384ms/step\n",
      "1/1 [==============================] - 0s 417ms/step\n",
      "1/1 [==============================] - 0s 395ms/step\n",
      "1/1 [==============================] - 0s 405ms/step\n",
      "1/1 [==============================] - 0s 420ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 424ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 442ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 372ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 441ms/step\n",
      "1/1 [==============================] - 0s 408ms/step\n",
      "1/1 [==============================] - 0s 436ms/step\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "1/1 [==============================] - 0s 378ms/step\n",
      "1/1 [==============================] - 0s 478ms/step\n",
      "1/1 [==============================] - 0s 389ms/step\n",
      "1/1 [==============================] - 0s 416ms/step\n",
      "\n",
      "Evaluating LSTM1 Binary...\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 429ms/step\n",
      "1/1 [==============================] - 0s 387ms/step\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "1/1 [==============================] - 0s 420ms/step\n",
      "1/1 [==============================] - 0s 382ms/step\n",
      "1/1 [==============================] - 0s 359ms/step\n",
      "1/1 [==============================] - 0s 393ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 378ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 351ms/step\n",
      "1/1 [==============================] - 0s 359ms/step\n",
      "1/1 [==============================] - 0s 402ms/step\n",
      "1/1 [==============================] - 0s 419ms/step\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 406ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 407ms/step\n",
      "1/1 [==============================] - 0s 344ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "\n",
      "Evaluating GPT Multifactorial...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating LSTM2 Multifactorial...\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 472ms/step\n",
      "1/1 [==============================] - 0s 403ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 311ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 306ms/step\n",
      "1/1 [==============================] - 0s 340ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 380ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 320ms/step\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 376ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 430ms/step\n",
      "1/1 [==============================] - 0s 398ms/step\n",
      "1/1 [==============================] - 0s 400ms/step\n",
      "1/1 [==============================] - 0s 330ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 336ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "1/1 [==============================] - 0s 315ms/step\n",
      "1/1 [==============================] - 0s 314ms/step\n",
      "1/1 [==============================] - 0s 407ms/step\n",
      "1/1 [==============================] - 0s 357ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 310ms/step\n",
      "1/1 [==============================] - 1s 511ms/step\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 334ms/step\n",
      "1/1 [==============================] - 0s 329ms/step\n",
      "1/1 [==============================] - 0s 420ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "1/1 [==============================] - 0s 450ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 319ms/step\n",
      "1/1 [==============================] - 0s 318ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 457ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 413ms/step\n",
      "1/1 [==============================] - 0s 434ms/step\n",
      "1/1 [==============================] - 0s 384ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 368ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 450ms/step\n",
      "1/1 [==============================] - 0s 333ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 313ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "\n",
      "Evaluating LSTM1 Multifactorial...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 0s 469ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 477ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "1/1 [==============================] - 0s 411ms/step\n",
      "1/1 [==============================] - 0s 437ms/step\n",
      "1/1 [==============================] - 0s 366ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 353ms/step\n",
      "1/1 [==============================] - 0s 402ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 363ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 322ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 355ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 379ms/step\n",
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 339ms/step\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "1/1 [==============================] - 0s 379ms/step\n",
      "1/1 [==============================] - 0s 381ms/step\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "1/1 [==============================] - 0s 365ms/step\n",
      "1/1 [==============================] - 0s 414ms/step\n",
      "1/1 [==============================] - 0s 341ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 362ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 397ms/step\n",
      "1/1 [==============================] - 1s 504ms/step\n",
      "1/1 [==============================] - 0s 413ms/step\n",
      "1/1 [==============================] - 0s 435ms/step\n",
      "1/1 [==============================] - 0s 443ms/step\n",
      "1/1 [==============================] - 0s 403ms/step\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "1/1 [==============================] - 0s 386ms/step\n",
      "1/1 [==============================] - 0s 424ms/step\n",
      "1/1 [==============================] - 0s 352ms/step\n",
      "1/1 [==============================] - 0s 402ms/step\n",
      "1/1 [==============================] - 0s 424ms/step\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 348ms/step\n",
      "1/1 [==============================] - 0s 369ms/step\n",
      "1/1 [==============================] - 0s 367ms/step\n",
      "1/1 [==============================] - 0s 475ms/step\n",
      "1/1 [==============================] - 0s 469ms/step\n",
      "1/1 [==============================] - 0s 395ms/step\n",
      "1/1 [==============================] - 0s 416ms/step\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "1/1 [==============================] - 0s 370ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 349ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "1/1 [==============================] - 0s 380ms/step\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "1/1 [==============================] - 0s 347ms/step\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "1/1 [==============================] - 0s 411ms/step\n",
      "1/1 [==============================] - 0s 412ms/step\n",
      "1/1 [==============================] - 0s 383ms/step\n",
      "1/1 [==============================] - 0s 374ms/step\n",
      "1/1 [==============================] - 0s 390ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 404ms/step\n",
      "1/1 [==============================] - 0s 421ms/step\n",
      "\n",
      "Binary Classification Results:\n",
      "==============================\n",
      "\n",
      "GPT Binary\n",
      "----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        20\n",
      "           1       1.00      0.70      0.82        20\n",
      "\n",
      "    accuracy                           0.85        40\n",
      "   macro avg       0.88      0.85      0.85        40\n",
      "weighted avg       0.88      0.85      0.85        40\n",
      "\n",
      "\n",
      "LSTM2 Binary\n",
      "------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        40\n",
      "   macro avg       1.00      1.00      1.00        40\n",
      "weighted avg       1.00      1.00      1.00        40\n",
      "\n",
      "\n",
      "LSTM1 Binary\n",
      "------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        20\n",
      "           1       1.00      0.90      0.95        20\n",
      "\n",
      "    accuracy                           0.95        40\n",
      "   macro avg       0.95      0.95      0.95        40\n",
      "weighted avg       0.95      0.95      0.95        40\n",
      "\n",
      "\n",
      "Multifactorial Classification Results:\n",
      "====================================\n",
      "\n",
      "GPT Multifactorial\n",
      "------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00        20\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.20      0.90      0.32        20\n",
      "           4       0.00      0.00      0.00        20\n",
      "           5       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.18       100\n",
      "   macro avg       0.03      0.15      0.05       100\n",
      "weighted avg       0.04      0.18      0.06       100\n",
      "\n",
      "\n",
      "LSTM2 Multifactorial\n",
      "--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00        20\n",
      "           2       0.22      0.90      0.36        20\n",
      "           3       0.23      0.15      0.18        20\n",
      "           4       0.60      0.15      0.24        20\n",
      "           5       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.24       100\n",
      "   macro avg       0.18      0.20      0.13       100\n",
      "weighted avg       0.21      0.24      0.16       100\n",
      "\n",
      "\n",
      "LSTM1 Multifactorial\n",
      "--------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.10      0.16        20\n",
      "           2       0.28      1.00      0.43        20\n",
      "           3       0.33      0.05      0.09        20\n",
      "           4       0.35      0.35      0.35        20\n",
      "           5       0.00      0.00      0.00        20\n",
      "\n",
      "    accuracy                           0.30       100\n",
      "   macro avg       0.27      0.30      0.21       100\n",
      "weighted avg       0.27      0.30      0.21       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_binary_models(df, models):\n",
    "    \"\"\"\n",
    "    Evaluate binary classification models on the balanced sample\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for model_name, (model, is_multi, model_type) in models.items():\n",
    "        if not is_multi:  # Only evaluate binary models\n",
    "            print(f\"\\nEvaluating {model_name}...\")\n",
    "            predictions = []\n",
    "            \n",
    "            for text in df['text']:\n",
    "                if model_type == 'finetuning':\n",
    "                    pred = int(model.predict(text)[0][1] > 0.5)\n",
    "                else:  # lstm\n",
    "                    pred = get_prediction_lstm(model, text)\n",
    "                predictions.append(pred)\n",
    "            \n",
    "            results[model_name] = {\n",
    "                'predictions': predictions,\n",
    "                'report': classification_report(df['label'], predictions),\n",
    "                'confusion_matrix': confusion_matrix(df['label'], predictions)\n",
    "            }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def evaluate_multifactorial_models(df, models):\n",
    "    \"\"\"\n",
    "    Evaluate multifactorial classification models on the balanced sample\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for model_name, (model, is_multi, model_type) in models.items():\n",
    "        if is_multi:  # Only evaluate multifactorial models\n",
    "            print(f\"\\nEvaluating {model_name}...\")\n",
    "            predictions = []\n",
    "            \n",
    "            for text in df['text']:\n",
    "                if model_type == 'finetuning':\n",
    "                    pred = model.predict(text)['predicted_label']\n",
    "                else:  # lstm\n",
    "                    pred = get_prediction_lstm_multifactorial(model, text)\n",
    "                predictions.append(pred)\n",
    "            \n",
    "            results[model_name] = {\n",
    "                'predictions': predictions,\n",
    "                'report': classification_report(df['nivel_risa'], predictions),\n",
    "                'confusion_matrix': confusion_matrix(df['nivel_risa'], predictions)\n",
    "            }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Load the balanced datasets\n",
    "binary_df = pd.read_csv(\"data/balanced_sample.csv\")\n",
    "multi_df = pd.read_csv(\"data/balanced_sample_multifactorial.csv\")\n",
    "\n",
    "# Define models dictionary (as provided)\n",
    "models = {\n",
    "    'GPT Binary': (model_5k_gpt_finetuning_binary, False, 'finetuning'),\n",
    "    'LSTM2 Binary': (classifier_lstm2_binary, False, 'lstm'),\n",
    "    'LSTM1 Binary': (classifier_lstm1_binary, False, 'lstm'),\n",
    "    'GPT Multifactorial': (model_12k_gpt_finetuning_multifactorial, True, 'finetuning'),\n",
    "    'LSTM2 Multifactorial': (classifier_lstm2_multifactorial, True, 'lstm'),\n",
    "    'LSTM1 Multifactorial': (classifier_lstm1_multifactorial, True, 'lstm')\n",
    "}\n",
    "\n",
    "# Evaluate models\n",
    "binary_results = evaluate_binary_models(binary_df, models)\n",
    "multi_results = evaluate_multifactorial_models(multi_df, models)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nBinary Classification Results:\")\n",
    "print(\"==============================\")\n",
    "for model_name, result in binary_results.items():\n",
    "    print(f\"\\n{model_name}\")\n",
    "    print(\"-\" * len(model_name))\n",
    "    print(result['report'])\n",
    "\n",
    "print(\"\\nMultifactorial Classification Results:\")\n",
    "print(\"====================================\")\n",
    "for model_name, result in multi_results.items():\n",
    "    print(f\"\\n{model_name}\")\n",
    "    print(\"-\" * len(model_name))\n",
    "    print(result['report'])\n",
    "\n",
    "# Create confusion matrix visualizations\n",
    "def plot_confusion_matrix(cm, title):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "for model_name, result in binary_results.items():\n",
    "    plot_confusion_matrix(result['confusion_matrix'], f'Confusion Matrix - {model_name}')\n",
    "\n",
    "for model_name, result in multi_results.items():\n",
    "    plot_confusion_matrix(result['confusion_matrix'], f'Confusion Matrix - {model_name}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, classification_report\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, is_multifactorial=False):\n",
    "    \"\"\"\n",
    "    Calculate performance metrics ensuring consistent lengths\n",
    "    \"\"\"\n",
    "    # Convert inputs to lists and ensure same length\n",
    "    y_true = list(y_true)\n",
    "    y_pred = list(y_pred)\n",
    "    \n",
    "    # Verify we have valid data\n",
    "    if len(y_true) != len(y_pred):\n",
    "        print(f\"Warning: Inconsistent lengths - y_true: {len(y_true)}, y_pred: {len(y_pred)}\")\n",
    "        # Take the minimum length to ensure consistency\n",
    "        min_len = min(len(y_true), len(y_pred))\n",
    "        y_true = y_true[:min_len]\n",
    "        y_pred = y_pred[:min_len]\n",
    "    \n",
    "    # Remove any invalid entries (like NaN)\n",
    "    valid_indices = [i for i in range(len(y_true)) \n",
    "                    if pd.notna(y_true[i]) and pd.notna(y_pred[i])]\n",
    "    y_true = [y_true[i] for i in valid_indices]\n",
    "    y_pred = [y_pred[i] for i in valid_indices]\n",
    "    \n",
    "    if is_multifactorial:\n",
    "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "        recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    else:\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'recall': recall,\n",
    "        'n_samples': len(y_true)\n",
    "    }\n",
    "\n",
    "def print_detailed_results(y_true, y_pred, task_name):\n",
    "    \"\"\"\n",
    "    Print detailed classification report\n",
    "    \"\"\"\n",
    "    print(f\"\\n{task_name} Classification Report:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Binary Classification Metrics:\n",
      "============================\n",
      "Accuracy: 0.9231\n",
      "F1-Score: 0.9231\n",
      "Recall: 0.9474\n",
      "Number of samples: 39\n",
      "\n",
      "Multifactorial Classification Metrics:\n",
      "================================\n",
      "Accuracy: 0.3043\n",
      "F1-Score: 0.2736\n",
      "Recall: 0.3043\n",
      "Number of samples: 92\n",
      "\n",
      "Binary Classification Report:\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92        20\n",
      "           1       0.90      0.95      0.92        19\n",
      "\n",
      "    accuracy                           0.92        39\n",
      "   macro avg       0.92      0.92      0.92        39\n",
      "weighted avg       0.92      0.92      0.92        39\n",
      "\n",
      "\n",
      "Multifactorial Classification Report:\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       0.54      0.70      0.61        20\n",
      "         2.0       0.29      0.50      0.37        18\n",
      "         3.0       0.33      0.25      0.29        16\n",
      "         4.0       0.50      0.05      0.10        19\n",
      "         5.0       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.30        92\n",
      "   macro avg       0.28      0.25      0.23        92\n",
      "weighted avg       0.34      0.30      0.27        92\n",
      "\n",
      "\n",
      "Summary:\n",
      "========\n",
      "          Task  Accuracy  F1_Score  Recall  Samples\n",
      "        Binary    0.9231    0.9231  0.9474       39\n",
      "Multifactorial    0.3043    0.2736  0.3043       92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\acost\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load datasets\n",
    "binary_original = pd.read_csv(\"data/balanced_sample.csv\")\n",
    "binary_gpt = pd.read_csv(\"data/balanced_sample_gpt_answers.csv\")\n",
    "multi_original = pd.read_csv(\"data/balanced_sample_multifactorial.csv\")\n",
    "\n",
    "multi_gpt = pd.read_csv(\"data/balanced_sample_multifactorial_gpt_answers.csv\")\n",
    "\n",
    "# Clean data to ensure valid comparisons\n",
    "def clean_data(df):\n",
    "    \"\"\"Remove any rows with NaN values\"\"\"\n",
    "    return df.dropna()\n",
    "\n",
    "binary_original = clean_data(binary_original)\n",
    "binary_gpt = clean_data(binary_gpt)\n",
    "multi_original = clean_data(multi_original)\n",
    "multi_gpt = clean_data(multi_gpt)\n",
    "\n",
    "# Ensure matching indices\n",
    "binary_indices = binary_original.index.intersection(binary_gpt.index)\n",
    "multi_indices = multi_original.index.intersection(multi_gpt.index)\n",
    "\n",
    "# Calculate metrics for binary classification\n",
    "binary_metrics = calculate_metrics(\n",
    "    binary_original.loc[binary_indices, 'label'],\n",
    "    binary_gpt.loc[binary_indices, 'label']\n",
    ")\n",
    "\n",
    "# Calculate metrics for multifactorial classification\n",
    "multi_metrics = calculate_metrics(\n",
    "    multi_original.loc[multi_indices, 'nivel_risa'],\n",
    "    multi_gpt.loc[multi_indices, 'nivel_risa'],\n",
    "    is_multifactorial=True\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(\"\\nBinary Classification Metrics:\")\n",
    "print(\"============================\")\n",
    "print(f\"Accuracy: {binary_metrics['accuracy']:.4f}\")\n",
    "print(f\"F1-Score: {binary_metrics['f1_score']:.4f}\")\n",
    "print(f\"Recall: {binary_metrics['recall']:.4f}\")\n",
    "print(f\"Number of samples: {binary_metrics['n_samples']}\")\n",
    "\n",
    "print(\"\\nMultifactorial Classification Metrics:\")\n",
    "print(\"================================\")\n",
    "print(f\"Accuracy: {multi_metrics['accuracy']:.4f}\")\n",
    "print(f\"F1-Score: {multi_metrics['f1_score']:.4f}\")\n",
    "print(f\"Recall: {multi_metrics['recall']:.4f}\")\n",
    "print(f\"Number of samples: {multi_metrics['n_samples']}\")\n",
    "\n",
    "# Print detailed classification reports\n",
    "print_detailed_results(\n",
    "    binary_original.loc[binary_indices, 'label'],\n",
    "    binary_gpt.loc[binary_indices, 'label'],\n",
    "    \"Binary\"\n",
    ")\n",
    "\n",
    "print_detailed_results(\n",
    "    multi_original.loc[multi_indices, 'nivel_risa'],\n",
    "    multi_gpt.loc[multi_indices, 'nivel_risa'],\n",
    "    \"Multifactorial\"\n",
    ")\n",
    "\n",
    "# Create summary DataFrame\n",
    "summary_df = pd.DataFrame({\n",
    "    'Task': ['Binary', 'Multifactorial'],\n",
    "    'Accuracy': [binary_metrics['accuracy'], multi_metrics['accuracy']],\n",
    "    'F1_Score': [binary_metrics['f1_score'], multi_metrics['f1_score']],\n",
    "    'Recall': [binary_metrics['recall'], multi_metrics['recall']],\n",
    "    'Samples': [binary_metrics['n_samples'], multi_metrics['n_samples']]\n",
    "})\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "print(\"========\")\n",
    "print(summary_df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
